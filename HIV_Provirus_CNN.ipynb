{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HIV Provirus_20191220",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D58TNN5zLL_S",
        "colab_type": "text"
      },
      "source": [
        "#**A Convolutional Neural Network for predicting HIV Integration Sites**\n",
        "###This python notebook is the result of degree project done by Senad Matuh Delic, the full-text describing the work in full can be found here (link to be added)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCbtnO1jIx7Y",
        "colab_type": "text"
      },
      "source": [
        "###Download the dataset for HIV Integration Sites\n",
        "#####This can be done fetching the pre-generated dataset from AWS using the code below. Otherwise you can generate your own dataset using our dataset generator tool [Retrovirus Integration Database Parser & Training Set Generator](https://github.com/senadmd/RetrovirusIntegrationDatabaseParser)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYFy-vFYbwpH",
        "colab_type": "code",
        "outputId": "910779bc-8c53-4511-c112-d4b367d47354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "!wget -O data.zip \"https://kth-project.s3.eu-north-1.amazonaws.com/data.zip\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-20 21:01:27--  https://kth-project.s3.eu-north-1.amazonaws.com/data.zip\n",
            "Resolving kth-project.s3.eu-north-1.amazonaws.com (kth-project.s3.eu-north-1.amazonaws.com)... 52.95.169.8\n",
            "Connecting to kth-project.s3.eu-north-1.amazonaws.com (kth-project.s3.eu-north-1.amazonaws.com)|52.95.169.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 345929473 (330M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>] 329.90M  10.7MB/s    in 44s     \n",
            "\n",
            "2019-12-20 21:02:17 (7.45 MB/s) - ‘data.zip’ saved [345929473/345929473]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyqIjZiTJ9At",
        "colab_type": "text"
      },
      "source": [
        "###Extract the compressed files\n",
        "####The files containing the \"_validation\" suffix are files part of the validation set and should only be used when validating the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH0p6NtZkl-D",
        "colab_type": "code",
        "outputId": "8492c60f-11b7-4839-e363-e2e0241cebfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "!unzip data.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/DNAString.txt      \n",
            "  inflating: data/DNAString_validation.txt  \n",
            "  inflating: data/inserts.txt        \n",
            "  inflating: data/inserts_validation.txt  \n",
            "  inflating: data/labels.txt         \n",
            "  inflating: data/labels_validation.txt  \n",
            "  inflating: data/positions.txt      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM0otVZwKPm-",
        "colab_type": "text"
      },
      "source": [
        "###Parse the one-hot encoded DNA sampled at HIV insert positions  from the inserts.txt file (training data)\n",
        "#####The DNA is encoded into four channels indicating occurrence of the nucleotides A,C,G,T. The one-hot encoded DNA string in the dataset  contains nucleotides 100 bp before integration site and 100 bp of nucleotides after the integration site fetched from the GRCh37/hg19 genome using the [UCSC Genome API](http://genome.ucsc.edu/goldenPath/help/api.html). The HIV Integration positions have been parsed from [Retrovirus Integration Database](https://rid.ncifcrf.gov) using our own tool described above, the positions parsed can be found in the extracted file *positions.txt*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUlFqfHhqm_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('data/inserts.txt', sep=',',header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x8_BVYRQY9m",
        "colab_type": "text"
      },
      "source": [
        "####What inserts.txt file looks like\n",
        "#####We see that the DNA string is a 800 length one-hot encoded string. This is result of four A-C-G-T channels of 200 bp being one-hot encoded and concatenated into a single string. Note that no proviral HIV DNA is contained in the files extracted, these contain only DNA sampled at the positions of HIV integration from the GRCh37/hg19 genome. Regarding false HIV integration DNA samples, these have randomly sampled from the GRCh37/hg19 genome with safeguards of collisions or overlap between the sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi7LbI0knGtt",
        "colab_type": "code",
        "outputId": "3976abde-9395-440a-e869-921f728cf92a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "df.head"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of          0    1    2    3    4    5    6    ...  793  794  795  796  797  798  799\n",
              "0          0    0    0    0    1    0    0  ...    0    0    0    0    0    1    1\n",
              "1          0    1    0    0    0    0    1  ...    1    1    1    0    0    1    1\n",
              "2          0    0    0    0    1    0    0  ...    0    0    0    0    1    0    0\n",
              "3          0    1    0    0    0    0    1  ...    0    0    0    0    0    0    0\n",
              "4          0    1    0    0    0    0    0  ...    1    1    1    1    0    1    0\n",
              "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
              "1595819    0    0    0    0    0    0    0  ...    1    0    0    0    0    0    1\n",
              "1595820    1    1    1    1    0    0    1  ...    1    1    0    0    0    1    0\n",
              "1595821    1    0    0    0    1    1    1  ...    0    0    1    0    1    0    0\n",
              "1595822    0    0    1    0    0    1    0  ...    1    1    1    1    0    0    0\n",
              "1595823    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
              "\n",
              "[1595824 rows x 800 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maNvYz1ZQsws",
        "colab_type": "text"
      },
      "source": [
        "###Parse the training labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQsmrZ91pry6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelsdf=pd.read_csv('data/labels.txt', sep=',',header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DIuN25sQ0Nt",
        "colab_type": "text"
      },
      "source": [
        "####Lets get an look into the label data\n",
        "#####Below we see that each second label is a false label, this means that each second row in the insert.txt file is a false integration event randomly sampled from the GRCh37/hg19 genome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7knmtYSw2h_",
        "colab_type": "code",
        "outputId": "eebd1bee-dcbc-4696-c6a1-0494e95f1f65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "labelsdf.head"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of          0\n",
              "0        1\n",
              "1        0\n",
              "2        1\n",
              "3        0\n",
              "4        1\n",
              "...     ..\n",
              "1595819  0\n",
              "1595820  1\n",
              "1595821  0\n",
              "1595822  1\n",
              "1595823  0\n",
              "\n",
              "[1595824 rows x 1 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvugOUR-TbW-",
        "colab_type": "text"
      },
      "source": [
        "###Import Tensorflow and Numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr-50K2hYXG0",
        "colab_type": "code",
        "outputId": "2ece30d1-99a3-4223-833f-053d1bd971cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution() # define eager execution to be able to preview our training data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i08_xdHYTkeZ",
        "colab_type": "text"
      },
      "source": [
        "###Split the training set into smaller equal size batches for less RAM consumption\n",
        "####Below we split our dataset using the divisor (272)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m8mtTAeGbFR",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "# Split traning data into equal parts\n",
        "data_chunks = list(np.split(df.values, 272)) \n",
        "labels_chunks = list(np.split(labelsdf.values, 272))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE2b71qFULj7",
        "colab_type": "text"
      },
      "source": [
        "####Lets confirm that we have 272 equal parts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1uMIjhQG_6h",
        "colab_type": "code",
        "outputId": "7a4a2120-905b-4457-a2a8-a8017fb5a3cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(data_chunks)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "272"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTZw5csHU6LQ",
        "colab_type": "text"
      },
      "source": [
        "####Lets examine the size of each batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLaYXhcaHv63",
        "colab_type": "code",
        "outputId": "f7463e01-789f-4d18-9874-a3664e173f47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data_chunks[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5867, 800)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnKVrtGYVkak",
        "colab_type": "text"
      },
      "source": [
        "###Reshaping each row to keep dimensionality of the data contained in each row\n",
        "####Before reshaping the data, lets look at how a single insert row look like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imozJeuPIHp_",
        "colab_type": "code",
        "outputId": "711104c9-ce0a-4431-8dc6-5d9ecefc790f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        }
      },
      "source": [
        "data_chunks[0][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
              "       1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
              "       1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9jS7uVUWSFx",
        "colab_type": "text"
      },
      "source": [
        "####Lets structure our data so that we don´t lose the dimensionality information contained in the seperate one-hot encoded channels\n",
        "#####Lets reshape each single row into four seperate channels corresponding to the nucleotides A-C-G-T.\n",
        "#####We can test this with the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14kh5a-UIm00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Below we repshape a single batch chunk for demonstration\n",
        "chunk_reshaped = data_chunks[0].reshape([data_chunks[0].shape[0],4,200])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8LctcYYJast",
        "colab_type": "code",
        "outputId": "06e6a9f7-8f41-426d-8966-cbcfda8cc6a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        }
      },
      "source": [
        "# Lets examine the shape and data contained in the first row of chunk_reshaped\n",
        "chunk_reshaped[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "        1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "        1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "        1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
              "        1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "        1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
              "        1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "        0, 0],\n",
              "       [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
              "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "        0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
              "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "        0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
              "        0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
              "        0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "        1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
              "        0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BuENWOJUfYa",
        "colab_type": "text"
      },
      "source": [
        "###Define batch set generator function\n",
        "####This batch set generator function will reshape each batch and tie together each tranining data row with each label row using the python [zip function](https://docs.python.org/3/library/functions.html#zip).\n",
        "####The generator will reshape the data similarly as above, with one difference, to use our data as input for a [tensorflow CNN](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D?version=stable) we need to add a channel dimension to our data. Since the default input data format for a tensorflow CNN is (batch, height, width, channels) per *channels_last* setting, we need to add an extra last dimension channel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCIE0uYb8flV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define a generator to reshape our dataset and zip each insert row with each label row\n",
        "batchSize=data_chunks[0].shape[0]\n",
        "def genenerator():\n",
        "    for i, j in zip(data_chunks, labels_chunks):\n",
        "        yield i.reshape([batchSize,4,200,-1]), j\n",
        "#create a tensor for our training dataset\n",
        "train_dataset = tf.data.Dataset.from_generator(genenerator,output_shapes=([batchSize,4,200,1],[batchSize,1]),output_types=(tf.float32, tf.float32)) \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3dbsTqxZZRE",
        "colab_type": "text"
      },
      "source": [
        "####Lets verify that the output from the batch set generator is indeed the same as in the previous example (with the exception of the extra dimension)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsr9l83yPwyi",
        "colab_type": "code",
        "outputId": "0d3079f5-6ae1-41a2-c0c3-ca36f720da58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "# define an iterator over our training data and get first next entry\n",
        "trainingData, trainingLabels = next(iter(train_dataset))\n",
        "print('Our first training label is:',trainingLabels[0].numpy()[0])\n",
        "print('Our first training row has the shape:',trainingData[0].numpy().shape)\n",
        "print('Our previous example has the shape:',chunk_reshaped[0].shape)\n",
        "print('Our first training row has the following entries in the first channel:',trainingData[0].numpy()[0][0],\n",
        "      trainingData[0].numpy()[0][1],trainingData[0].numpy()[0][2],trainingData[0].numpy()[0][3],trainingData[0].numpy()[0][2],trainingData[0].numpy()[0][4],\"..\")\n",
        "print('Our first training row has the following entries in the last channel:',trainingData[0].numpy()[3][0],\n",
        "      trainingData[0].numpy()[3][1],trainingData[0].numpy()[3][2],trainingData[0].numpy()[3][3],trainingData[0].numpy()[3][2],trainingData[0].numpy()[3][4],\"..\")\n",
        "print('Our previous example row has the following entries in the first channel:',chunk_reshaped[0][0][0],chunk_reshaped[0][0][1],chunk_reshaped[0][0][2],chunk_reshaped[0][0][3],chunk_reshaped[0][0][4], \"..\")\n",
        "print('Our previous example row has the following entries in the last channel:',chunk_reshaped[0][3][0],chunk_reshaped[0][3][1],chunk_reshaped[0][3][2],chunk_reshaped[0][3][3],chunk_reshaped[0][3][4],\"..\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our first training label is: 1.0\n",
            "Our first training row has the shape: (4, 200, 1)\n",
            "Our previous example has the shape: (4, 200)\n",
            "Our first training row has the following entries in the first channel: [0.] [0.] [0.] [0.] [0.] [1.] ..\n",
            "Our first training row has the following entries in the last channel: [1.] [0.] [0.] [0.] [0.] [0.] ..\n",
            "Our previous example row has the following entries in the first channel: 0 0 0 0 1 ..\n",
            "Our previous example row has the following entries in the last channel: 1 0 0 0 0 ..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xskyaynkijc",
        "colab_type": "text"
      },
      "source": [
        "###Modeling the neural network with Keras\n",
        "####Lets import Keras API and Matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm9s8aPqN0FY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import keras API and matplotlib\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsPk92UJk7o4",
        "colab_type": "text"
      },
      "source": [
        "####Define the layers for our CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-gCAt5gOIQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create our neural network model\n",
        "tf.keras.backend.clear_session()\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(100, (4, 30), activation='relu', input_shape=(4, 200,1)))\n",
        "model.add(layers.MaxPooling2D((3, 10),strides=1,padding='same'))\n",
        "model.add(layers.Conv2D(50, (1, 10), padding='same', activation='relu'))\n",
        "model.add(layers.MaxPooling2D((1, 1),strides=1))\n",
        "model.add(layers.Conv2D(50, (1, 5), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(50, activation='relu'))\n",
        "model.add(layers.Dense(1, activation=tf.nn.sigmoid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpYqddd3lSyc",
        "colab_type": "text"
      },
      "source": [
        "####Lets examine the layers and the number of parameters associated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr1oO5Vtlw7H",
        "colab_type": "code",
        "outputId": "fda98623-4bbd-4162-9670-9abc5c141ec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 1, 171, 100)       12100     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 1, 171, 100)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 1, 171, 50)        50050     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 1, 171, 50)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 1, 167, 50)        12550     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8350)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 50)                417550    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 492,301\n",
            "Trainable params: 492,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWFa-eCtlho4",
        "colab_type": "text"
      },
      "source": [
        "####Compile our Keras CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ1tnQqQmHig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compile our model\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1w1BZPRlrgL",
        "colab_type": "text"
      },
      "source": [
        "####Train the neural network in batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7BhSl1sm4sf",
        "colab_type": "code",
        "outputId": "7b4d6d91-f8a1-40ae-9293-71357e3fe97b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#train our neural network\n",
        "#use batch training\n",
        "for trainData, trainLabels in iter(train_dataset):\n",
        " model.fit(trainData, trainLabels,batch_size=batchSize, epochs=5)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 9s 1ms/sample - loss: 0.6939 - acc: 0.5001\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.8091 - acc: 0.5001\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6932 - acc: 0.4972\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6927 - acc: 0.5282\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6919 - acc: 0.5204\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6986 - acc: 0.4999\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6976 - acc: 0.5001\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6960 - acc: 0.5001\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6923 - acc: 0.4999\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6931 - acc: 0.4999\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6943 - acc: 0.5001\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6938 - acc: 0.5001\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6926 - acc: 0.5001\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6922 - acc: 0.5652\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6921 - acc: 0.5001\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6925 - acc: 0.5001\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6920 - acc: 0.4997\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6913 - acc: 0.5468\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 28us/sample - loss: 0.6912 - acc: 0.5482\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6906 - acc: 0.5471\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6898 - acc: 0.5548\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6894 - acc: 0.5456\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6882 - acc: 0.5493\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6874 - acc: 0.5519\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6859 - acc: 0.5509\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6838 - acc: 0.5572\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6823 - acc: 0.5642\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6805 - acc: 0.5650\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6802 - acc: 0.5621\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6811 - acc: 0.5626\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6803 - acc: 0.5579\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6779 - acc: 0.5676\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6778 - acc: 0.5715\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6773 - acc: 0.5660\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6752 - acc: 0.5753\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6743 - acc: 0.5778\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6730 - acc: 0.5783\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 28us/sample - loss: 0.6717 - acc: 0.5812\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6709 - acc: 0.5836\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6687 - acc: 0.5906\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6721 - acc: 0.5754\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6702 - acc: 0.5911\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6686 - acc: 0.5955\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6673 - acc: 0.5877\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6650 - acc: 0.6024\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6645 - acc: 0.6012\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6626 - acc: 0.6005\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6606 - acc: 0.6047\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6590 - acc: 0.6087\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6562 - acc: 0.6112\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6566 - acc: 0.6122\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6543 - acc: 0.6208\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6537 - acc: 0.6192\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6617 - acc: 0.6005\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6768 - acc: 0.5620\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6605 - acc: 0.6099\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6679 - acc: 0.5834\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6575 - acc: 0.6080\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6563 - acc: 0.6175\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6594 - acc: 0.6078\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6563 - acc: 0.6151\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6544 - acc: 0.6172\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6576 - acc: 0.6090\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6520 - acc: 0.6196\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6544 - acc: 0.6196\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6461 - acc: 0.6286\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6416 - acc: 0.6375\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6452 - acc: 0.6279\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6391 - acc: 0.6426\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6391 - acc: 0.6443\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6387 - acc: 0.6381\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6347 - acc: 0.6445\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6358 - acc: 0.6364\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6313 - acc: 0.6467\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6321 - acc: 0.6462\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6326 - acc: 0.6480\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6345 - acc: 0.6399\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6342 - acc: 0.6456\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6284 - acc: 0.6552\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6332 - acc: 0.6407\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6360 - acc: 0.6427\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6319 - acc: 0.6465\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6350 - acc: 0.6371\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6270 - acc: 0.6555\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6276 - acc: 0.6538\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6296 - acc: 0.6520\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6246 - acc: 0.6557\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6220 - acc: 0.6588\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6251 - acc: 0.6542\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6346 - acc: 0.6381\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 28us/sample - loss: 0.6284 - acc: 0.6463\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6221 - acc: 0.6581\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6244 - acc: 0.6540\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6214 - acc: 0.6598\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6185 - acc: 0.6635\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6149 - acc: 0.6625\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6124 - acc: 0.6664\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6111 - acc: 0.6649\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6089 - acc: 0.6683\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6088 - acc: 0.6644\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6172 - acc: 0.6709\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6373 - acc: 0.6317\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6137 - acc: 0.6681\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6427 - acc: 0.6364\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6198 - acc: 0.6523\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 28us/sample - loss: 0.6473 - acc: 0.6168\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6202 - acc: 0.6472\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6406 - acc: 0.6463\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6183 - acc: 0.6583\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6240 - acc: 0.6451\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6265 - acc: 0.6475\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6186 - acc: 0.6586\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6118 - acc: 0.6618\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6204 - acc: 0.6559\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6105 - acc: 0.6623\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6180 - acc: 0.6514\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6203 - acc: 0.6480\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6136 - acc: 0.6615\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6122 - acc: 0.6649\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6146 - acc: 0.6627\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 28us/sample - loss: 0.6099 - acc: 0.6734\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6082 - acc: 0.6724\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6081 - acc: 0.6676\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6037 - acc: 0.6770\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6046 - acc: 0.6777\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6091 - acc: 0.6632\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6093 - acc: 0.6663\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6056 - acc: 0.6731\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6053 - acc: 0.6687\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6042 - acc: 0.6690\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5993 - acc: 0.6724\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5970 - acc: 0.6739\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5979 - acc: 0.6739\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5943 - acc: 0.6782\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5916 - acc: 0.6796\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 28us/sample - loss: 0.6049 - acc: 0.6632\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6024 - acc: 0.6673\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5998 - acc: 0.6707\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6011 - acc: 0.6659\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5978 - acc: 0.6755\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5962 - acc: 0.6721\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6010 - acc: 0.6692\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6227 - acc: 0.6439\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5970 - acc: 0.6791\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5996 - acc: 0.6789\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 28us/sample - loss: 0.6080 - acc: 0.6688\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6021 - acc: 0.6716\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6152 - acc: 0.6717\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6075 - acc: 0.6676\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6050 - acc: 0.6688\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6016 - acc: 0.6756\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6065 - acc: 0.6779\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5979 - acc: 0.6751\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6014 - acc: 0.6690\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5980 - acc: 0.6782\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6000 - acc: 0.6727\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6036 - acc: 0.6680\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6015 - acc: 0.6734\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6007 - acc: 0.6712\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5985 - acc: 0.6748\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5881 - acc: 0.6835\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5895 - acc: 0.6813\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5881 - acc: 0.6823\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5842 - acc: 0.6903\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5829 - acc: 0.6913\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5896 - acc: 0.6854\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5897 - acc: 0.6825\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5861 - acc: 0.6854\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5854 - acc: 0.6809\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5834 - acc: 0.6860\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5980 - acc: 0.6733\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5956 - acc: 0.6719\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5921 - acc: 0.6745\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5923 - acc: 0.6785\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5900 - acc: 0.6828\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5843 - acc: 0.6883\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5862 - acc: 0.6825\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5872 - acc: 0.6859\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5823 - acc: 0.6867\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5778 - acc: 0.6917\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5747 - acc: 0.6929\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5735 - acc: 0.6930\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5705 - acc: 0.6987\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5685 - acc: 0.7036\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5658 - acc: 0.7024\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5849 - acc: 0.6869\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5866 - acc: 0.6777\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5885 - acc: 0.6818\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5836 - acc: 0.6860\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5768 - acc: 0.6963\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5990 - acc: 0.6779\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6085 - acc: 0.6606\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6080 - acc: 0.6697\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5975 - acc: 0.6745\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5986 - acc: 0.6777\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5907 - acc: 0.6814\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5786 - acc: 0.6954\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5717 - acc: 0.6958\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5796 - acc: 0.6935\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5834 - acc: 0.6891\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6069 - acc: 0.6765\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6029 - acc: 0.6702\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5932 - acc: 0.6831\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6079 - acc: 0.6601\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5941 - acc: 0.6857\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5988 - acc: 0.6719\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5863 - acc: 0.6837\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5962 - acc: 0.6741\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5820 - acc: 0.6883\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5879 - acc: 0.6814\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5799 - acc: 0.6896\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5818 - acc: 0.6886\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5800 - acc: 0.6884\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5760 - acc: 0.6912\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5742 - acc: 0.6952\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5845 - acc: 0.6884\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5841 - acc: 0.6923\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5849 - acc: 0.6913\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5806 - acc: 0.6922\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5811 - acc: 0.6884\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5780 - acc: 0.6881\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5783 - acc: 0.6896\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5745 - acc: 0.6912\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5745 - acc: 0.6918\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5752 - acc: 0.6917\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5757 - acc: 0.7031\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5723 - acc: 0.7033\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5704 - acc: 0.7053\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5698 - acc: 0.7075\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5672 - acc: 0.7094\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5746 - acc: 0.6929\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5747 - acc: 0.6963\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5736 - acc: 0.6947\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5699 - acc: 0.6968\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5667 - acc: 0.7010\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5670 - acc: 0.7048\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5646 - acc: 0.7068\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5624 - acc: 0.7043\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5609 - acc: 0.7079\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5585 - acc: 0.7077\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5569 - acc: 0.7125\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5564 - acc: 0.7150\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5655 - acc: 0.6987\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6045 - acc: 0.6910\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6957 - acc: 0.5829\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6205 - acc: 0.6608\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.7231 - acc: 0.5771\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6223 - acc: 0.6514\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6621 - acc: 0.6058\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6629 - acc: 0.5993\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6063 - acc: 0.6756\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6181 - acc: 0.6584\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6379 - acc: 0.6271\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6176 - acc: 0.6533\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5998 - acc: 0.6900\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6086 - acc: 0.6717\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6135 - acc: 0.6625\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6079 - acc: 0.6693\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5958 - acc: 0.6842\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5939 - acc: 0.6857\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6076 - acc: 0.6652\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6024 - acc: 0.6709\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5932 - acc: 0.6881\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5938 - acc: 0.6847\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5958 - acc: 0.6830\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5879 - acc: 0.6869\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5886 - acc: 0.6877\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5896 - acc: 0.6862\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5817 - acc: 0.6925\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5837 - acc: 0.6935\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5808 - acc: 0.6886\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5783 - acc: 0.6915\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5784 - acc: 0.6934\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5746 - acc: 0.6983\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5729 - acc: 0.6978\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5792 - acc: 0.6971\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5766 - acc: 0.6976\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5775 - acc: 0.6983\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5736 - acc: 0.6998\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5734 - acc: 0.7014\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5672 - acc: 0.7002\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5675 - acc: 0.6997\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5636 - acc: 0.7033\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5626 - acc: 0.7009\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5592 - acc: 0.7070\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5605 - acc: 0.7130\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5600 - acc: 0.7126\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5560 - acc: 0.7138\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5559 - acc: 0.7147\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5514 - acc: 0.7176\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5718 - acc: 0.6956\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5703 - acc: 0.6958\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5691 - acc: 0.6959\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5671 - acc: 0.6987\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5639 - acc: 0.7033\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5701 - acc: 0.7021\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5683 - acc: 0.7017\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5664 - acc: 0.7016\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5642 - acc: 0.7044\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5617 - acc: 0.7080\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5713 - acc: 0.7000\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5701 - acc: 0.6985\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5688 - acc: 0.6978\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5678 - acc: 0.6990\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5680 - acc: 0.7012\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5577 - acc: 0.7082\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5617 - acc: 0.7026\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5485 - acc: 0.7164\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5477 - acc: 0.7155\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5519 - acc: 0.7108\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5599 - acc: 0.7097\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5589 - acc: 0.7121\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5616 - acc: 0.7043\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5541 - acc: 0.7177\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5536 - acc: 0.7186\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5603 - acc: 0.7063\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5522 - acc: 0.7131\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5538 - acc: 0.7123\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5558 - acc: 0.7102\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5458 - acc: 0.7200\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5577 - acc: 0.7114\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5586 - acc: 0.7029\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5473 - acc: 0.7119\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5599 - acc: 0.7077\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5494 - acc: 0.7123\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5656 - acc: 0.6980\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5682 - acc: 0.7017\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5575 - acc: 0.7084\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5619 - acc: 0.7022\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5528 - acc: 0.7128\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5467 - acc: 0.7237\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5402 - acc: 0.7305\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5412 - acc: 0.7252\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5378 - acc: 0.7305\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5337 - acc: 0.7326\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5485 - acc: 0.7205\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5441 - acc: 0.7225\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5452 - acc: 0.7264\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5421 - acc: 0.7247\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5371 - acc: 0.7266\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5482 - acc: 0.7184\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5457 - acc: 0.7196\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5422 - acc: 0.7174\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5422 - acc: 0.7240\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5405 - acc: 0.7249\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5410 - acc: 0.7230\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5385 - acc: 0.7259\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5380 - acc: 0.7239\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5380 - acc: 0.7268\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5389 - acc: 0.7220\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5390 - acc: 0.7239\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5353 - acc: 0.7244\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5289 - acc: 0.7321\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5270 - acc: 0.7317\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5275 - acc: 0.7293\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5330 - acc: 0.7321\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5295 - acc: 0.7360\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5292 - acc: 0.7329\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5275 - acc: 0.7358\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5235 - acc: 0.7362\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5223 - acc: 0.7372\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5226 - acc: 0.7363\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5218 - acc: 0.7368\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5183 - acc: 0.7401\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5146 - acc: 0.7426\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5342 - acc: 0.7307\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5324 - acc: 0.7307\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5310 - acc: 0.7336\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5286 - acc: 0.7358\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5253 - acc: 0.7355\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5262 - acc: 0.7367\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5253 - acc: 0.7344\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5238 - acc: 0.7365\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5216 - acc: 0.7389\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5202 - acc: 0.7409\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5209 - acc: 0.7421\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5210 - acc: 0.7382\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5200 - acc: 0.7413\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5206 - acc: 0.7363\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5180 - acc: 0.7418\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5247 - acc: 0.7304\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5201 - acc: 0.7397\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5192 - acc: 0.7401\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5204 - acc: 0.7346\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5177 - acc: 0.7377\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5194 - acc: 0.7402\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5181 - acc: 0.7396\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5186 - acc: 0.7430\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5163 - acc: 0.7442\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5121 - acc: 0.7433\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5114 - acc: 0.7472\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5139 - acc: 0.7421\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5132 - acc: 0.7517\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5124 - acc: 0.7440\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5056 - acc: 0.7530\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5154 - acc: 0.7406\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5162 - acc: 0.7450\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5143 - acc: 0.7433\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5113 - acc: 0.7493\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5090 - acc: 0.7488\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5084 - acc: 0.7481\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5077 - acc: 0.7457\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5053 - acc: 0.7508\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5030 - acc: 0.7505\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5009 - acc: 0.7513\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5171 - acc: 0.7527\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5180 - acc: 0.7450\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5127 - acc: 0.7530\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5111 - acc: 0.7537\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5118 - acc: 0.7517\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5109 - acc: 0.7505\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5132 - acc: 0.7525\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5189 - acc: 0.7363\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5080 - acc: 0.7547\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5074 - acc: 0.7556\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5097 - acc: 0.7455\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5013 - acc: 0.7558\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5012 - acc: 0.7595\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5028 - acc: 0.7537\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4964 - acc: 0.7612\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5052 - acc: 0.7588\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5036 - acc: 0.7540\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5009 - acc: 0.7573\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4987 - acc: 0.7593\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4976 - acc: 0.7573\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5084 - acc: 0.7469\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5061 - acc: 0.7488\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5048 - acc: 0.7479\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5030 - acc: 0.7489\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4995 - acc: 0.7529\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5103 - acc: 0.7452\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5098 - acc: 0.7481\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5086 - acc: 0.7486\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5060 - acc: 0.7525\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5033 - acc: 0.7540\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4982 - acc: 0.7508\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4979 - acc: 0.7535\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4973 - acc: 0.7496\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4956 - acc: 0.7566\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4940 - acc: 0.7530\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5007 - acc: 0.7564\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4990 - acc: 0.7558\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4969 - acc: 0.7571\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4953 - acc: 0.7607\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4943 - acc: 0.7580\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5101 - acc: 0.7452\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5197 - acc: 0.7370\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5155 - acc: 0.7411\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5077 - acc: 0.7467\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4984 - acc: 0.7571\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4997 - acc: 0.7573\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5071 - acc: 0.7479\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4948 - acc: 0.7614\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4928 - acc: 0.7619\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4963 - acc: 0.7571\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4997 - acc: 0.7629\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4972 - acc: 0.7621\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4984 - acc: 0.7593\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4941 - acc: 0.7617\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4933 - acc: 0.7670\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5120 - acc: 0.7474\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5086 - acc: 0.7529\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5090 - acc: 0.7523\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5094 - acc: 0.7493\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5031 - acc: 0.7580\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5090 - acc: 0.7498\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5119 - acc: 0.7430\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5055 - acc: 0.7518\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5103 - acc: 0.7500\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5069 - acc: 0.7462\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4976 - acc: 0.7597\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5106 - acc: 0.7462\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5045 - acc: 0.7525\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5036 - acc: 0.7546\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4984 - acc: 0.7598\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5059 - acc: 0.7542\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5096 - acc: 0.7486\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5026 - acc: 0.7593\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5104 - acc: 0.7501\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5073 - acc: 0.7520\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5082 - acc: 0.7437\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5201 - acc: 0.7384\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5088 - acc: 0.7430\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5138 - acc: 0.7382\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5029 - acc: 0.7435\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5231 - acc: 0.7341\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5124 - acc: 0.7464\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5173 - acc: 0.7438\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5099 - acc: 0.7462\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5108 - acc: 0.7430\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5034 - acc: 0.7540\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5005 - acc: 0.7566\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5010 - acc: 0.7563\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4974 - acc: 0.7605\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4957 - acc: 0.7600\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5116 - acc: 0.7423\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5120 - acc: 0.7471\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5086 - acc: 0.7452\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5076 - acc: 0.7474\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5039 - acc: 0.7512\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4967 - acc: 0.7566\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4956 - acc: 0.7593\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4946 - acc: 0.7588\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4924 - acc: 0.7598\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4902 - acc: 0.7609\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5010 - acc: 0.7522\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5004 - acc: 0.7539\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4982 - acc: 0.7559\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4963 - acc: 0.7571\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4933 - acc: 0.7597\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4899 - acc: 0.7568\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4893 - acc: 0.7595\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4879 - acc: 0.7556\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4857 - acc: 0.7615\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4831 - acc: 0.7609\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4866 - acc: 0.7587\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4858 - acc: 0.7585\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4843 - acc: 0.7592\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4823 - acc: 0.7604\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4799 - acc: 0.7633\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4841 - acc: 0.7680\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4836 - acc: 0.7672\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4827 - acc: 0.7636\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4807 - acc: 0.7699\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4776 - acc: 0.7673\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4964 - acc: 0.7525\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4965 - acc: 0.7522\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4951 - acc: 0.7523\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4911 - acc: 0.7525\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4871 - acc: 0.7547\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4939 - acc: 0.7571\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4953 - acc: 0.7610\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4960 - acc: 0.7583\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4898 - acc: 0.7617\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4889 - acc: 0.7679\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4920 - acc: 0.7587\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4868 - acc: 0.7651\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4863 - acc: 0.7638\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4874 - acc: 0.7658\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4817 - acc: 0.7668\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4976 - acc: 0.7559\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4970 - acc: 0.7484\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4908 - acc: 0.7571\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4945 - acc: 0.7566\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4943 - acc: 0.7537\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4887 - acc: 0.7614\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4941 - acc: 0.7551\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4889 - acc: 0.7576\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4825 - acc: 0.7639\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4923 - acc: 0.7566\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5121 - acc: 0.7442\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4891 - acc: 0.7634\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5089 - acc: 0.7469\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4936 - acc: 0.7619\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4983 - acc: 0.7578\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5004 - acc: 0.7510\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5116 - acc: 0.7430\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4990 - acc: 0.7585\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5050 - acc: 0.7561\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4932 - acc: 0.7564\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4953 - acc: 0.7558\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4910 - acc: 0.7544\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4968 - acc: 0.7518\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4943 - acc: 0.7569\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4878 - acc: 0.7624\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4902 - acc: 0.7590\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4909 - acc: 0.7581\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4908 - acc: 0.7529\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4899 - acc: 0.7520\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4852 - acc: 0.7627\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4878 - acc: 0.7650\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4875 - acc: 0.7638\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4868 - acc: 0.7646\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4841 - acc: 0.7677\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4809 - acc: 0.7716\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4837 - acc: 0.7604\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4846 - acc: 0.7610\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4826 - acc: 0.7624\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4795 - acc: 0.7653\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4776 - acc: 0.7692\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4873 - acc: 0.7672\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4862 - acc: 0.7673\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4836 - acc: 0.7709\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4823 - acc: 0.7719\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4806 - acc: 0.7733\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4828 - acc: 0.7667\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4817 - acc: 0.7660\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4810 - acc: 0.7701\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4791 - acc: 0.7713\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4755 - acc: 0.7726\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4856 - acc: 0.7677\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4882 - acc: 0.7692\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4861 - acc: 0.7636\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4815 - acc: 0.7742\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4824 - acc: 0.7721\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 28us/sample - loss: 0.4915 - acc: 0.7605\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4921 - acc: 0.7588\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4907 - acc: 0.7634\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4865 - acc: 0.7622\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4844 - acc: 0.7615\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4928 - acc: 0.7656\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4910 - acc: 0.7648\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4905 - acc: 0.7643\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4875 - acc: 0.7661\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4853 - acc: 0.7701\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4884 - acc: 0.7626\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4868 - acc: 0.7621\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4868 - acc: 0.7624\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4863 - acc: 0.7670\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4814 - acc: 0.7670\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4845 - acc: 0.7646\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4835 - acc: 0.7646\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4807 - acc: 0.7668\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4819 - acc: 0.7672\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4810 - acc: 0.7634\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4935 - acc: 0.7617\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4947 - acc: 0.7583\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4924 - acc: 0.7626\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4902 - acc: 0.7624\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4883 - acc: 0.7626\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4903 - acc: 0.7644\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4901 - acc: 0.7670\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4883 - acc: 0.7660\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4855 - acc: 0.7667\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4836 - acc: 0.7696\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4833 - acc: 0.7684\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4820 - acc: 0.7692\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4806 - acc: 0.7694\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4784 - acc: 0.7736\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4753 - acc: 0.7718\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4882 - acc: 0.7672\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4876 - acc: 0.7692\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4864 - acc: 0.7696\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4842 - acc: 0.7716\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4815 - acc: 0.7726\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4881 - acc: 0.7566\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4879 - acc: 0.7609\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4859 - acc: 0.7587\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4838 - acc: 0.7627\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4819 - acc: 0.7639\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4843 - acc: 0.7704\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4837 - acc: 0.7701\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4823 - acc: 0.7719\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4799 - acc: 0.7730\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4774 - acc: 0.7733\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4886 - acc: 0.7650\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4877 - acc: 0.7665\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4857 - acc: 0.7672\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4838 - acc: 0.7667\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4811 - acc: 0.7706\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4760 - acc: 0.7728\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4750 - acc: 0.7742\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4739 - acc: 0.7750\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4726 - acc: 0.7752\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4691 - acc: 0.7801\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4790 - acc: 0.7704\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4785 - acc: 0.7696\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4782 - acc: 0.7690\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4762 - acc: 0.7721\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4727 - acc: 0.7718\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4812 - acc: 0.7697\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4803 - acc: 0.7701\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4786 - acc: 0.7738\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4764 - acc: 0.7740\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4734 - acc: 0.7774\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4810 - acc: 0.7644\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4800 - acc: 0.7667\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4776 - acc: 0.7680\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4746 - acc: 0.7713\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4721 - acc: 0.7718\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4850 - acc: 0.7641\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4862 - acc: 0.7633\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4833 - acc: 0.7672\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4808 - acc: 0.7692\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4782 - acc: 0.7719\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4877 - acc: 0.7639\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4880 - acc: 0.7602\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4854 - acc: 0.7660\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4823 - acc: 0.7643\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4797 - acc: 0.7673\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4900 - acc: 0.7615\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4903 - acc: 0.7619\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4909 - acc: 0.7629\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4865 - acc: 0.7633\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4807 - acc: 0.7694\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4818 - acc: 0.7673\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4804 - acc: 0.7716\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4786 - acc: 0.7743\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4789 - acc: 0.7725\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4747 - acc: 0.7784\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4913 - acc: 0.7641\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4928 - acc: 0.7604\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4891 - acc: 0.7641\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4883 - acc: 0.7673\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4858 - acc: 0.7668\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5021 - acc: 0.7537\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5005 - acc: 0.7551\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4977 - acc: 0.7568\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4968 - acc: 0.7576\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4919 - acc: 0.7646\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4832 - acc: 0.7673\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4825 - acc: 0.7670\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4788 - acc: 0.7714\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4768 - acc: 0.7701\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4758 - acc: 0.7689\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4842 - acc: 0.7644\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4837 - acc: 0.7672\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4790 - acc: 0.7687\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4749 - acc: 0.7716\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4728 - acc: 0.7725\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4777 - acc: 0.7747\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4805 - acc: 0.7696\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4767 - acc: 0.7743\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4729 - acc: 0.7794\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4719 - acc: 0.7757\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4834 - acc: 0.7641\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4776 - acc: 0.7684\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4796 - acc: 0.7687\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4785 - acc: 0.7708\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4745 - acc: 0.7723\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4869 - acc: 0.7668\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4837 - acc: 0.7663\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4837 - acc: 0.7670\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4818 - acc: 0.7675\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4779 - acc: 0.7682\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4896 - acc: 0.7675\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4866 - acc: 0.7656\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4822 - acc: 0.7689\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4844 - acc: 0.7682\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4883 - acc: 0.7627\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4849 - acc: 0.7660\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4919 - acc: 0.7634\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4912 - acc: 0.7597\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4880 - acc: 0.7634\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4807 - acc: 0.7714\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4861 - acc: 0.7690\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4899 - acc: 0.7609\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4806 - acc: 0.7673\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4880 - acc: 0.7655\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4750 - acc: 0.7736\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4953 - acc: 0.7559\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4915 - acc: 0.7604\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4936 - acc: 0.7592\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4869 - acc: 0.7624\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4861 - acc: 0.7612\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4744 - acc: 0.7690\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4763 - acc: 0.7689\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4733 - acc: 0.7675\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4695 - acc: 0.7709\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4677 - acc: 0.7740\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4741 - acc: 0.7680\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4740 - acc: 0.7692\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4706 - acc: 0.7699\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4713 - acc: 0.7733\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4687 - acc: 0.7719\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4868 - acc: 0.7621\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4846 - acc: 0.7612\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4841 - acc: 0.7615\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4826 - acc: 0.7631\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4788 - acc: 0.7646\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4847 - acc: 0.7643\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4845 - acc: 0.7660\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4827 - acc: 0.7673\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4796 - acc: 0.7680\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4777 - acc: 0.7714\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4935 - acc: 0.7595\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4921 - acc: 0.7598\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4906 - acc: 0.7598\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4883 - acc: 0.7627\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4851 - acc: 0.7629\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4763 - acc: 0.7701\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4759 - acc: 0.7694\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4741 - acc: 0.7719\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4723 - acc: 0.7747\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4696 - acc: 0.7733\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4786 - acc: 0.7658\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4791 - acc: 0.7643\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4768 - acc: 0.7679\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4736 - acc: 0.7696\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4718 - acc: 0.7696\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4894 - acc: 0.7585\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4873 - acc: 0.7576\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4863 - acc: 0.7593\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4838 - acc: 0.7604\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4804 - acc: 0.7614\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4691 - acc: 0.7776\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4679 - acc: 0.7772\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4660 - acc: 0.7772\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4628 - acc: 0.7788\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4597 - acc: 0.7822\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4759 - acc: 0.7653\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4749 - acc: 0.7677\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4730 - acc: 0.7682\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4702 - acc: 0.7687\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4666 - acc: 0.7725\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4728 - acc: 0.7675\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4715 - acc: 0.7708\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4699 - acc: 0.7714\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4675 - acc: 0.7759\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4652 - acc: 0.7755\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4863 - acc: 0.7643\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4884 - acc: 0.7660\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4866 - acc: 0.7629\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4793 - acc: 0.7714\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4751 - acc: 0.7728\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4779 - acc: 0.7738\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4749 - acc: 0.7759\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4740 - acc: 0.7742\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4717 - acc: 0.7791\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4668 - acc: 0.7781\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4739 - acc: 0.7718\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4746 - acc: 0.7677\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4704 - acc: 0.7738\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4673 - acc: 0.7771\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4663 - acc: 0.7743\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4729 - acc: 0.7711\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4720 - acc: 0.7696\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4724 - acc: 0.7692\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4674 - acc: 0.7716\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4656 - acc: 0.7762\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4845 - acc: 0.7607\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4826 - acc: 0.7617\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4822 - acc: 0.7646\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4798 - acc: 0.7641\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4755 - acc: 0.7668\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4805 - acc: 0.7679\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4804 - acc: 0.7660\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4750 - acc: 0.7735\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4758 - acc: 0.7702\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4718 - acc: 0.7699\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 28us/sample - loss: 0.4885 - acc: 0.7658\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4872 - acc: 0.7634\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4856 - acc: 0.7673\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4828 - acc: 0.7711\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4793 - acc: 0.7701\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4714 - acc: 0.7742\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4706 - acc: 0.7726\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4691 - acc: 0.7725\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4659 - acc: 0.7769\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4636 - acc: 0.7786\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4732 - acc: 0.7701\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4718 - acc: 0.7747\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4687 - acc: 0.7757\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4669 - acc: 0.7735\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4636 - acc: 0.7798\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4742 - acc: 0.7719\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4714 - acc: 0.7711\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4702 - acc: 0.7702\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4667 - acc: 0.7740\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4647 - acc: 0.7789\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4790 - acc: 0.7660\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4776 - acc: 0.7714\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4756 - acc: 0.7677\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4727 - acc: 0.7701\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4702 - acc: 0.7709\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4681 - acc: 0.7760\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4675 - acc: 0.7769\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4663 - acc: 0.7791\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4639 - acc: 0.7794\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4609 - acc: 0.7864\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4743 - acc: 0.7776\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4751 - acc: 0.7752\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4714 - acc: 0.7791\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4691 - acc: 0.7783\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4667 - acc: 0.7803\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4663 - acc: 0.7696\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4660 - acc: 0.7677\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4645 - acc: 0.7711\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4626 - acc: 0.7745\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4592 - acc: 0.7764\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4721 - acc: 0.7731\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4707 - acc: 0.7754\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4696 - acc: 0.7769\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4666 - acc: 0.7791\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4632 - acc: 0.7818\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4905 - acc: 0.7605\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4888 - acc: 0.7604\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4864 - acc: 0.7624\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4834 - acc: 0.7660\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4805 - acc: 0.7687\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4728 - acc: 0.7754\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4736 - acc: 0.7764\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4704 - acc: 0.7762\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4693 - acc: 0.7754\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4663 - acc: 0.7798\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4681 - acc: 0.7769\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4673 - acc: 0.7760\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4666 - acc: 0.7783\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4638 - acc: 0.7791\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4602 - acc: 0.7803\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4693 - acc: 0.7718\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4750 - acc: 0.7723\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4807 - acc: 0.7670\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4738 - acc: 0.7735\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4603 - acc: 0.7791\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4830 - acc: 0.7675\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4790 - acc: 0.7667\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4863 - acc: 0.7658\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4803 - acc: 0.7706\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4729 - acc: 0.7765\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4919 - acc: 0.7617\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5308 - acc: 0.7321\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5585 - acc: 0.7223\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6032 - acc: 0.6779\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4990 - acc: 0.7641\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6134 - acc: 0.6743\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5072 - acc: 0.7592\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5454 - acc: 0.7116\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5397 - acc: 0.7166\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5109 - acc: 0.7627\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5254 - acc: 0.7474\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5519 - acc: 0.7099\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5049 - acc: 0.7612\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4862 - acc: 0.7673\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4949 - acc: 0.7607\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4963 - acc: 0.7581\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4920 - acc: 0.7569\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4767 - acc: 0.7706\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4832 - acc: 0.7704\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4801 - acc: 0.7711\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4834 - acc: 0.7624\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4890 - acc: 0.7592\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4855 - acc: 0.7626\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4797 - acc: 0.7673\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4805 - acc: 0.7684\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4953 - acc: 0.7656\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5042 - acc: 0.7517\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4961 - acc: 0.7607\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4944 - acc: 0.7629\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4894 - acc: 0.7643\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4810 - acc: 0.7714\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4760 - acc: 0.7769\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4772 - acc: 0.7760\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4735 - acc: 0.7798\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4709 - acc: 0.7779\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4781 - acc: 0.7680\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4749 - acc: 0.7696\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4770 - acc: 0.7653\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4717 - acc: 0.7713\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4715 - acc: 0.7706\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4837 - acc: 0.7675\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4845 - acc: 0.7684\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4815 - acc: 0.7721\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4799 - acc: 0.7704\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4773 - acc: 0.7716\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4891 - acc: 0.7677\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4889 - acc: 0.7672\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4862 - acc: 0.7675\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4851 - acc: 0.7656\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4818 - acc: 0.7692\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4763 - acc: 0.7689\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4749 - acc: 0.7740\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4735 - acc: 0.7742\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4719 - acc: 0.7730\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4689 - acc: 0.7789\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4810 - acc: 0.7648\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4798 - acc: 0.7670\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4777 - acc: 0.7665\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4759 - acc: 0.7677\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4731 - acc: 0.7702\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4869 - acc: 0.7629\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4856 - acc: 0.7646\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4830 - acc: 0.7656\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4809 - acc: 0.7677\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4775 - acc: 0.7696\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4857 - acc: 0.7634\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4852 - acc: 0.7667\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4831 - acc: 0.7653\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4821 - acc: 0.7668\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4792 - acc: 0.7706\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4698 - acc: 0.7723\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4696 - acc: 0.7771\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4643 - acc: 0.7765\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4650 - acc: 0.7784\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4595 - acc: 0.7823\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4828 - acc: 0.7622\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4785 - acc: 0.7704\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4787 - acc: 0.7706\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4743 - acc: 0.7716\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4735 - acc: 0.7711\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4708 - acc: 0.7736\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4691 - acc: 0.7719\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4687 - acc: 0.7708\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4641 - acc: 0.7718\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4614 - acc: 0.7757\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4695 - acc: 0.7692\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4683 - acc: 0.7702\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4625 - acc: 0.7750\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4637 - acc: 0.7728\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4562 - acc: 0.7765\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4843 - acc: 0.7656\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4803 - acc: 0.7687\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4826 - acc: 0.7682\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4795 - acc: 0.7690\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4785 - acc: 0.7711\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4774 - acc: 0.7689\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4793 - acc: 0.7675\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4744 - acc: 0.7740\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4745 - acc: 0.7697\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4698 - acc: 0.7771\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4745 - acc: 0.7673\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4704 - acc: 0.7718\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4712 - acc: 0.7733\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4679 - acc: 0.7721\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4673 - acc: 0.7735\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4609 - acc: 0.7808\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4610 - acc: 0.7783\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4609 - acc: 0.7803\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4571 - acc: 0.7830\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4541 - acc: 0.7849\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4651 - acc: 0.7713\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4626 - acc: 0.7721\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4619 - acc: 0.7723\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4584 - acc: 0.7762\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4562 - acc: 0.7759\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4731 - acc: 0.7726\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4703 - acc: 0.7743\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4717 - acc: 0.7697\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4686 - acc: 0.7728\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4675 - acc: 0.7745\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4742 - acc: 0.7735\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4725 - acc: 0.7755\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4707 - acc: 0.7794\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4708 - acc: 0.7794\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4664 - acc: 0.7822\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4694 - acc: 0.7767\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4689 - acc: 0.7762\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4681 - acc: 0.7738\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4645 - acc: 0.7783\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4625 - acc: 0.7779\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4669 - acc: 0.7796\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4666 - acc: 0.7789\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4645 - acc: 0.7815\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4628 - acc: 0.7825\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4599 - acc: 0.7834\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4698 - acc: 0.7713\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4694 - acc: 0.7723\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4660 - acc: 0.7752\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4639 - acc: 0.7767\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4611 - acc: 0.7793\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4787 - acc: 0.7745\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4783 - acc: 0.7730\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4756 - acc: 0.7759\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4742 - acc: 0.7743\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4707 - acc: 0.7779\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4631 - acc: 0.7801\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4619 - acc: 0.7810\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4599 - acc: 0.7813\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4586 - acc: 0.7844\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4552 - acc: 0.7858\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4695 - acc: 0.7771\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4678 - acc: 0.7765\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4666 - acc: 0.7774\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4636 - acc: 0.7796\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4606 - acc: 0.7822\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4693 - acc: 0.7777\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4671 - acc: 0.7788\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4667 - acc: 0.7791\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4632 - acc: 0.7796\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4611 - acc: 0.7823\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4698 - acc: 0.7772\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4684 - acc: 0.7772\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4671 - acc: 0.7779\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4642 - acc: 0.7789\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4621 - acc: 0.7808\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4729 - acc: 0.7743\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4725 - acc: 0.7755\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4714 - acc: 0.7779\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4678 - acc: 0.7788\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4666 - acc: 0.7800\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4688 - acc: 0.7748\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4686 - acc: 0.7760\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4659 - acc: 0.7765\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4640 - acc: 0.7788\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4610 - acc: 0.7798\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4708 - acc: 0.7747\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4704 - acc: 0.7747\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4684 - acc: 0.7760\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4659 - acc: 0.7783\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4633 - acc: 0.7796\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4675 - acc: 0.7779\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4666 - acc: 0.7783\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4648 - acc: 0.7791\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4624 - acc: 0.7813\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4597 - acc: 0.7827\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4728 - acc: 0.7736\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4716 - acc: 0.7743\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4697 - acc: 0.7757\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4677 - acc: 0.7781\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4649 - acc: 0.7820\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4548 - acc: 0.7859\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4548 - acc: 0.7830\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4522 - acc: 0.7866\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4503 - acc: 0.7868\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4483 - acc: 0.7897\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4656 - acc: 0.7736\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4661 - acc: 0.7760\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4632 - acc: 0.7767\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4611 - acc: 0.7798\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4578 - acc: 0.7806\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 28us/sample - loss: 0.4659 - acc: 0.7767\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4654 - acc: 0.7776\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4624 - acc: 0.7783\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4603 - acc: 0.7794\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4568 - acc: 0.7811\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4730 - acc: 0.7682\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4720 - acc: 0.7675\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4706 - acc: 0.7689\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4681 - acc: 0.7740\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4650 - acc: 0.7730\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4658 - acc: 0.7736\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4635 - acc: 0.7738\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4622 - acc: 0.7786\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4595 - acc: 0.7800\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4559 - acc: 0.7830\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 28us/sample - loss: 0.4815 - acc: 0.7716\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4806 - acc: 0.7719\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4790 - acc: 0.7711\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4769 - acc: 0.7725\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4737 - acc: 0.7750\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4715 - acc: 0.7696\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4708 - acc: 0.7711\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4692 - acc: 0.7704\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4668 - acc: 0.7716\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4635 - acc: 0.7736\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4596 - acc: 0.7818\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4585 - acc: 0.7834\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4565 - acc: 0.7830\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4539 - acc: 0.7869\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4508 - acc: 0.7846\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4500 - acc: 0.7829\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4497 - acc: 0.7861\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4501 - acc: 0.7839\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4497 - acc: 0.7869\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4482 - acc: 0.7864\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4796 - acc: 0.7699\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4759 - acc: 0.7713\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4746 - acc: 0.7740\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4731 - acc: 0.7719\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4682 - acc: 0.7777\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4679 - acc: 0.7771\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4673 - acc: 0.7736\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4655 - acc: 0.7757\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4636 - acc: 0.7788\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4611 - acc: 0.7791\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4561 - acc: 0.7846\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4551 - acc: 0.7859\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4526 - acc: 0.7852\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4500 - acc: 0.7890\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4475 - acc: 0.7900\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4634 - acc: 0.7842\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4611 - acc: 0.7849\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4620 - acc: 0.7840\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4557 - acc: 0.7873\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4600 - acc: 0.7861\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4670 - acc: 0.7747\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4702 - acc: 0.7701\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4649 - acc: 0.7706\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4574 - acc: 0.7755\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4621 - acc: 0.7745\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4615 - acc: 0.7805\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4649 - acc: 0.7813\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4643 - acc: 0.7805\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4594 - acc: 0.7839\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4566 - acc: 0.7861\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4718 - acc: 0.7675\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4806 - acc: 0.7660\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4775 - acc: 0.7651\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4855 - acc: 0.7655\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4793 - acc: 0.7689\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4760 - acc: 0.7673\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4697 - acc: 0.7742\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4701 - acc: 0.7762\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4662 - acc: 0.7788\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4678 - acc: 0.7777\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 28us/sample - loss: 0.4756 - acc: 0.7740\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4741 - acc: 0.7750\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4731 - acc: 0.7735\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4678 - acc: 0.7776\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4639 - acc: 0.7803\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4721 - acc: 0.7750\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4699 - acc: 0.7719\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4692 - acc: 0.7743\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4678 - acc: 0.7798\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4638 - acc: 0.7777\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4676 - acc: 0.7765\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4669 - acc: 0.7771\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4636 - acc: 0.7811\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4612 - acc: 0.7832\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4598 - acc: 0.7817\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4703 - acc: 0.7759\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4683 - acc: 0.7702\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4650 - acc: 0.7769\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4640 - acc: 0.7779\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4616 - acc: 0.7779\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4680 - acc: 0.7783\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4677 - acc: 0.7748\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4653 - acc: 0.7796\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4627 - acc: 0.7791\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4613 - acc: 0.7805\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4778 - acc: 0.7755\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4762 - acc: 0.7764\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4753 - acc: 0.7764\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4727 - acc: 0.7772\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4694 - acc: 0.7798\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4772 - acc: 0.7673\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4763 - acc: 0.7701\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4740 - acc: 0.7692\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4729 - acc: 0.7697\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4703 - acc: 0.7733\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4868 - acc: 0.7694\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4861 - acc: 0.7685\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4846 - acc: 0.7713\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4814 - acc: 0.7702\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4797 - acc: 0.7711\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4688 - acc: 0.7805\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4687 - acc: 0.7806\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4670 - acc: 0.7806\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4650 - acc: 0.7829\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4627 - acc: 0.7830\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4658 - acc: 0.7827\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4655 - acc: 0.7798\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4633 - acc: 0.7849\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4607 - acc: 0.7852\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4585 - acc: 0.7881\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4651 - acc: 0.7806\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4640 - acc: 0.7817\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4623 - acc: 0.7818\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4593 - acc: 0.7817\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4563 - acc: 0.7815\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4746 - acc: 0.7673\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4741 - acc: 0.7667\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4734 - acc: 0.7696\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4697 - acc: 0.7704\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4658 - acc: 0.7723\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4674 - acc: 0.7777\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4662 - acc: 0.7810\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4646 - acc: 0.7820\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4621 - acc: 0.7832\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4589 - acc: 0.7839\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4762 - acc: 0.7738\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4753 - acc: 0.7682\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4717 - acc: 0.7740\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4692 - acc: 0.7754\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4678 - acc: 0.7718\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4594 - acc: 0.7856\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4561 - acc: 0.7868\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4541 - acc: 0.7893\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4535 - acc: 0.7893\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4495 - acc: 0.7924\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4632 - acc: 0.7789\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4617 - acc: 0.7813\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4600 - acc: 0.7805\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4588 - acc: 0.7823\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4560 - acc: 0.7852\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4743 - acc: 0.7745\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4726 - acc: 0.7733\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4708 - acc: 0.7774\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4693 - acc: 0.7781\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4669 - acc: 0.7800\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4618 - acc: 0.7840\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4601 - acc: 0.7818\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4582 - acc: 0.7808\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4573 - acc: 0.7839\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4550 - acc: 0.7847\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4630 - acc: 0.7788\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4620 - acc: 0.7764\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4586 - acc: 0.7788\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4567 - acc: 0.7793\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4543 - acc: 0.7801\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4760 - acc: 0.7716\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4754 - acc: 0.7733\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4733 - acc: 0.7735\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4715 - acc: 0.7762\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4696 - acc: 0.7718\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4639 - acc: 0.7868\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4621 - acc: 0.7852\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4613 - acc: 0.7856\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4592 - acc: 0.7878\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4563 - acc: 0.7902\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4698 - acc: 0.7730\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4687 - acc: 0.7738\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4669 - acc: 0.7771\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4647 - acc: 0.7777\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4621 - acc: 0.7796\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4642 - acc: 0.7822\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4628 - acc: 0.7815\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4599 - acc: 0.7849\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4589 - acc: 0.7878\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4567 - acc: 0.7788\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4507 - acc: 0.7871\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4489 - acc: 0.7888\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4475 - acc: 0.7927\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4450 - acc: 0.7936\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4417 - acc: 0.7965\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4535 - acc: 0.7849\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4514 - acc: 0.7844\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4503 - acc: 0.7858\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4503 - acc: 0.7856\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4526 - acc: 0.7846\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5020 - acc: 0.7581\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.5030 - acc: 0.7592\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4669 - acc: 0.7731\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4835 - acc: 0.7697\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4600 - acc: 0.7754\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4920 - acc: 0.7549\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4741 - acc: 0.7709\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4851 - acc: 0.7660\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4709 - acc: 0.7725\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4792 - acc: 0.7680\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4756 - acc: 0.7754\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4825 - acc: 0.7713\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4781 - acc: 0.7735\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4752 - acc: 0.7743\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4701 - acc: 0.7776\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4592 - acc: 0.7781\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4620 - acc: 0.7777\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4631 - acc: 0.7755\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4573 - acc: 0.7801\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4511 - acc: 0.7852\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4717 - acc: 0.7765\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4709 - acc: 0.7771\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4714 - acc: 0.7777\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4693 - acc: 0.7788\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4664 - acc: 0.7815\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4575 - acc: 0.7794\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4550 - acc: 0.7803\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4532 - acc: 0.7825\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4523 - acc: 0.7846\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4490 - acc: 0.7868\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4596 - acc: 0.7806\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4594 - acc: 0.7764\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4569 - acc: 0.7776\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4569 - acc: 0.7786\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4545 - acc: 0.7813\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4729 - acc: 0.7725\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4710 - acc: 0.7750\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4696 - acc: 0.7781\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4670 - acc: 0.7791\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4647 - acc: 0.7811\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4603 - acc: 0.7794\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4601 - acc: 0.7786\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4584 - acc: 0.7818\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4569 - acc: 0.7840\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4541 - acc: 0.7830\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4536 - acc: 0.7859\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4528 - acc: 0.7863\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4500 - acc: 0.7876\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4486 - acc: 0.7907\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4452 - acc: 0.7905\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4494 - acc: 0.7888\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4488 - acc: 0.7909\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4464 - acc: 0.7917\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4446 - acc: 0.7931\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4425 - acc: 0.7950\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4578 - acc: 0.7858\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4556 - acc: 0.7876\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4545 - acc: 0.7892\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4526 - acc: 0.7866\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.4491 - acc: 0.7902\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnfE8GAOl1hO",
        "colab_type": "text"
      },
      "source": [
        "###Validating the model\n",
        "####To measure the performance and verify our model, lets import the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdMASdpvXrE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import validation data\n",
        "labelsValidationDf=pd.read_csv('data/labels_validation.txt', sep=',',header=None)\n",
        "dataValidationDf=pd.read_csv('data/inserts_validation.txt', sep=',',header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyfPhpTpmJH4",
        "colab_type": "text"
      },
      "source": [
        "####Lets inspect the size of our validation labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eY2zctmYMDD",
        "colab_type": "code",
        "outputId": "36e5c5b2-f177-47ab-996c-d665fb659f45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#verify the length of validation set labels\n",
        "len(labelsValidationDf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "177482"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id8bfVrmmT8O",
        "colab_type": "text"
      },
      "source": [
        "####Lets inspect the size of validation data and confirm that it is of same size as the validation set labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofRASI86YOpm",
        "colab_type": "code",
        "outputId": "39f5bbd5-0fc6-4b19-9ded-f78ddb7eaddf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#verify the length of validation set data\n",
        "len(dataValidationDf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "177482"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI7hmx1smjHe",
        "colab_type": "text"
      },
      "source": [
        "####Lets define a batch set generator for our validation data, this time without splitting the dataset into smaller chunks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y-tvZ1nYBPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define a generator to reshape our dataset and zip it to be more manageable\n",
        "validationSetSize=len(labelsValidationDf)\n",
        "def geneneratorValidation():\n",
        "        npArr = np.array(dataValidationDf.values)\n",
        "        yield npArr.reshape([validationSetSize,4,200,-1]), labelsValidationDf\n",
        "#create a tensor for our validation dataset\n",
        "validation_dataset = tf.data.Dataset.from_generator(geneneratorValidation,output_shapes=([validationSetSize,4,200,1],[validationSetSize,1]),output_types=(tf.float32, tf.float32)) \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oil63k7Tm1mU",
        "colab_type": "text"
      },
      "source": [
        "####Define an iterator for the set so that we can use the set for evaluating our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiWey8IuZEGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validationData, validationLabels = next(iter(validation_dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Iny-S3snFJa",
        "colab_type": "text"
      },
      "source": [
        "####Validate our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fdy8I3qxZL4-",
        "colab_type": "code",
        "outputId": "a911c869-56b7-4a5a-fcb7-35a060a2c764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#Validate our model against validation data\n",
        "validation_loss, validation_accuracy = model.evaluate(validationData, validationLabels)\n",
        "print('Validation accuracy:', validation_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "177482/177482 [==============================] - 9s 52us/sample - loss: 0.4643 - acc: 0.7786\n",
            "Validation accuracy: 0.7786367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm12-G3BnPX4",
        "colab_type": "text"
      },
      "source": [
        "###Receiver Operating Characteristics (ROC)\n",
        "####We will calculate the ROC and the area under the curve (AUC) for a performance benchmark of our neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeZc0QXsNR4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get predictions on validation data\n",
        "prediction=model.predict(validationData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DuzXNaON36x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        " \n",
        "fpr , tpr , thresholds = roc_curve ( validationLabels , prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua-wyIU8N-Lt",
        "colab_type": "code",
        "outputId": "30c79742-1304-4b76-8a25-0b6143cacc72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "# Plot ROC Curve\n",
        "def plot_roc_curve(fpr,tpr): \n",
        "  plt.plot(fpr,tpr) \n",
        "  plt.axis([0,1,0,1]) \n",
        "  plt.xlabel('False Positive Rate') \n",
        "  plt.ylabel('True Positive Rate') \n",
        "  plt.show()    \n",
        "  \n",
        "plot_roc_curve (fpr,tpr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFCIi0q3/D+R+MnK1jXnwAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FuUIxJSONas",
        "colab_type": "code",
        "outputId": "8c78a6b6-747b-4b95-bfac-175488671ace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "auc_score=roc_auc_score(validationLabels,prediction)\n",
        "print('AUC:',auc_score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.8612403503049895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKC6clC4NWaH",
        "colab_type": "text"
      },
      "source": [
        "###Are there any patterns discovered by the network?\n",
        "####Lets examine if there are patterns by comparing the true/false integration datasets. We can do this by comparing the datasets of correctly predicted true/false predictions. We will do this by comparing the relative differences in frequencies of nucleotides in the datasets.\n",
        "####We will install biopython to help us compare the datasets and sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDEXb0VpRqwS",
        "colab_type": "code",
        "outputId": "4efab17d-6927-4bf8-e114-adc59ca9be7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "#Lets determine a consensus sequence for correct our correct predictions\n",
        "#For this we need to install biopython\n",
        "!pip install biopython\n",
        "import Bio\n",
        "print(Bio.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting biopython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/3d/e0c8a993dbea1136be90c31345aefc5babdd5046cd52f81c18fc3fdad865/biopython-1.76-cp36-cp36m-manylinux1_x86_64.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from biopython) (1.17.4)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.76\n",
            "1.76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpw6pQhKOc9v",
        "colab_type": "text"
      },
      "source": [
        "####Parse the DNA strings from which our one-hot encoded validation data was generated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "op50f2IsVJpD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lets parse the DNA strings for our validation data\n",
        "dnaValidation=pd.read_csv('data/DNAString_validation.txt', sep=',',header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLGiAVChOwRh",
        "colab_type": "text"
      },
      "source": [
        "####Add all correct predictions of true HIV integration events into a single dataset of DNA sequences\n",
        "#####We will ignore the sequences that contain random nucleotides 'N' as these correspond to any random nucleotide and cannot be used in biopython for sequence analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgHxHwZMSFdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add the DNA Sequences of correctly predicted true integration events into a list\n",
        "#Following http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc214\n",
        "from Bio.Seq import Seq\n",
        "dnaSequences = []\n",
        "for predIndex in range(prediction.size):\n",
        "  if (prediction[predIndex] >= 0.5 and validationLabels[predIndex].numpy()[0] == 1):\n",
        "    dnaString = dnaValidation[0][predIndex].upper()\n",
        "    #Ignore predictions performed on sequences containing random nucleotides as biopython does not handle these ->\n",
        "    if (\"N\" in dnaString): continue \n",
        "    dnaSequences.append(Seq(dnaString))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHDlUzizPsM8",
        "colab_type": "text"
      },
      "source": [
        "####Lets examine the proportion true integration events taken into consideration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD7tOHu9geZk",
        "colab_type": "code",
        "outputId": "82b9e9bc-e203-453f-e579-598569eebf0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Lets calculate the percentage of correct predictions of true integrations not containing random nucleotides \n",
        "#We divide validationLabels/2 since the validation set contains equal proportions of true/false events\n",
        "len(dnaSequences)/(validationLabels.shape[0].value/2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7945707170304595"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlC6vdI3P84L",
        "colab_type": "text"
      },
      "source": [
        "####Lets create an motif from the dataset for sequence analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vYPHPalZLlx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create a motif based on these sequences\n",
        "from Bio import motifs\n",
        "motifCorrectPredictions = motifs.create(dnaSequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLmvD8vNQM0i",
        "colab_type": "text"
      },
      "source": [
        "####Lets examine the consensus sequence of these correctly predicted true integrations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dKtTMlXcxYd",
        "colab_type": "code",
        "outputId": "f7e319de-2c87-49be-c930-4d7fea0fe35b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "#Get the consenus sequence for the correct predictions\n",
        "print(motifCorrectPredictions.consensus)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ATTTTTATTTTTATATATATTTTTATATTAATAAATTTATTATTTTTTTAATTAATTTTTTTAAATTTTATAAATTTATTTATTAAAATATTTTATTTGGTAACCAAATAAAATATTTTATTAAATAAATTTATAAAATTTAAATAAATTAATTAAAAAAATAATTAATTATTAATTTTTAATAATTTTATTATAATAAA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kq2mUKEvSYJR",
        "colab_type": "text"
      },
      "source": [
        "####When examining the above consenus sequence, wee see that there is a high rate of (A)denine and (T)hymine throughout the length of the consensus sequence except in the middle. This is the position of HIV integration site. The HIV integration site contains a relative high frequency of (G)uanine and (C)ytosine compared to other positions in the DNA, the high occurrences of (G)uanine occurs right before the HIV integration position (at 100 bp) wheras (C)ytosine occurs a few bp after the integration site.\n",
        "####Below we print out the index position where the high frequency of (G)uanine and (C)ytosine occurs, we have also marked the nucleotides at these positions in red."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDW7nTqNQzQY",
        "colab_type": "code",
        "outputId": "147cfb0e-693d-46ff-cbdf-7c000fac067c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "#Lets highlight the high occurrences of (G)uanine and (C)ytosine in red and reveal their positions\n",
        "print('The position of first guanine nucleotide is at position:', str(motifCorrectPredictions.consensus).index(\"G\"))\n",
        "print('The position of first cytosine nucleotide is at position:', str(motifCorrectPredictions.consensus).index(\"C\"))\n",
        "print(str(motifCorrectPredictions.consensus).replace(\"GG\",\"\\033[1;31mGG\\x1b[0m\").replace(\"CC\",\"\\033[1;31mCC\\x1b[0m\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The position of first guanine nucleotide is at position: 98\n",
            "The position of first cytosine nucleotide is at position: 103\n",
            "ATTTTTATTTTTATATATATTTTTATATTAATAAATTTATTATTTTTTTAATTAATTTTTTTAAATTTTATAAATTTATTTATTAAAATATTTTATTT\u001b[1;31mGG\u001b[0mTAA\u001b[1;31mCC\u001b[0mAAATAAAATATTTTATTAAATAAATTTATAAAATTTAAATAAATTAATTAAAAAAATAATTAATTATTAATTTTTAATAATTTTATTATAATAAA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq_DpzK9W9se",
        "colab_type": "text"
      },
      "source": [
        "####Lets compare the above consensus sequence with correctly predicted false integration sites (sites with randomly sampled DNA from the GRCh37/hg19 genome)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5UhNPjGa5kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets now predict the consensus sequence for correctly predicted false integration events\n",
        "# Add the DNA Sequences of correctly predicted false integration events into a list\n",
        "dnaFalseSequences = []\n",
        "for predIndex in range(prediction.size):\n",
        "  if (prediction[predIndex] < 0.5 and validationLabels[predIndex].numpy()[0] == 0):\n",
        "    dnaString = dnaValidation[0][predIndex].upper()\n",
        "    if (\"N\" in dnaString): continue \n",
        "    dnaFalseSequences.append(Seq(dnaString))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKQe44geXzP8",
        "colab_type": "text"
      },
      "source": [
        "####Lets examine the proportion of false integration events we have taken into consideration for this analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2htR9APYaWe",
        "colab_type": "code",
        "outputId": "ea940deb-9154-4047-ea13-ef3680324864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Lets calculate the proportion of correctly predicted false integration events that do not contain random nucelotides\n",
        "len(dnaFalseSequences)/(validationLabels.shape[0].value/2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.657001836805986"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tKIJPQ2YNwT",
        "colab_type": "text"
      },
      "source": [
        "####Lets generate a similar consensus sequence for false integration events"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkM5-5z0jAH5",
        "colab_type": "code",
        "outputId": "e8ff2c62-222a-4da1-8eb1-0efb0ea37025",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "#Get the consenus sequence for the correct predictions of false integrations\n",
        "motifFalseCorrectPredictions = motifs.create(dnaFalseSequences)\n",
        "print(motifFalseCorrectPredictions.consensus)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ATTTTTATATATATAATATTAATAAAAAAATAAATAAAAAATAAAATTTTAAAAAAAAAAAAATAATAAAATTTAAAATAAAAATTTAAATAATTAAATTATTAATTTAATTTTTTAATTTATTAATTTATTATTTATAAATTAATTATAATAATTATTTTTTTAATTTATATTAAAATTTTTTTTTTAATTTAATAAAT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dbkavYkZT21",
        "colab_type": "text"
      },
      "source": [
        "####Above we see that there are no similar inconsistencies regarding the sudden large relative occurance of (G)uanine in the correctly predicted false integration data.\n",
        "####Lets examine if there are more differences between these two sets by looking at the relative frequencies of the different nucleotides. We will compare these relative frequencies of nucleotides by substracing the total counts of nucleotides of correctly predicted false integration events from the dataset of correctly predicted true integration events ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_7XS_-vWbpx",
        "colab_type": "code",
        "outputId": "90cc40d8-dd5d-4e17-c327-ea4e130bb580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        }
      },
      "source": [
        "'''\n",
        "Lets compare differences in occurrences of nucleotides in correctly predicted true \n",
        "integrations events compared to correctly predicted false integration events to see\n",
        "if there is a pattern in the relative frequencies of nucleotides at different positions\n",
        "'''\n",
        "from IPython.display import HTML, display\n",
        "import tabulate\n",
        "from operator import sub\n",
        "diffA = [\"Diff. A\"]\n",
        "diffA.extend(map(sub, motifCorrectPredictions.counts[0], motifFalseCorrectPredictions.counts[0]))\n",
        "diffC = [\"Diff. C\"]\n",
        "diffC.extend(map(sub, motifCorrectPredictions.counts[1], motifFalseCorrectPredictions.counts[1]))\n",
        "diffG = [\"Diff. G\"]\n",
        "diffG.extend(map(sub, motifCorrectPredictions.counts[2], motifFalseCorrectPredictions.counts[2]))\n",
        "diffT = [\"Diff. T\"]\n",
        "diffT.extend(map(sub, motifCorrectPredictions.counts[3], motifFalseCorrectPredictions.counts[3]))\n",
        "\n",
        "table = [diffA,diffC,diffG, diffT]\n",
        "display(HTML(tabulate.tabulate(table, tablefmt='html')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table>\n",
              "<tbody>\n",
              "<tr><td>Diff. A</td><td style=\"text-align: right;\">4950</td><td style=\"text-align: right;\">4497</td><td style=\"text-align: right;\">4228</td><td style=\"text-align: right;\">3733</td><td style=\"text-align: right;\">3700</td><td style=\"text-align: right;\">4102</td><td style=\"text-align: right;\">4233</td><td style=\"text-align: right;\">4489</td><td style=\"text-align: right;\">4020</td><td style=\"text-align: right;\">4786</td><td style=\"text-align: right;\">4622</td><td style=\"text-align: right;\">4475</td><td style=\"text-align: right;\">4086</td><td style=\"text-align: right;\">3971</td><td style=\"text-align: right;\">4689</td><td style=\"text-align: right;\">3967</td><td style=\"text-align: right;\">5276</td><td style=\"text-align: right;\">5003</td><td style=\"text-align: right;\">5157</td><td style=\"text-align: right;\">4321</td><td style=\"text-align: right;\">3903</td><td style=\"text-align: right;\">3970</td><td style=\"text-align: right;\">4426</td><td style=\"text-align: right;\">4069</td><td style=\"text-align: right;\">4636</td><td style=\"text-align: right;\">3953</td><td style=\"text-align: right;\">4122</td><td style=\"text-align: right;\">4090</td><td style=\"text-align: right;\">4621</td><td style=\"text-align: right;\">5558</td><td style=\"text-align: right;\">4792</td><td style=\"text-align: right;\">4088</td><td style=\"text-align: right;\">3844</td><td style=\"text-align: right;\">4668</td><td style=\"text-align: right;\">4277</td><td style=\"text-align: right;\">3944</td><td style=\"text-align: right;\">3929</td><td style=\"text-align: right;\">4409</td><td style=\"text-align: right;\">5104</td><td style=\"text-align: right;\">4752</td><td style=\"text-align: right;\">4401</td><td style=\"text-align: right;\">4935</td><td style=\"text-align: right;\">3606</td><td style=\"text-align: right;\">3544</td><td style=\"text-align: right;\">4041</td><td style=\"text-align: right;\">3374</td><td style=\"text-align: right;\">4155</td><td style=\"text-align: right;\">3277</td><td style=\"text-align: right;\">4073</td><td style=\"text-align: right;\">5940</td><td style=\"text-align: right;\">5859</td><td style=\"text-align: right;\">4120</td><td style=\"text-align: right;\">3844</td><td style=\"text-align: right;\">4891</td><td style=\"text-align: right;\">5028</td><td style=\"text-align: right;\">4580</td><td style=\"text-align: right;\">4865</td><td style=\"text-align: right;\">3258</td><td style=\"text-align: right;\">4033</td><td style=\"text-align: right;\">3777</td><td style=\"text-align: right;\">2778</td><td style=\"text-align: right;\">4157</td><td style=\"text-align: right;\">5366</td><td style=\"text-align: right;\">5587</td><td style=\"text-align: right;\">3953</td><td style=\"text-align: right;\">3571</td><td style=\"text-align: right;\">3738</td><td style=\"text-align: right;\">4231</td><td style=\"text-align: right;\">3427</td><td style=\"text-align: right;\">4958</td><td style=\"text-align: right;\">3770</td><td style=\"text-align: right;\">4422</td><td style=\"text-align: right;\">5679</td><td style=\"text-align: right;\">6214</td><td style=\"text-align: right;\">2585</td><td style=\"text-align: right;\">2028</td><td style=\"text-align: right;\">2397</td><td style=\"text-align: right;\">5091</td><td style=\"text-align: right;\">5202</td><td style=\"text-align: right;\">5067</td><td style=\"text-align: right;\">1608</td><td style=\"text-align: right;\">5703</td><td style=\"text-align: right;\">3417</td><td style=\"text-align: right;\">3064</td><td style=\"text-align: right;\">5323</td><td style=\"text-align: right;\">5637</td><td style=\"text-align: right;\">7663</td><td style=\"text-align: right;\">5824</td><td style=\"text-align: right;\">3528</td><td style=\"text-align: right;\"> 8497</td><td style=\"text-align: right;\">2561</td><td style=\"text-align: right;\"> 596</td><td style=\"text-align: right;\">2336</td><td style=\"text-align: right;\">2482</td><td style=\"text-align: right;\">4755</td><td style=\"text-align: right;\">-2240</td><td style=\"text-align: right;\">-6180</td><td style=\"text-align: right;\"> 3303</td><td style=\"text-align: right;\"> 3352</td><td style=\"text-align: right;\"> -2006</td><td style=\"text-align: right;\"> 1250</td><td style=\"text-align: right;\"> 8375</td><td style=\"text-align: right;\">16081</td><td style=\"text-align: right;\">-13277</td><td style=\"text-align: right;\">-4259</td><td style=\"text-align: right;\"> 8306</td><td style=\"text-align: right;\">18987</td><td style=\"text-align: right;\"> 6396</td><td style=\"text-align: right;\">3144</td><td style=\"text-align: right;\">3031</td><td style=\"text-align: right;\">3575</td><td style=\"text-align: right;\">3979</td><td style=\"text-align: right;\">7415</td><td style=\"text-align: right;\"> 6315</td><td style=\"text-align: right;\">7969</td><td style=\"text-align: right;\">4185</td><td style=\"text-align: right;\"> 440</td><td style=\"text-align: right;\"> 632</td><td style=\"text-align: right;\">3184</td><td style=\"text-align: right;\">3601</td><td style=\"text-align: right;\">3943</td><td style=\"text-align: right;\">2327</td><td style=\"text-align: right;\">9684</td><td style=\"text-align: right;\">6894</td><td style=\"text-align: right;\">5289</td><td style=\"text-align: right;\">4307</td><td style=\"text-align: right;\">4640</td><td style=\"text-align: right;\">5416</td><td style=\"text-align: right;\">5815</td><td style=\"text-align: right;\">5779</td><td style=\"text-align: right;\">4473</td><td style=\"text-align: right;\">3383</td><td style=\"text-align: right;\">4853</td><td style=\"text-align: right;\">4418</td><td style=\"text-align: right;\">6337</td><td style=\"text-align: right;\">4867</td><td style=\"text-align: right;\">5414</td><td style=\"text-align: right;\">5687</td><td style=\"text-align: right;\">3584</td><td style=\"text-align: right;\">2817</td><td style=\"text-align: right;\">4009</td><td style=\"text-align: right;\">4910</td><td style=\"text-align: right;\">5608</td><td style=\"text-align: right;\">4068</td><td style=\"text-align: right;\">4014</td><td style=\"text-align: right;\">4999</td><td style=\"text-align: right;\">6693</td><td style=\"text-align: right;\">5485</td><td style=\"text-align: right;\">2921</td><td style=\"text-align: right;\">4658</td><td style=\"text-align: right;\">4718</td><td style=\"text-align: right;\">5300</td><td style=\"text-align: right;\">4649</td><td style=\"text-align: right;\">4064</td><td style=\"text-align: right;\">4509</td><td style=\"text-align: right;\">5512</td><td style=\"text-align: right;\">4239</td><td style=\"text-align: right;\">5135</td><td style=\"text-align: right;\">4769</td><td style=\"text-align: right;\">5394</td><td style=\"text-align: right;\">5670</td><td style=\"text-align: right;\">4537</td><td style=\"text-align: right;\">4854</td><td style=\"text-align: right;\">5232</td><td style=\"text-align: right;\">4055</td><td style=\"text-align: right;\">4666</td><td style=\"text-align: right;\">5044</td><td style=\"text-align: right;\">4859</td><td style=\"text-align: right;\">4015</td><td style=\"text-align: right;\">4183</td><td style=\"text-align: right;\">4039</td><td style=\"text-align: right;\">3932</td><td style=\"text-align: right;\">4637</td><td style=\"text-align: right;\">5828</td><td style=\"text-align: right;\">5452</td><td style=\"text-align: right;\">4075</td><td style=\"text-align: right;\">3761</td><td style=\"text-align: right;\">3981</td><td style=\"text-align: right;\">4030</td><td style=\"text-align: right;\">4295</td><td style=\"text-align: right;\">5671</td><td style=\"text-align: right;\">5586</td><td style=\"text-align: right;\">4605</td><td style=\"text-align: right;\">4983</td><td style=\"text-align: right;\">5192</td><td style=\"text-align: right;\">5503</td><td style=\"text-align: right;\">4808</td><td style=\"text-align: right;\">4396</td><td style=\"text-align: right;\">3849</td><td style=\"text-align: right;\">4229</td><td style=\"text-align: right;\">4261</td><td style=\"text-align: right;\">4672</td><td style=\"text-align: right;\">5193</td><td style=\"text-align: right;\">4682</td><td style=\"text-align: right;\">5397</td><td style=\"text-align: right;\">5241</td><td style=\"text-align: right;\">3848</td><td style=\"text-align: right;\">4177</td><td style=\"text-align: right;\">3923</td><td style=\"text-align: right;\">4447</td></tr>\n",
              "<tr><td>Diff. C</td><td style=\"text-align: right;\">1359</td><td style=\"text-align: right;\">1432</td><td style=\"text-align: right;\">1881</td><td style=\"text-align: right;\">2082</td><td style=\"text-align: right;\">2728</td><td style=\"text-align: right;\">2256</td><td style=\"text-align: right;\">1835</td><td style=\"text-align: right;\">1142</td><td style=\"text-align: right;\">1205</td><td style=\"text-align: right;\">1283</td><td style=\"text-align: right;\">1649</td><td style=\"text-align: right;\">1592</td><td style=\"text-align: right;\">2043</td><td style=\"text-align: right;\">2197</td><td style=\"text-align: right;\">1191</td><td style=\"text-align: right;\">1532</td><td style=\"text-align: right;\"> 648</td><td style=\"text-align: right;\"> 907</td><td style=\"text-align: right;\">1380</td><td style=\"text-align: right;\">1757</td><td style=\"text-align: right;\">1442</td><td style=\"text-align: right;\">1246</td><td style=\"text-align: right;\"> 637</td><td style=\"text-align: right;\">2013</td><td style=\"text-align: right;\">1701</td><td style=\"text-align: right;\">1778</td><td style=\"text-align: right;\">2208</td><td style=\"text-align: right;\">2908</td><td style=\"text-align: right;\">1237</td><td style=\"text-align: right;\"> 409</td><td style=\"text-align: right;\"> 689</td><td style=\"text-align: right;\">1339</td><td style=\"text-align: right;\">2303</td><td style=\"text-align: right;\">1423</td><td style=\"text-align: right;\">1570</td><td style=\"text-align: right;\">1689</td><td style=\"text-align: right;\">1925</td><td style=\"text-align: right;\">1493</td><td style=\"text-align: right;\">1453</td><td style=\"text-align: right;\"> 850</td><td style=\"text-align: right;\">1000</td><td style=\"text-align: right;\"> 619</td><td style=\"text-align: right;\">1804</td><td style=\"text-align: right;\">1408</td><td style=\"text-align: right;\">1259</td><td style=\"text-align: right;\">1812</td><td style=\"text-align: right;\">1579</td><td style=\"text-align: right;\">2106</td><td style=\"text-align: right;\">1724</td><td style=\"text-align: right;\"> 818</td><td style=\"text-align: right;\"> -65</td><td style=\"text-align: right;\">1131</td><td style=\"text-align: right;\">1667</td><td style=\"text-align: right;\"> -13</td><td style=\"text-align: right;\"> 485</td><td style=\"text-align: right;\">1282</td><td style=\"text-align: right;\"> 813</td><td style=\"text-align: right;\">1144</td><td style=\"text-align: right;\">1622</td><td style=\"text-align: right;\">1711</td><td style=\"text-align: right;\">2503</td><td style=\"text-align: right;\">1940</td><td style=\"text-align: right;\">1670</td><td style=\"text-align: right;\"> 696</td><td style=\"text-align: right;\">1620</td><td style=\"text-align: right;\">1447</td><td style=\"text-align: right;\">2135</td><td style=\"text-align: right;\">1871</td><td style=\"text-align: right;\"> 908</td><td style=\"text-align: right;\">1519</td><td style=\"text-align: right;\">2368</td><td style=\"text-align: right;\">2158</td><td style=\"text-align: right;\"> 566</td><td style=\"text-align: right;\">-706</td><td style=\"text-align: right;\">1502</td><td style=\"text-align: right;\">2956</td><td style=\"text-align: right;\">4458</td><td style=\"text-align: right;\">2097</td><td style=\"text-align: right;\"> 307</td><td style=\"text-align: right;\"> 811</td><td style=\"text-align: right;\"> 845</td><td style=\"text-align: right;\">1460</td><td style=\"text-align: right;\">1727</td><td style=\"text-align: right;\">3302</td><td style=\"text-align: right;\">  58</td><td style=\"text-align: right;\">1933</td><td style=\"text-align: right;\">1376</td><td style=\"text-align: right;\">  44</td><td style=\"text-align: right;\"> 305</td><td style=\"text-align: right;\"> -851</td><td style=\"text-align: right;\">2255</td><td style=\"text-align: right;\">5339</td><td style=\"text-align: right;\"> 970</td><td style=\"text-align: right;\">1108</td><td style=\"text-align: right;\"> 936</td><td style=\"text-align: right;\"> 5620</td><td style=\"text-align: right;\">-2950</td><td style=\"text-align: right;\">-5875</td><td style=\"text-align: right;\">-1737</td><td style=\"text-align: right;\">  6373</td><td style=\"text-align: right;\">-1864</td><td style=\"text-align: right;\">-2150</td><td style=\"text-align: right;\">-2554</td><td style=\"text-align: right;\"> 21777</td><td style=\"text-align: right;\">15821</td><td style=\"text-align: right;\"> 7438</td><td style=\"text-align: right;\"> 2726</td><td style=\"text-align: right;\"> 2685</td><td style=\"text-align: right;\">3647</td><td style=\"text-align: right;\">5431</td><td style=\"text-align: right;\">5210</td><td style=\"text-align: right;\">2704</td><td style=\"text-align: right;\"> 276</td><td style=\"text-align: right;\">-1660</td><td style=\"text-align: right;\"> 509</td><td style=\"text-align: right;\">2462</td><td style=\"text-align: right;\">2711</td><td style=\"text-align: right;\">4490</td><td style=\"text-align: right;\">3938</td><td style=\"text-align: right;\">1953</td><td style=\"text-align: right;\">2941</td><td style=\"text-align: right;\">2754</td><td style=\"text-align: right;\"> 612</td><td style=\"text-align: right;\">-128</td><td style=\"text-align: right;\">1478</td><td style=\"text-align: right;\"> 491</td><td style=\"text-align: right;\"> 286</td><td style=\"text-align: right;\">2205</td><td style=\"text-align: right;\">2767</td><td style=\"text-align: right;\"> 968</td><td style=\"text-align: right;\">1834</td><td style=\"text-align: right;\">2581</td><td style=\"text-align: right;\"> 886</td><td style=\"text-align: right;\">1162</td><td style=\"text-align: right;\">1540</td><td style=\"text-align: right;\">1117</td><td style=\"text-align: right;\"> 971</td><td style=\"text-align: right;\">1479</td><td style=\"text-align: right;\">2732</td><td style=\"text-align: right;\">2942</td><td style=\"text-align: right;\"> 914</td><td style=\"text-align: right;\">1543</td><td style=\"text-align: right;\">1354</td><td style=\"text-align: right;\">2504</td><td style=\"text-align: right;\">2312</td><td style=\"text-align: right;\">2397</td><td style=\"text-align: right;\"> 162</td><td style=\"text-align: right;\">1050</td><td style=\"text-align: right;\">3397</td><td style=\"text-align: right;\">2086</td><td style=\"text-align: right;\">1648</td><td style=\"text-align: right;\">1128</td><td style=\"text-align: right;\">1283</td><td style=\"text-align: right;\">1489</td><td style=\"text-align: right;\">1767</td><td style=\"text-align: right;\">1558</td><td style=\"text-align: right;\">2202</td><td style=\"text-align: right;\">1623</td><td style=\"text-align: right;\">2140</td><td style=\"text-align: right;\">1867</td><td style=\"text-align: right;\"> 863</td><td style=\"text-align: right;\">2051</td><td style=\"text-align: right;\">1747</td><td style=\"text-align: right;\">1478</td><td style=\"text-align: right;\">1656</td><td style=\"text-align: right;\">1127</td><td style=\"text-align: right;\">1271</td><td style=\"text-align: right;\">1697</td><td style=\"text-align: right;\">2281</td><td style=\"text-align: right;\">1711</td><td style=\"text-align: right;\">2069</td><td style=\"text-align: right;\">2588</td><td style=\"text-align: right;\">2181</td><td style=\"text-align: right;\"> 790</td><td style=\"text-align: right;\"> 540</td><td style=\"text-align: right;\"> 883</td><td style=\"text-align: right;\">1857</td><td style=\"text-align: right;\">2138</td><td style=\"text-align: right;\">1983</td><td style=\"text-align: right;\">1792</td><td style=\"text-align: right;\">1390</td><td style=\"text-align: right;\">1313</td><td style=\"text-align: right;\">1827</td><td style=\"text-align: right;\">1340</td><td style=\"text-align: right;\"> 741</td><td style=\"text-align: right;\"> 664</td><td style=\"text-align: right;\">1435</td><td style=\"text-align: right;\">1986</td><td style=\"text-align: right;\">1633</td><td style=\"text-align: right;\">1672</td><td style=\"text-align: right;\">1882</td><td style=\"text-align: right;\">1462</td><td style=\"text-align: right;\"> 833</td><td style=\"text-align: right;\"> 981</td><td style=\"text-align: right;\">1228</td><td style=\"text-align: right;\">1186</td><td style=\"text-align: right;\">1506</td><td style=\"text-align: right;\">1661</td><td style=\"text-align: right;\">1842</td><td style=\"text-align: right;\">1660</td></tr>\n",
              "<tr><td>Diff. G</td><td style=\"text-align: right;\">1162</td><td style=\"text-align: right;\">1536</td><td style=\"text-align: right;\">1708</td><td style=\"text-align: right;\">2092</td><td style=\"text-align: right;\">1585</td><td style=\"text-align: right;\">1584</td><td style=\"text-align: right;\">1573</td><td style=\"text-align: right;\">1378</td><td style=\"text-align: right;\">1274</td><td style=\"text-align: right;\">1124</td><td style=\"text-align: right;\">1069</td><td style=\"text-align: right;\">1466</td><td style=\"text-align: right;\">1749</td><td style=\"text-align: right;\">1998</td><td style=\"text-align: right;\">1947</td><td style=\"text-align: right;\">2320</td><td style=\"text-align: right;\">1542</td><td style=\"text-align: right;\"> 872</td><td style=\"text-align: right;\"> 799</td><td style=\"text-align: right;\">1499</td><td style=\"text-align: right;\">2351</td><td style=\"text-align: right;\">1494</td><td style=\"text-align: right;\">1574</td><td style=\"text-align: right;\">1743</td><td style=\"text-align: right;\">1921</td><td style=\"text-align: right;\">2134</td><td style=\"text-align: right;\">1962</td><td style=\"text-align: right;\"> 971</td><td style=\"text-align: right;\"> 663</td><td style=\"text-align: right;\"> 807</td><td style=\"text-align: right;\">2330</td><td style=\"text-align: right;\">2426</td><td style=\"text-align: right;\">2287</td><td style=\"text-align: right;\">1595</td><td style=\"text-align: right;\">2311</td><td style=\"text-align: right;\">1703</td><td style=\"text-align: right;\">1016</td><td style=\"text-align: right;\">1265</td><td style=\"text-align: right;\">1543</td><td style=\"text-align: right;\">1256</td><td style=\"text-align: right;\">1924</td><td style=\"text-align: right;\">2324</td><td style=\"text-align: right;\">1121</td><td style=\"text-align: right;\">1884</td><td style=\"text-align: right;\">2062</td><td style=\"text-align: right;\">1838</td><td style=\"text-align: right;\">2215</td><td style=\"text-align: right;\">1618</td><td style=\"text-align: right;\">1992</td><td style=\"text-align: right;\">1284</td><td style=\"text-align: right;\">1541</td><td style=\"text-align: right;\">1603</td><td style=\"text-align: right;\">1337</td><td style=\"text-align: right;\">2391</td><td style=\"text-align: right;\">3844</td><td style=\"text-align: right;\"> 887</td><td style=\"text-align: right;\"> 101</td><td style=\"text-align: right;\">2869</td><td style=\"text-align: right;\">2055</td><td style=\"text-align: right;\">2335</td><td style=\"text-align: right;\">1475</td><td style=\"text-align: right;\">1454</td><td style=\"text-align: right;\">1171</td><td style=\"text-align: right;\">3006</td><td style=\"text-align: right;\">2820</td><td style=\"text-align: right;\">1404</td><td style=\"text-align: right;\">1000</td><td style=\"text-align: right;\"> 914</td><td style=\"text-align: right;\">1558</td><td style=\"text-align: right;\">1135</td><td style=\"text-align: right;\"> 988</td><td style=\"text-align: right;\">2585</td><td style=\"text-align: right;\">1511</td><td style=\"text-align: right;\">1133</td><td style=\"text-align: right;\">2457</td><td style=\"text-align: right;\">2007</td><td style=\"text-align: right;\"> 454</td><td style=\"text-align: right;\"> 475</td><td style=\"text-align: right;\">1451</td><td style=\"text-align: right;\">-318</td><td style=\"text-align: right;\"> 797</td><td style=\"text-align: right;\">2462</td><td style=\"text-align: right;\">3120</td><td style=\"text-align: right;\">2205</td><td style=\"text-align: right;\">3880</td><td style=\"text-align: right;\">4461</td><td style=\"text-align: right;\">2596</td><td style=\"text-align: right;\">2237</td><td style=\"text-align: right;\"> 372</td><td style=\"text-align: right;\">-2229</td><td style=\"text-align: right;\"> 116</td><td style=\"text-align: right;\">2401</td><td style=\"text-align: right;\">4907</td><td style=\"text-align: right;\">5123</td><td style=\"text-align: right;\">3550</td><td style=\"text-align: right;\"> 2437</td><td style=\"text-align: right;\"> 2315</td><td style=\"text-align: right;\"> 6827</td><td style=\"text-align: right;\">15596</td><td style=\"text-align: right;\"> 21302</td><td style=\"text-align: right;\">-2322</td><td style=\"text-align: right;\">-1889</td><td style=\"text-align: right;\">-1786</td><td style=\"text-align: right;\">  6142</td><td style=\"text-align: right;\">-2104</td><td style=\"text-align: right;\">-6200</td><td style=\"text-align: right;\">-3109</td><td style=\"text-align: right;\"> 5599</td><td style=\"text-align: right;\">1157</td><td style=\"text-align: right;\">1453</td><td style=\"text-align: right;\"> 970</td><td style=\"text-align: right;\">5026</td><td style=\"text-align: right;\">1948</td><td style=\"text-align: right;\">-1150</td><td style=\"text-align: right;\">  76</td><td style=\"text-align: right;\">-343</td><td style=\"text-align: right;\">1350</td><td style=\"text-align: right;\">1658</td><td style=\"text-align: right;\"> 385</td><td style=\"text-align: right;\">3793</td><td style=\"text-align: right;\">1514</td><td style=\"text-align: right;\">1359</td><td style=\"text-align: right;\"> 845</td><td style=\"text-align: right;\"> 553</td><td style=\"text-align: right;\"> 400</td><td style=\"text-align: right;\">2332</td><td style=\"text-align: right;\">4789</td><td style=\"text-align: right;\">2803</td><td style=\"text-align: right;\">1199</td><td style=\"text-align: right;\">-914</td><td style=\"text-align: right;\"> 419</td><td style=\"text-align: right;\">2194</td><td style=\"text-align: right;\">2132</td><td style=\"text-align: right;\">1513</td><td style=\"text-align: right;\"> 785</td><td style=\"text-align: right;\">1976</td><td style=\"text-align: right;\">2044</td><td style=\"text-align: right;\">1204</td><td style=\"text-align: right;\">1742</td><td style=\"text-align: right;\">1069</td><td style=\"text-align: right;\">1557</td><td style=\"text-align: right;\">1833</td><td style=\"text-align: right;\">2579</td><td style=\"text-align: right;\">1661</td><td style=\"text-align: right;\">1638</td><td style=\"text-align: right;\">1208</td><td style=\"text-align: right;\">1004</td><td style=\"text-align: right;\">1035</td><td style=\"text-align: right;\"> 551</td><td style=\"text-align: right;\"> 108</td><td style=\"text-align: right;\">1847</td><td style=\"text-align: right;\">1663</td><td style=\"text-align: right;\"> 164</td><td style=\"text-align: right;\"> 776</td><td style=\"text-align: right;\">2128</td><td style=\"text-align: right;\">1842</td><td style=\"text-align: right;\">1480</td><td style=\"text-align: right;\">2038</td><td style=\"text-align: right;\">1295</td><td style=\"text-align: right;\">1854</td><td style=\"text-align: right;\">1739</td><td style=\"text-align: right;\"> 723</td><td style=\"text-align: right;\">1028</td><td style=\"text-align: right;\"> 645</td><td style=\"text-align: right;\">1266</td><td style=\"text-align: right;\">1559</td><td style=\"text-align: right;\">1780</td><td style=\"text-align: right;\">1575</td><td style=\"text-align: right;\">1533</td><td style=\"text-align: right;\">1391</td><td style=\"text-align: right;\">2341</td><td style=\"text-align: right;\">1510</td><td style=\"text-align: right;\"> 492</td><td style=\"text-align: right;\"> 364</td><td style=\"text-align: right;\">1456</td><td style=\"text-align: right;\">2758</td><td style=\"text-align: right;\">2368</td><td style=\"text-align: right;\">1689</td><td style=\"text-align: right;\">1706</td><td style=\"text-align: right;\">1762</td><td style=\"text-align: right;\"> 965</td><td style=\"text-align: right;\">1005</td><td style=\"text-align: right;\">1232</td><td style=\"text-align: right;\">1533</td><td style=\"text-align: right;\">1328</td><td style=\"text-align: right;\"> 970</td><td style=\"text-align: right;\">1080</td><td style=\"text-align: right;\">1195</td><td style=\"text-align: right;\">1557</td><td style=\"text-align: right;\">2143</td><td style=\"text-align: right;\">1680</td><td style=\"text-align: right;\">1696</td><td style=\"text-align: right;\">1672</td><td style=\"text-align: right;\">1356</td><td style=\"text-align: right;\"> 959</td><td style=\"text-align: right;\">1334</td><td style=\"text-align: right;\">2045</td><td style=\"text-align: right;\">2327</td><td style=\"text-align: right;\">2671</td><td style=\"text-align: right;\">2377</td></tr>\n",
              "<tr><td>Diff. T</td><td style=\"text-align: right;\">4737</td><td style=\"text-align: right;\">4743</td><td style=\"text-align: right;\">4391</td><td style=\"text-align: right;\">4301</td><td style=\"text-align: right;\">4195</td><td style=\"text-align: right;\">4266</td><td style=\"text-align: right;\">4567</td><td style=\"text-align: right;\">5199</td><td style=\"text-align: right;\">5709</td><td style=\"text-align: right;\">5015</td><td style=\"text-align: right;\">4868</td><td style=\"text-align: right;\">4675</td><td style=\"text-align: right;\">4330</td><td style=\"text-align: right;\">4042</td><td style=\"text-align: right;\">4381</td><td style=\"text-align: right;\">4389</td><td style=\"text-align: right;\">4742</td><td style=\"text-align: right;\">5426</td><td style=\"text-align: right;\">4872</td><td style=\"text-align: right;\">4631</td><td style=\"text-align: right;\">4512</td><td style=\"text-align: right;\">5498</td><td style=\"text-align: right;\">5571</td><td style=\"text-align: right;\">4383</td><td style=\"text-align: right;\">3950</td><td style=\"text-align: right;\">4343</td><td style=\"text-align: right;\">3916</td><td style=\"text-align: right;\">4239</td><td style=\"text-align: right;\">5687</td><td style=\"text-align: right;\">5434</td><td style=\"text-align: right;\">4397</td><td style=\"text-align: right;\">4355</td><td style=\"text-align: right;\">3774</td><td style=\"text-align: right;\">4522</td><td style=\"text-align: right;\">4050</td><td style=\"text-align: right;\">4872</td><td style=\"text-align: right;\">5338</td><td style=\"text-align: right;\">5041</td><td style=\"text-align: right;\">4108</td><td style=\"text-align: right;\">5350</td><td style=\"text-align: right;\">4883</td><td style=\"text-align: right;\">4330</td><td style=\"text-align: right;\">5677</td><td style=\"text-align: right;\">5372</td><td style=\"text-align: right;\">4846</td><td style=\"text-align: right;\">5184</td><td style=\"text-align: right;\">4259</td><td style=\"text-align: right;\">5207</td><td style=\"text-align: right;\">4419</td><td style=\"text-align: right;\">4166</td><td style=\"text-align: right;\">4873</td><td style=\"text-align: right;\">5354</td><td style=\"text-align: right;\">5360</td><td style=\"text-align: right;\">4939</td><td style=\"text-align: right;\">2851</td><td style=\"text-align: right;\">5459</td><td style=\"text-align: right;\">6429</td><td style=\"text-align: right;\">4937</td><td style=\"text-align: right;\">4498</td><td style=\"text-align: right;\">4385</td><td style=\"text-align: right;\">5452</td><td style=\"text-align: right;\">4657</td><td style=\"text-align: right;\">4001</td><td style=\"text-align: right;\">2919</td><td style=\"text-align: right;\">3815</td><td style=\"text-align: right;\">5786</td><td style=\"text-align: right;\">5335</td><td style=\"text-align: right;\">5192</td><td style=\"text-align: right;\">6315</td><td style=\"text-align: right;\">4596</td><td style=\"text-align: right;\">5082</td><td style=\"text-align: right;\">3043</td><td style=\"text-align: right;\">4452</td><td style=\"text-align: right;\">5567</td><td style=\"text-align: right;\">5664</td><td style=\"text-align: right;\">5217</td><td style=\"text-align: right;\">4899</td><td style=\"text-align: right;\">4545</td><td style=\"text-align: right;\">5248</td><td style=\"text-align: right;\">6648</td><td style=\"text-align: right;\">8958</td><td style=\"text-align: right;\">2583</td><td style=\"text-align: right;\">3944</td><td style=\"text-align: right;\">3637</td><td style=\"text-align: right;\">2947</td><td style=\"text-align: right;\"> 177</td><td style=\"text-align: right;\"> 573</td><td style=\"text-align: right;\">4103</td><td style=\"text-align: right;\">8003</td><td style=\"text-align: right;\"> 6791</td><td style=\"text-align: right;\">7276</td><td style=\"text-align: right;\">3872</td><td style=\"text-align: right;\">3995</td><td style=\"text-align: right;\">3495</td><td style=\"text-align: right;\">2967</td><td style=\"text-align: right;\"> 6391</td><td style=\"text-align: right;\">19023</td><td style=\"text-align: right;\"> 7953</td><td style=\"text-align: right;\">-5003</td><td style=\"text-align: right;\">-13461</td><td style=\"text-align: right;\">15144</td><td style=\"text-align: right;\"> 7872</td><td style=\"text-align: right;\">  467</td><td style=\"text-align: right;\"> -2434</td><td style=\"text-align: right;\"> 2750</td><td style=\"text-align: right;\"> 2664</td><td style=\"text-align: right;\">-6396</td><td style=\"text-align: right;\">-2472</td><td style=\"text-align: right;\">4260</td><td style=\"text-align: right;\">2293</td><td style=\"text-align: right;\">2453</td><td style=\"text-align: right;\"> 499</td><td style=\"text-align: right;\">2569</td><td style=\"text-align: right;\"> 8703</td><td style=\"text-align: right;\">3654</td><td style=\"text-align: right;\">5904</td><td style=\"text-align: right;\">7707</td><td style=\"text-align: right;\">5428</td><td style=\"text-align: right;\">4701</td><td style=\"text-align: right;\">2861</td><td style=\"text-align: right;\">3810</td><td style=\"text-align: right;\">5768</td><td style=\"text-align: right;\">1067</td><td style=\"text-align: right;\">4889</td><td style=\"text-align: right;\">5041</td><td style=\"text-align: right;\">5078</td><td style=\"text-align: right;\">2493</td><td style=\"text-align: right;\">1784</td><td style=\"text-align: right;\">2427</td><td style=\"text-align: right;\">6375</td><td style=\"text-align: right;\">5482</td><td style=\"text-align: right;\">4050</td><td style=\"text-align: right;\">4337</td><td style=\"text-align: right;\">5115</td><td style=\"text-align: right;\">3546</td><td style=\"text-align: right;\">4248</td><td style=\"text-align: right;\">3779</td><td style=\"text-align: right;\">3838</td><td style=\"text-align: right;\">4150</td><td style=\"text-align: right;\">5380</td><td style=\"text-align: right;\">5728</td><td style=\"text-align: right;\">3922</td><td style=\"text-align: right;\">2667</td><td style=\"text-align: right;\">3975</td><td style=\"text-align: right;\">4244</td><td style=\"text-align: right;\">3604</td><td style=\"text-align: right;\">4349</td><td style=\"text-align: right;\">4638</td><td style=\"text-align: right;\">5339</td><td style=\"text-align: right;\">5356</td><td style=\"text-align: right;\">3995</td><td style=\"text-align: right;\">4117</td><td style=\"text-align: right;\">6112</td><td style=\"text-align: right;\">5879</td><td style=\"text-align: right;\">3804</td><td style=\"text-align: right;\">3296</td><td style=\"text-align: right;\">4287</td><td style=\"text-align: right;\">3412</td><td style=\"text-align: right;\">4004</td><td style=\"text-align: right;\">3093</td><td style=\"text-align: right;\">3936</td><td style=\"text-align: right;\">4897</td><td style=\"text-align: right;\">4579</td><td style=\"text-align: right;\">4853</td><td style=\"text-align: right;\">5231</td><td style=\"text-align: right;\">4856</td><td style=\"text-align: right;\">4113</td><td style=\"text-align: right;\">4077</td><td style=\"text-align: right;\">4379</td><td style=\"text-align: right;\">4923</td><td style=\"text-align: right;\">3759</td><td style=\"text-align: right;\">4178</td><td style=\"text-align: right;\">4898</td><td style=\"text-align: right;\">5226</td><td style=\"text-align: right;\">4760</td><td style=\"text-align: right;\">4492</td><td style=\"text-align: right;\">4222</td><td style=\"text-align: right;\">4400</td><td style=\"text-align: right;\">4489</td><td style=\"text-align: right;\">4359</td><td style=\"text-align: right;\">4182</td><td style=\"text-align: right;\">4304</td><td style=\"text-align: right;\">4544</td><td style=\"text-align: right;\">4352</td><td style=\"text-align: right;\">4947</td><td style=\"text-align: right;\">5071</td><td style=\"text-align: right;\">4885</td><td style=\"text-align: right;\">4631</td><td style=\"text-align: right;\">5169</td><td style=\"text-align: right;\">4164</td><td style=\"text-align: right;\">4385</td><td style=\"text-align: right;\">4378</td><td style=\"text-align: right;\">4510</td><td style=\"text-align: right;\">5189</td><td style=\"text-align: right;\">4624</td><td style=\"text-align: right;\">4447</td><td style=\"text-align: right;\">4809</td><td style=\"text-align: right;\">4043</td><td style=\"text-align: right;\">3772</td><td style=\"text-align: right;\">3724</td></tr>\n",
              "</tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mLrq5BvdChq",
        "colab_type": "text"
      },
      "source": [
        "####Above see that an interesting pattern ensues, even though the number false integration events taken into consideration are significantly less compared to the number of true integration events, we that some nucleotides occur significantly less in the DNA of true integration events at close proximity to the HIV integration site.\n",
        "####We can make illustrate this more clearly by setting all positive differences to zero while retaining all the negative differences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N0wduBCTdYy",
        "colab_type": "code",
        "outputId": "06a21ba6-ce02-4377-de79-fea94b6bde9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        }
      },
      "source": [
        "'''\n",
        "Lets eliminate positive differences and leave the negative differences as is\n",
        "revealing a pattern at the site of HIV integration (in the middle of the sequence)\n",
        "'''\n",
        "diffANew = list(map(lambda x: 0 if type(x) == int and x > 0  else x,diffA))\n",
        "diffCNew = list(map(lambda x: 0 if type(x) == int and x > 0  else x,diffC))\n",
        "diffGNew = list(map(lambda x: 0 if type(x) == int and x > 0  else x, diffG))\n",
        "diffTNew = list(map(lambda x: 0 if type(x) == int and x > 0  else x, diffT))\n",
        "tableNew = [diffANew,diffCNew,diffGNew, diffTNew]\n",
        "display(HTML(tabulate.tabulate(tableNew, tablefmt='html')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table>\n",
              "<tbody>\n",
              "<tr><td>Diff. A</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">  0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">  0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">-2240</td><td style=\"text-align: right;\">-6180</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\"> -2006</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">-13277</td><td style=\"text-align: right;\">-4259</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td></tr>\n",
              "<tr><td>Diff. C</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">-65</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">-13</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">-706</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\"> -851</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">-2950</td><td style=\"text-align: right;\">-5875</td><td style=\"text-align: right;\">-1737</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">-1864</td><td style=\"text-align: right;\">-2150</td><td style=\"text-align: right;\">-2554</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">-1660</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">-128</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td></tr>\n",
              "<tr><td>Diff. G</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">  0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">  0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">-318</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">-2229</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">-2322</td><td style=\"text-align: right;\">-1889</td><td style=\"text-align: right;\">-1786</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">-2104</td><td style=\"text-align: right;\">-6200</td><td style=\"text-align: right;\">-3109</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">-1150</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">-343</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">-914</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td></tr>\n",
              "<tr><td>Diff. T</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">  0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">  0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">-5003</td><td style=\"text-align: right;\">-13461</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\"> -2434</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">-6396</td><td style=\"text-align: right;\">-2472</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td></tr>\n",
              "</tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIztfemC5l2f",
        "colab_type": "text"
      },
      "source": [
        "####Lets plot the above differences using a dot-plot to more easily examine the differences and highlight the relative differences in nucleotide frequencies around the HIV integration sites (at 100bp position)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX2NFA2CSVup",
        "colab_type": "code",
        "outputId": "c8fa6ff2-f4e3-49c9-e0e3-ff26bad7c272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "# Dot plot created using scatter plot (with help from https://github.com/Pjarzabek/DotPlotPython)\n",
        "import seaborn as sns\n",
        "from __future__ import division\n",
        "seqLimitStart = 80\n",
        "seqLimitEnd = 120\n",
        "xLimit = np.arange(seqLimitStart,seqLimitEnd)\n",
        "\n",
        "Thue = []\n",
        "Ghue = []\n",
        "Chue = []\n",
        "Ahue = []\n",
        "TyValues = ['T'] * (seqLimitEnd-seqLimitStart)\n",
        "GyValues = ['G'] * (seqLimitEnd-seqLimitStart)\n",
        "CyValues = ['C'] * (seqLimitEnd-seqLimitStart)\n",
        "AyValues = ['A'] * (seqLimitEnd-seqLimitStart)\n",
        "for position in np.arange(seqLimitStart+1,seqLimitEnd+1):\n",
        "  Thue.append(diffTNew[position])\n",
        "  Ghue.append(diffGNew[position])\n",
        "  Chue.append(diffCNew[position])\n",
        "  Ahue.append(diffANew[position])\n",
        "  \n",
        "def addSubplot(plt, yValues, hueValues):\n",
        " plt.subplots( figsize=(15,1))\n",
        " ax = sns.scatterplot(xLimit, yValues, hue=hueValues, s=250, legend=False, palette=\"Reds_r\")\n",
        " scale_legend = plt.Normalize(min(hueValues), max(hueValues))  # Create the scale for the colormap.\n",
        " color_map = plt.cm.ScalarMappable(cmap=\"Reds_r\", norm=scale_legend)  # Set the colormap\n",
        " ax.figure.colorbar(color_map)  # Add colormap legend\n",
        " plt.xlim([seqLimitStart,seqLimitEnd])  \n",
        " plt.plot()\n",
        "\n",
        "addSubplot(plt, AyValues,Ahue)\n",
        "addSubplot(plt, CyValues,Chue)\n",
        "addSubplot(plt, GyValues,Ghue)\n",
        "addSubplot(plt, TyValues,Thue)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxUAAABZCAYAAABIbwmAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEIIIYQQohT/H5vO3e8jRW9tAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x72 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAw4AAABZCAYAAACXIXOfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x72 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAw8AAABZCAYAAAB44xihAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO2de7RkdXXnP7uq7rOf0N2AAkLLQ0WU\nhy3E+AxqBOIEHxlDRhMnmphk4koyWRONK8uJE8dZyUwSs8aoGWOMzqwx6JiZSBzAByji+IBGWoTw\nsGlEIC3QDf2g7731Onv+OOfcOlW3HudVXfc2389at2/fqjr77POt/fvt3z7nd87P3B0hhBBCCCGE\nGEVl0g4IIYQQQggh1gYqHoQQQgghhBCpUPEghBBCCCGESIWKByGEEEIIIUQqVDwIIYQQQgghUqHi\nQQghhBBCCJEKFQ9CCCGEEEKsMszsUjO7x8x2m9nvT9qfGNM6D0IIIYQQQqwezKwK3Au8GngIuAX4\nBXf/p4k6hq48CCGEEEIIsdq4CNjt7nvcvQFcBVwxYZ8AqI3L8NatW/30008fl3khhBBCCCEAuPXW\nW/e5+7ZJ+zGMS1/9Kt+3fz8At962605gKfH2x9z9Y4m/TwYeTPz9EHDx2J1MwdiKh9NPP52dO3eO\ny7wQQgghhBAAmNkDk/ZhFPv272fnTTcAYOuPX3L3HRN2KRdjKx6EEEIIIYQQEe7Qaqb99MPAqYm/\nT4lemzi650EIIYQQQohx4w7tVvgzmluAs8xsu5lNA1cCV4/Vv5ToyoMQQgghhBBjx/F0hQPu3jKz\ndwJfBKrAJ9z9znF6lxYVD0IIIYQQQowbd2innraEu18DXDM+h/Kh4kEIIYQQQoix42mnLK1qVDwI\nIYQQQggxblzFgxBCCCGEECIN7tCsT9qLwqh4EEIIIYQQYty44yoehBBCCCGEECPxABpLoz+3ylHx\nIIQQQgghxLhxh2Zj0l4URsWDEEIIIYQQ40ZXHoQQQgghhBCpcMebKh6EEEIIIYQQo/BA05aEEEII\nIYQQKQgcGnrakhBCCCGEEGIUHkBd05aEEEIIIYQQo9DTloQQQgghhBCpcE1bGo0HYJWM23j4E2OU\nYMPCn7w2LPons40AYjeK+hD7kVmLhA9l+JHHh14/cvjg7VZ0qS8InZiawaam8/uQ04/CWrgDXnJc\nFIzNMmyUoQVAZRJtvec4Crd1MmvhQQBLC6EdDKamsOnZbDbaLWjWQz+MsI1Us3Xx3qxDuw14eAzT\ns9gktKgvRvnDoDaFTc1kstFYXGTp0GHcHTNjfvMmajPZbPjiQqSnQ6UK6zcW1GJSOUD5cNlEuwVB\nu/NCdQor0ufk/j6CxAs2+X4vt41VkA/XGkEAdRUPgwnaUF+AqRmw6uigiIOw3YBWk+UMWKnA1Cyp\nGpgH0SWhetRBRDaqU1CbinwYYiP2wYMoaUSdjFWgOg3V2ugGEtsIWtBqdDoJq2TXotWAdlKLamgj\njRZBEG7XV4vp9D54O7zEltSiNg2VWnobK7SowtR0Ki28vgiNJfzuW/A9d4TPR65NYyedBue9DObW\nYXPrj6IW9e7vNLUWUUfdboUx3qXFTGgrlQ0P20e/uBgV311aLHX+TzhAo1qCFtUaIwcWy1o0w7iI\nfYjbSKWS0kbcRlrZtYiTVhBAq96jxXQYG2naOh4Otlu9WsxAtTryOLxRD+N79/fwu3fC4hGo1WDL\n06m84BLYsBnm1g8dtC63kd234Y88AM1mWHyceDqcdUFYRMzMDTkMDwfrC4cI7r0VDu0Pj2V6FnvG\nOfD0Z4Y2alMptOjT79Vmwu9lVFtv1KFZx/d8H7/v9tCnag22PI3K814C6zaMbOtP7tvPkf2Pc/1f\nfIR7briR+pEFZjes5/n/4jJe9utvZ27zJtYdf9xgH4IAnjwIj+0l+OJn8R8/GB7T+k1UXnIZPO+i\nsM+ZGVLYrZkcQAn5MG8OOLpaeLMBrUbYPhYOhnpUa7D5BNjydKjURsd30RwQxOOTJVh6smOjWoO5\njaGNSqVYDjjqY4Oi+XBADkiTD9cq7sfEOg/myeq1RHZceIHv/MbX4t3A9Fyns+klCMIG1W4ONmgV\nmJnvBFWSOJgbC91nFXqp1EI/+jUu93DbxkJ3Rd9LbSYa+PazEYSNeugzfA1m5qJkOsBGo6gWQVi4\ndZ3d6KEaaTHIhyBIp0Vtur+eQRB2Cq0hFbYZTM9HHeZKG75wmOAbn4c9d9J9iiTB1pOp/PS/gg3H\nYb02UmsxBdOzQ7RohwOZQT5AWODWpgbbaKbVojq4jTQWwyQ8iEo1tNGv082ixdTs4DbSboV+FNKi\nHiWMAZSpxaDjKBwXHrbRxhJDtVju9/rE9+KT+C1fwe/4ZpTQ+7BpC5VLfwmOO6Hv4MYXDhN851rY\n99BgH7adSuXiy/oOvL3dgsOPE9x8HSwc6r+9VbBnPh87+wX9ixAPEnExCAu1rE71/U598Qj+3Rvw\nH9w2uM/ZuIXKJW+CjVuwarV7e3eeePAhPn7lL7PnWzcP9OK5l72aX/z4h9n89JNW+tCow8P30/74\nH8MTj/U3UJvCXvUGKpe8Dlu/ceX7aXPAdJQD+sZnGTkgRT6s1mBqUD4sIQeUlg8XoxMEg0wM1sLd\nobGI3387LD452MbmE7FTzu5/hauMHBC0YekILA5oYxBquH5L2EYG5dTmCC3KygGD+r0g0qJwDiiY\nDwduZre6+47UG0yAHc84yb/ze28GoPZbf77q/R1EjvkneYg6snZzZdDGHdSwjhLC7eJqvbczi98b\n1lFCONioH1mZqOMzI/UjwztKCAO+sdTHRjQoGrn4h4eNt93qfxz1MrQ4MrxzgHD//T7n0ZnUtFo0\nl/rYiIrBYZ1DvK/6kXB/PfvyhcME//cTsOcOhnZS+x4m+PsPw6HHV9pO6jSMdrN/hxoPiuoLw32A\n8HiTZ2FigmggkFaLoE9cBEHnvWEE7f7Hm1WLxkL/+I7fS6VFo39sNhaHFw6xv/Uj4fEU0aL+5IC2\nPkCnXgbFRVwYj0qgEB1vc2V8Lx4h+Mpn8Nu/MbhwADi4n+BzH4L9e/F2d//mC4cJbrhqeOEA8NiD\nBDdchfcMnjxow8HHCL7+ucGFQ/hB/L5dBLtuCK9ydL3n4Xc9tHCAMAcsdp99jt9ZOkJw4+fwe787\nvM85tJ/gCx+HA4+FVwgSPP7Ag/zxxZcMLRwA7rz2y/z5Ky7n4N4fd/vQbOI/vIf2n71rcOEA0Gri\n132G4H/9N/zJHs3iQVGaHNBYiNp6n3ZWSg5IkQ/bQ/JhKTmghHy4dGT4YHn5cwPac30Bv+fm4YUD\nwIFH8Pt2hdP2umx7CTmgDUcODi8cIPweDj3WfRUz+V49hRZl5YBB+TBoZcwBfWw0FjPkwz45YK3j\nQThtaY1PXTpKxUNEY7E7EOJB5qhOLslST4cWBOkadnKfjcXuoPaoA0tLO7pkmPSj3R49KErSz4dG\nRi3qR+g67riDKaRFVMylpd3s7vjjznZU8kvS6O6ovL4YXnHYvzfd9vUFgi/8Db5wOPGih7GSlqAd\n6t8Vn55iUJSg1Yjmiye2j2MlLfWFlW2k9zsaShTLQU9sZdWid0CQWYt69wA/HmSOSn5Jegcvy2dC\nU2oRJ6AVbT2rFvX+/VZaevo4bzXx22+CB+5Kt327RfD5j3UNgHxpgeD/fR4WDw/ZMMHCIYJv/iOe\n7OfqiwTfvHp48ZJk7/34D+8Ii46YoD16IJCk2X3ixVsN/Hs3wd4fptu+1SS47lNd8XzokUf5y8vf\nyKEfP5LKxKM/2M3fvuVXeXJ/4oTD4QMEH35f6v7Xb/kafvNXu7VoZ9SiXz7MmgOW+uWAEvJh5hyQ\nyIdxDigjH6bu91hRCHmzju/+bvo+Z/Ew/vC9eLK/jvVJS6unj4v7zSx6Ht7f03+XkANy58OCOaA3\nH7aaxXLAsUDg0GiEP2uYVMWDmZ1oZp82sz1mdquZfcvMXp9rj83EAC2e85YJ7xmUBNk6GOg+u+ue\nrcOPaSUGFEHGwURM8ixFPNDMQtxJL/+do0pvtzp5Jr5fJCvN5NQNL6BFZKOxFE1VysDhJ/D9ibOJ\ny/PgM9CVAIP8WgSJ77RobHlPvKeht00EebWI7RX4Tru0yNFZtpJXMDzbwApYnn4R+5C5v+nxIWvh\nEJMsxuqL+K6bsm0f3xcRH8vSk3Dg0Ww2Ht8b3pQNeBDgD94T3V+WHt+9qzNfN7cWybZex++5Ndv2\njSX8wR8QT7ndd/8D7L3rnkwm7r7hRo5ExYO3mgQ3XZO5vQdf/CwcPhj9UUJc5M2HK3JAnnwYb19C\n/03ePFJCPkz2DwuHsvvxxCOdAW/uHJA8jiB9gZ9k8XC3FrlyQLKwLZgDisR3sv/No2erz1XstYx7\neF9aM0cuWkWMLB4svFPvH4Cvu/sz3f0FwJXAKbn2GJ+lzpvIoTMoyZu8oBOQeQc18Q1D4R/ZO2zo\nNE738CbaPHRpkfMyWFKLPN+Je6eDiG8Ky0o0cPd2C7/rFjJ3dIDv/DK+FJ1xyatFO9aCnFoELPue\np5iDzg1keWMTOgmskBbNRFxkTF6QuBmPqK3k1CK+5J47vuuJtp7TRpy8ewcoqbfvxIL/855cx+K3\n3QiLR/BmneCu4dNzBtq4+xY8mnLl9+3KbqBZx5+IzvDn1iLMAe6OP/SDXLHl3/8GLB1h4cABrnn/\nn2T3AbjhLz5CY3ERjhzGv35NdgOHD+B7H4g9ypkDWokcUEY+LKGN5M0BnswBBfNh3n4vmvLjrQa+\nd08uE/743rBIL5ID4nzY+3SntMRXoFdLDoB8OaA3H+bKAT1Xftc47o43GvhT4MrDJUDD3f8qfsHd\nH3D3D+XeazyoyNtZdp1VzdEwIdEoCgRlPJc549m7LuIGlddG8qxVUS3ydPhJG8nfefAA6kv4nu/n\n2/6RH3V0zHss8Rkaz6kllBQXBQvs3qtzeYif5pE3rqBzsiC3FlEbdfIlr6QPcUGWh1Z0v1YhLdp4\ns4Hf89182x85GN1s3oK8A6O9e6KbFZvRDaA5bPzo7vBG67zfB4TxGT1ZKReHn4BWk+ZinTuv+0ou\nE7v+4QssHjgIRw6PnhM/AP/29eHUpSL9Xln5sFAOaK2eHFBEi6Ad6ZDzjD/AgUciPUrQIst06C68\nc8IhbzuLtYAJ54AS8mGRcdpq4xi55yHNo1qfC+TMdgNITsnIbwS8wGO8yvIBinUy8VnuQjjhc/eK\nbE8xLeKrD0VtEBR7jFnyTEdeH+KzX4V8oLgfZgX9KMGH5O9cNqLvo2hcmDHZBFJGfxFAO8g9aAc6\nxW3eAUWzHmpZZODfrIfzdgv3F+1iiyUFAUG7teLm6bQsHDgYPgJ3Me8Aj/DRun0e+JCNEvqcojnA\nPdx8NeSAov1WbCcvrcRVxiL7L1qMBQFUC/oROlNg0xK+j+WTtCXkomMB9zV/vwPkuGHazD5sZt8z\ns1v6vPcOM9tpZjsf27d/iJHlDbLuvjxK2beVYMuKjfuTfhTdvshxWI6FbvrZiJ+zX9RGIT+W/yng\nQ0Eb3c5Mhvg4CoV39H0UtrEKcCh4ING6NUOeJz+K5bUjcra1ai1MXpXq6M8OojYFlYLPYI/X4Rj2\nbP0UNioFjmNm3Xx430TGBei6mI4fa7zGc8BybV7UTtG4WPGfgnZyUK0CXk6fVbSNFD0vGBoq5kPR\nfIglfgr4cazgjjdbeLPACZxVQJoMdCdwYfyHu/8m8EpgW+8H3f1j7r7D3Xds27plyF6jBJi7408E\nYt4kGu877/bQWbci4yqu3X5EiSevFskBXhEtimwP4RoaED4jOi/RAjF24jPybb/x+MT3mrOzWY7N\nCcdF/F1U88ZF7H+BTrtwO6WzYFClyHqUUQLL68dyfBdIQPFx5P0+Yj9q09jJZ+Xbfmo6/KlU4PgT\n89k4/qRlP/LGp207NVqjoKAWU9Fij3mYDp8jX6lVOeW85+UycfrFO5iam4MNm/Jr8ZwLwlW8C8VF\nlANy9xeJuJ5kDiil34ue618kH8bHkbconN8UtfcC32msxVS2VeK7iL+T3Fokv8tVkA+L5oBjhcDx\npSa+dIzfMA3cAMya2W8kXpvPv8fEipJ5zzDHqyBWCnQQtZlOg8jb2cWNwaIGlnn7hBZFjmP5jH1O\nG8kVHfM28Dh55k2i0eDMpqax81+ey4Sd/wqYW18stpZXJ86bwKyTdHJrGW1XqRT7TuPVSou2s7wF\nRHKV57xFZXKl57yJuBbFd5GrWkkt8gywLFwI0SoV7FkX5LJhz7kIZuaxmTnsnBdl9wGwc34iXOht\nagY79Vk5DFSwp58RTvcZtRruEBtgWKWKnXXhyI/3NfHsF8LMHBtO2Mbl731XLhs/8953M795E8zO\nYxe+OLuBqWnsnBdEDmVbzGqZ1ZIPp2aL54BS8iHF82HUzu3EfIWpnXhauAhh7oF7IgfEqz5nZfn7\nKPKdlpgD8ubDrhyQNx9OHVO1A+4E9SZB/RgvHjx8Ht7rgJeb2f1mdjPwKeDdufYYD1Qhf0AuJ3Ly\ndXRW6RQOeTvcpA95G2cZWsQrtuY94xMPqmIfcmmR7CCLaBHZmFsPW56W0Ycp7LRnh4MaM6jm8CG5\nmmXeTrusuEjGZ57B6nIiz+lDUovcbSTxnRr5CoiuNpJnsJpoV3m1iM+cQX4tkvE9PQtnnJvRgGHn\nvWR5lWnbtDVcVTcLs+uxjeEVYavVsDPOz+gD2MlnJjQ0qOUo6JLxPT0DJ5+R0QnDzo7O+ANn/OTF\nzG/enMnE1mdu5/jTTg3Nzc5Rec2bsvkA2MWvhPl1yz7lKvRXSz4snAPK6PeSqxoXy4dmBptOyN53\nzm3o9FN5T1j0ajG7LruNuY2Js/2rIAfkzocl54BjAA+coNEiaBz705Zw973ufqW7b3f3i9z9p9z9\nM5n3Vp3q7hCs0llKPS3Tc92fN4OZjI0zXsp+2UY1W8cfN6TezjJLZzdIiywldq92ZtkHFDPz3Zck\nK5VsHU00/aBLi6mZbFrUprt8sPn1VH76LeF3nQYz7NK3wux812uhnmmJPp+Mi0o1W2cXTwfp1SJL\nx1eboetyuVVyfKfrVsZFWi2XP9+njWTWYqon+cxm02Jqlq72kLutF9RiqqfPqdayFeqVWlcBYtOz\nVF5yRTjNLq0br3hDWFTHzM5Teenr07ezSi38fDKWZtdhz3tZah9Ytwk798XYVNQ/mEGtlm3AWu3+\nvM3MUXnxz8L8htQm7KWv6xqQrd+2lXde+/dUaun8mFm3jt/8wmfYeOIJnReP24Zd8dbUPnDSqVRe\n+2ZsOhpcmkX3gqyGHJCjjazIAUc5H/bkACqVqJ1m0KK3rVensO3PT799dQrb/rxOfMd+FMoBle6C\nJA2zG7r7l8oEckBp+bBoDji2CgcgfHhVvUVQfwoUD6VQnQrPuPUGghnMrE8XINNznbnHye0r1ZQd\npsFsn32ZRfOJU3SY8b56bcQNPE0irU0P1mK2p9EPYno+nCLUV4sUHY0N0iJKHGmSR7yvfjZm5tMl\nj3hfvTY2bKbyhn8D6zaN2H4K+5m3YyecunwmMvTBQn3SFBCDdLdKNLc6RTFVqa1MwrGNmXXptJia\n6S7EkjZm15Mqkcb7WhEXtXTJwyphe+w9jkqkRZrkUa31j4tKFi1mo8FYsoCxErSIBgNFtLBoYJNK\ni2hfPVrY+k1hfI+6wmYV7JVvws48rzNQBcwqsHELlZ+6cnS/NT1L5ZKfhw3HhWdkYxtT09ipZ2Pn\nvYKRem7aRuUlr8d6z6Iua5Gi34u16NHT1m2k8jNvg01bh29vFezlbwx9TgzwqrUap5x3Lv/u69cx\nu2F4EbLhhG2869vXs+3MM7q1mFtH5SWXUXnjr4zuf7c/i+pv/yds43Er/CsvB6TJh/MD2nolXT4c\nlgOmpjPkgKL5cEAOsEr6fDizUgurVmH95vAK2yg9p2axs1+4sl+IB7yptBiQAypV2Lg1XR6Z2xie\nJOjX58yuT6nFupVTCpdzQJp8OED3PPmwcA7okw/XOB44wVKTYI3f82A+pkdg7bjwAt/5ja+FCWN5\nHvmQBhxEKyI2693PFI4vByen5/QjuZhVq979iLS4A1h+UskAG/Ej/1qNzkJdMdVap4MbdvNQED2a\nsllf+azq2nTUGEZMvyhNi+bKBVYq1ej7qKY7jmUtElRr0YAljRbRAjW9j4aMtRhxM5YvHMYfexi/\n9Svw6EOdNzYcj13wcuy054RzlgcNXsrQIn7kXl8tpjrzWkdp4UHoQ5cWltCCwTbi4wja3avSQufM\nX1xYjzMuPHoUY7/4TtvWkwsXBQO0MAbbiB/91251r+aaSYt4EahGuO4BvVrMjp4yVoIWvnAYDuwj\nuOXL8OAPOn7MrcfOfxl29oUwM4dN9x+8eBBAfQF/7CH8ru/AocRT7jZuxc65GNt6CszOhQVHPxut\nRrjS84N34/fdDo3Eo2RPOI3Ks18I6zZiw05KlKHF4pP4gX34rhvhxz/svDG3Hjv3Rdj2c2F6Dhvw\ntKp2s8nhx/Zx91e+yrUf+FMeuXf38nunnv98Ln/vu3nmi17IhhNPoDIgxn1xARaeJPjWl/AbvxCu\nAQFh4XLuC6lc9vOw5URsw5BpUsO0WI7vCebDSnSlvZI2BzRXLq6YOR8uDc4BY86H3o7W4Tj4GP7o\nA92PAp/fhD1tO8xtwIYV4UNzQK1zlXSoFu3wZ+FQ9+K28dWiuDgYNLBO5oBWrxbRSb/qUcwBw/Lh\nuHPAAMzsVnffkWmjo8wFG+b9axecCcDmm76/6v0dxPiKhx07fOfNNw8P5H7EST1JFhtx4+gly9MC\n+tk42sfRz4ZF/2TRIn6GeNJGlgZZhp79nsOeUQtfPNJZrdMqYSE4t77r7OFwA2PSohQbGeOiqJ7j\nOI5416tBi8JtnaMeF760EA7SgnZnADG3HstwLOHq6tFiX9GZRptNP93BgyAsHOJn9VcqUK11XfFI\nYST6nXgta1tfWgwHN0EQ6liphScIMmhx6JFHaTUaBO02lWqNqdlpNmxb8YDAwT60WnDkUGfxtGoN\npmex+QxTgo7lHLAG86HHA974eKIBbtc0pdFGivcXcUEV24kH2kX6vVUTF2XYyBgXXZuu/uLh/PVz\nfv3zwvu8tn77zlXv7yCKPDtrNHke72UV0sxIGLx9/sAr10bB4yjDhhmU8Yz9oloUXf8BsLkcN511\nGVglWqwGPVfLcUiLjokMg/xx2bBKJd/Nnd1Got8FTMzOAVnmZ6+k636GPD7UarAp/T0p/Y0oB3Rs\nTF4LMyu2pkdoZPJ9Vhk2Vk1clGBjjeEOjWaBFbtXCeMtHoQQQgghhBC4O81GgZXHVwkqHoQQQggh\nhBgz7tBsqXgQQgghhBBCjEBXHoQQQgghhBCpOFbueTjGVt8QQgghhBBi9eGB02gENApefTCz95nZ\nw2a2K/q5PPHee8xst5ndY2avSbx+afTabjP7/cTr283sO9HrnzGzkY8gU/EghBBCCCHEmHGg5U6r\nnGUSPuju50c/1wCY2TnAlcBzgUuBj5hZ1cyqwIeBy4BzgF+IPgvwJ5GtM4EngLeP2rGKByGEEEII\nIcaMAw13GmNaYw24ArjK3evufj+wG7go+tnt7nvcvQFcBVxh4WJZlwCfi7b/FPC6UTtR8SCEEEII\nIcSYCYBG4DQCB9hqZjsTP+/IaO6dZna7mX3CzI6LXjsZeDDxmYei1wa9vgU44O6tnteHohumhRBC\nCCGEGDPu0Oxcddg3bIVpM/sKcFKft/4A+CjwfsKLGe8H/gx4W7neDkbFgxBCCCGEEGPGcRqe7mZp\nd39Vms+Z2V8DX4j+fBg4NfH2KdFrDHh9P7DZzGrR1Yfk5weiaUtCCCGEEEKMGadr2lJuzOxpiT9f\nD9wR/f9q4EozmzGz7cBZwM3ALcBZ0ZOVpglvqr7a3R34KvBz0fZvBT4/av+68iCEEEIIIcSYcbqm\nLRXhP5vZ+ZHJHwK/BuDud5rZZ4F/AlrAb7p7G8DM3gl8EagCn3D3OyNb7wauMrP/CNwG/M2onat4\nEEIIIYQQYswEDosFrzoAuPsvDnnvA8AH+rx+DXBNn9f3ED6NKTUqHoQQQgghhBgzAc5Ce2yPaT1q\nqHgQQgghhBBizAQOC0Gx1aVXAyoehBBCCCGEGDMBsFTCtKVJo+JBCCGEEEKIMeMl3fMwaVQ8CCGE\nEEIIMWaOlXsezMt5ZNRKw2aHgXvGYvypyVZg36SdOEaQluUiPctFepaHtCwX6Vku0rNcnuXuGybt\nxDDM7DrC7x3CFaYvnaQ/eRln8bBz2LLbIhvSszykZblIz3KRnuUhLctFepaL9CwX6Xn00ArTQggh\nhBBCiFSoeBBCCCGEEEKkYpzFw8fGaPupiPQsD2lZLtKzXKRneUjLcpGe5SI9y0V6HiXGds+DEEII\nIYQQ4thC05aEEEIIIYQQqVDxIIQQQgghhEhFKcWDmf1bM7vTzO4ws78zs1kz225m3zGz3Wb2GTOb\nLmNfTwUG6PlJM7vfzHZFP+dP2s+1gpn9dqTlnWb2O9Frx5vZl83sB9Hv4ybt51pggJbvM7OHE7F5\n+aT9XK2Y2SfM7FEzuyPxWt9YtJD/GvWht5vZhZPzfHWSUc9XmNnBRJz++8l5vjoZoOe/jNp7YGY7\nej7/nig+7zGz1xx9j1cvWbQ0s9PNbDERm381Ga9XLwP0/C9mdnfUP/4fM9uceE+xOUYKFw9mdjLw\nW8AOdz8XqAJXAn8CfNDdzwSeAN5edF9PBYboCfB77n5+9LNrYk6uIczsXOBXgYuA84DXmtmZwO8D\n17v7WcD10d9iCEO0hLCtx7F5zcScXP18EuhdFGhQLF4GnBX9vAP46FHycS3xSdLrCXBTIk7/6Cj5\nuJb4JCv1vAN4A/D15Itmdg5hbnputM1HzKx6FHxcK3ySlFpG3JeIzV8ft3NrkE+yUs8vA+e6+/OB\ne4H3gGLzaFDWtKUaMGdmNWAe2AtcAnwuev9TwOtK2tdTgV49/3nC/qxlngN8x90X3L0F3EjYeV9B\nGJeg+EzLIC1FStz968DjPS8PisUrgP/uId8GNpvZ046Op2uDjHqKEfTT093vcvd7+nz8CuAqd6+7\n+/3AbsITC4LMWooRDNDzS8+mppoAAAOFSURBVFEuAvg2cEr0f8XmmClcPLj7w8CfAj8iLBoOArcC\nBxJf6kPAyUX39VSgn57u/qXo7Q9El+c+aGYzE3NybXEH8FIz22Jm88DlwKnAie6+N/rMj4ETJ+Xg\nGmKQlgDvjGLzE5oClplBsXgy8GDic+pH0zGsbb/IzL5nZtea2XMn4NuxhOKzXLab2W1mdqOZvXTS\nzqxB3gZcG/1fsTlmypi2dBxhlbcdeDqwjpWXlkRK+ulpZm8hvBz3bOCFwPHAuyfm5BrC3e8inEL3\nJeA6YBfQ7vmMA3pm8QiGaPlR4AzgfMKC988m5eNaR7FYLj16fhc4zd3PAz4E/MPEHBOim73AM9z9\nAuB3gU+b2cYJ+7RmMLM/AFrA/5y0L08Vypi29Crgfnd/zN2bwP8GXkx4ib0WfeYU4OES9vVUoJ+e\nP+nue6PpC3Xgb9EluNS4+9+4+wvc/WWE99/cCzwSTwGJfj86SR/XCv20dPdH3L3t7gHw1yg2szIo\nFh+mc2UH1I+mpa+e7n7I3Z+M/n8NMGVmWyfn5ppH8VkS0fSa/dH/bwXuA86erFdrAzP718BrgTd7\nZ+EyxeaYKaN4+BHwE2Y2b2YGvBL4J+CrwM9Fn3kr8PkS9vVUoJ+edyWSoRHO4b1jiA2RwMxOiH4/\ng3CO/qeBqwnjEhSfqemnZc88/Nej2MzKoFi8Gvil6KlLP0E4hXFvPwOii756mtlJUf+JmV1EmP/2\nT8TDY4OrgSvNbMbMthPe2H/zhH1ak5jZtviGXjN7JqGWeybr1erHzC4F3gX8rLsvJN5SbI6ZUlaY\nNrP/APw84WWj24BfIZxfdhXhFJvbgLdEZ83FCAboeS2wDTDC6SK/Hp9FE8Mxs5uALUAT+F13v97M\ntgCfBZ4BPAC8yd17b7wUPQzQ8n8QTlly4IfAr2mQ2x8z+zvgFcBW4BHgDwmnz6yIxWig+5eE00AX\ngF92952T8Hu1klHPdwK/QdivLhLG7zcn4fdqZYCejxNO89oGHAB2uftros//AeFc8xbwO+5+bR+z\nT0myaGlmbwT+iLBfDYA/dPd/nITfq5UBer4HmKFzEuDb8ZOqFJvjpZTiQQghhBBCCHHsoxWmhRBC\nCCGEEKlQ8SCEEEIIIYRIhYoHIYQQQgghRCpUPAghhBBCCCFSoeJBCCGEEEIIkQoVD0IIIYQQQohU\nqHgQQgghhBBCpOL/A+VVl+EO/xqSAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x72 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxQAAABZCAYAAACnrWK+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1080x72 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZv12QDP7xus",
        "colab_type": "text"
      },
      "source": [
        "###**Conclusion**\n",
        "####Previously we showed a high relative frequency of guanine around the HIV integration site based on the consensus sequence calculated from DNA of correctly predicted true integration sites. Also, judging from the dot-plot above, which compares the relative distribution of DNA nucleotides from correctly predicted true integration sites with nucleotides from correctly predicted randomly sampled (false) integration sites, we clearly see that there is a significant difference in the relative distribution of nucleotides at the proviral HIV integration site. The difference is largest around the integration site itself (at 100 bp position). Not only is there a significant difference in the relative distribution of nucleotides at the integration site; but the relative distributions of nucleotides above show significant symmetry. When examining the dot-plot generated, one can see that the relative differences in frequencies between the nucleotides (A)denine and (T)thymine are shifted and reversed versions of each other. Similar can be said about the relative frequencies of nucleotides (C)ytosine and (G)uanine, both their distributions contain the first peaks at 89 bp and 113 bp positions while their distributions between these peaks are reversed versions of each other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVUlvm9A8k7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}