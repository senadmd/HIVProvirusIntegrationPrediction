{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HIV Provirus_20190216_SGD",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D58TNN5zLL_S",
        "colab_type": "text"
      },
      "source": [
        "#**A Convolutional Neural Network for predicting HIV Integration Sites**\n",
        "###This python notebook is the result of degree project done by Senad Matuh Delic, the full-text describing the work in full can be found here (link to be added)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCbtnO1jIx7Y",
        "colab_type": "text"
      },
      "source": [
        "###Download the dataset for HIV Integration Sites\n",
        "#####This can be done fetching the pre-generated dataset from AWS using the code below. Otherwise you can generate your own dataset using our dataset generator tool [Retrovirus Integration Database Parser & Training Set Generator](https://github.com/senadmd/RetrovirusIntegrationDatabaseParser)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYFy-vFYbwpH",
        "colab_type": "code",
        "outputId": "264ae9cc-f450-4b41-f97b-7bd101f9312c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "!wget -O data.zip \"https://kth-project.s3.eu-north-1.amazonaws.com/data.zip\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-16 13:46:12--  https://kth-project.s3.eu-north-1.amazonaws.com/data.zip\n",
            "Resolving kth-project.s3.eu-north-1.amazonaws.com (kth-project.s3.eu-north-1.amazonaws.com)... 52.95.171.0\n",
            "Connecting to kth-project.s3.eu-north-1.amazonaws.com (kth-project.s3.eu-north-1.amazonaws.com)|52.95.171.0|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 345929473 (330M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>] 329.90M  10.8MB/s    in 33s     \n",
            "\n",
            "2020-02-16 13:46:47 (9.86 MB/s) - ‘data.zip’ saved [345929473/345929473]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyqIjZiTJ9At",
        "colab_type": "text"
      },
      "source": [
        "###Extract the compressed files\n",
        "####The files containing the \"_validation\" suffix are files part of the validation set and should only be used when validating the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH0p6NtZkl-D",
        "colab_type": "code",
        "outputId": "10603bbb-96ed-4160-8c1f-99c2c3a221a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "!unzip data.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/DNAString.txt      \n",
            "  inflating: data/DNAString_validation.txt  \n",
            "  inflating: data/inserts.txt        \n",
            "  inflating: data/inserts_validation.txt  \n",
            "  inflating: data/labels.txt         \n",
            "  inflating: data/labels_validation.txt  \n",
            "  inflating: data/positions.txt      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM0otVZwKPm-",
        "colab_type": "text"
      },
      "source": [
        "###Parse the one-hot encoded DNA sampled at HIV insert positions  from the inserts.txt file (training data)\n",
        "#####The DNA is encoded into four channels indicating occurrence of the nucleotides A,C,G,T. The one-hot encoded DNA string in the dataset  contains nucleotides 100 bp before integration site and 100 bp of nucleotides after the integration site fetched from the GRCh37/hg19 genome using the [UCSC Genome API](http://genome.ucsc.edu/goldenPath/help/api.html). The HIV Integration positions have been parsed from [Retrovirus Integration Database](https://rid.ncifcrf.gov) using our own tool described above, the positions parsed can be found in the extracted file *positions.txt*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUlFqfHhqm_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('data/inserts.txt', sep=',',header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x8_BVYRQY9m",
        "colab_type": "text"
      },
      "source": [
        "####What inserts.txt file looks like\n",
        "#####We see that the DNA string is a 800 length one-hot encoded string. This is result of four A-C-G-T channels of 200 bp being one-hot encoded and concatenated into a single string. Note that no proviral HIV DNA is contained in the files extracted, these contain only DNA sampled at the positions of HIV integration from the GRCh37/hg19 genome. Regarding false HIV integration DNA samples, these have randomly sampled from the GRCh37/hg19 genome with safeguards of collisions or overlap between the sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi7LbI0knGtt",
        "colab_type": "code",
        "outputId": "055ae99a-3311-4a59-c590-a525e5c9e504",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "df.head"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of          0    1    2    3    4    5    6    ...  793  794  795  796  797  798  799\n",
              "0          0    0    0    0    1    0    0  ...    0    0    0    0    0    1    1\n",
              "1          0    1    0    0    0    0    1  ...    1    1    1    0    0    1    1\n",
              "2          0    0    0    0    1    0    0  ...    0    0    0    0    1    0    0\n",
              "3          0    1    0    0    0    0    1  ...    0    0    0    0    0    0    0\n",
              "4          0    1    0    0    0    0    0  ...    1    1    1    1    0    1    0\n",
              "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
              "1595819    0    0    0    0    0    0    0  ...    1    0    0    0    0    0    1\n",
              "1595820    1    1    1    1    0    0    1  ...    1    1    0    0    0    1    0\n",
              "1595821    1    0    0    0    1    1    1  ...    0    0    1    0    1    0    0\n",
              "1595822    0    0    1    0    0    1    0  ...    1    1    1    1    0    0    0\n",
              "1595823    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    0\n",
              "\n",
              "[1595824 rows x 800 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maNvYz1ZQsws",
        "colab_type": "text"
      },
      "source": [
        "###Parse the training labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQsmrZ91pry6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelsdf=pd.read_csv('data/labels.txt', sep=',',header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DIuN25sQ0Nt",
        "colab_type": "text"
      },
      "source": [
        "####Lets get an look into the label data\n",
        "#####Below we see that each second label is a false label, this means that each second row in the insert.txt file is a false integration event randomly sampled from the GRCh37/hg19 genome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7knmtYSw2h_",
        "colab_type": "code",
        "outputId": "eebd1bee-dcbc-4696-c6a1-0494e95f1f65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "labelsdf.head"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of          0\n",
              "0        1\n",
              "1        0\n",
              "2        1\n",
              "3        0\n",
              "4        1\n",
              "...     ..\n",
              "1595819  0\n",
              "1595820  1\n",
              "1595821  0\n",
              "1595822  1\n",
              "1595823  0\n",
              "\n",
              "[1595824 rows x 1 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvugOUR-TbW-",
        "colab_type": "text"
      },
      "source": [
        "###Import Tensorflow and Numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr-50K2hYXG0",
        "colab_type": "code",
        "outputId": "1d043a02-e3c8-424b-dc8e-8704bdc188bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution() # define eager execution to be able to preview our training data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i08_xdHYTkeZ",
        "colab_type": "text"
      },
      "source": [
        "###Split the training set into smaller equal size batches for less RAM consumption\n",
        "####Below we split our dataset using the divisor (272)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m8mtTAeGbFR",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "# Split traning data into equal parts\n",
        "data_chunks = list(np.split(df.values, 272)) \n",
        "labels_chunks = list(np.split(labelsdf.values, 272))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE2b71qFULj7",
        "colab_type": "text"
      },
      "source": [
        "####Lets confirm that we have 272 equal parts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1uMIjhQG_6h",
        "colab_type": "code",
        "outputId": "24c8b764-e187-40b0-8008-df0996c2913f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(data_chunks)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "272"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTZw5csHU6LQ",
        "colab_type": "text"
      },
      "source": [
        "####Lets examine the size of each batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLaYXhcaHv63",
        "colab_type": "code",
        "outputId": "27bd8cca-39ab-455d-ba3a-e6b4e9951414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data_chunks[0].shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5867, 800)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnKVrtGYVkak",
        "colab_type": "text"
      },
      "source": [
        "###Reshaping each row to keep dimensionality of the data contained in each row\n",
        "####Before reshaping the data, lets look at how a single insert row look like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imozJeuPIHp_",
        "colab_type": "code",
        "outputId": "711104c9-ce0a-4431-8dc6-5d9ecefc790f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        }
      },
      "source": [
        "data_chunks[0][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
              "       1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
              "       1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9jS7uVUWSFx",
        "colab_type": "text"
      },
      "source": [
        "####Lets structure our data so that we don´t lose the dimensionality information contained in the seperate one-hot encoded channels\n",
        "#####Lets reshape each single row into four seperate channels corresponding to the nucleotides A-C-G-T.\n",
        "#####We can test this with the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14kh5a-UIm00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Below we repshape a single batch chunk for demonstration\n",
        "chunk_reshaped = data_chunks[0].reshape([data_chunks[0].shape[0],4,200])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8LctcYYJast",
        "colab_type": "code",
        "outputId": "6d7dd743-98c6-4503-f078-eb7896bd17e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        }
      },
      "source": [
        "# Lets examine the shape and data contained in the first row of chunk_reshaped\n",
        "chunk_reshaped[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "        1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "        1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "        1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
              "        1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "        1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
              "        1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "        0, 0],\n",
              "       [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
              "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "        0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
              "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "        0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
              "        0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
              "        0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "        1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
              "        0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BuENWOJUfYa",
        "colab_type": "text"
      },
      "source": [
        "###Define batch set generator function\n",
        "####This batch set generator function will reshape each batch and tie together each tranining data row with each label row using the python [zip function](https://docs.python.org/3/library/functions.html#zip).\n",
        "####The generator will reshape the data similarly as above, with one difference, to use our data as input for a [tensorflow CNN](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D?version=stable) we need to add a channel dimension to our data. Since the default input data format for a tensorflow CNN is (batch, height, width, channels) per *channels_last* setting, we need to add an extra last dimension channel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCIE0uYb8flV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define a generator to reshape our dataset and zip each insert row with each label row\n",
        "batchSize=data_chunks[0].shape[0]\n",
        "def genenerator():\n",
        "    for i, j in zip(data_chunks, labels_chunks):\n",
        "        yield i.reshape([batchSize,4,200,-1]), j\n",
        "#create a tensor for our training dataset\n",
        "train_dataset = tf.data.Dataset.from_generator(genenerator,output_shapes=([batchSize,4,200,1],[batchSize,1]),output_types=(tf.float32, tf.float32)) \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3dbsTqxZZRE",
        "colab_type": "text"
      },
      "source": [
        "####Lets verify that the output from the batch set generator is indeed the same as in the previous example (with the exception of the extra dimension)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsr9l83yPwyi",
        "colab_type": "code",
        "outputId": "5c46bf14-c424-4fce-d4f3-79ccd26ad049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "# define an iterator over our training data and get first next entry\n",
        "trainingData, trainingLabels = next(iter(train_dataset))\n",
        "print('Our first training label is:',trainingLabels[0].numpy()[0])\n",
        "print('Our first training row has the shape:',trainingData[0].numpy().shape)\n",
        "print('Our previous example has the shape:',chunk_reshaped[0].shape)\n",
        "print('Our first training row has the following entries in the first channel:',trainingData[0].numpy()[0][0],\n",
        "      trainingData[0].numpy()[0][1],trainingData[0].numpy()[0][2],trainingData[0].numpy()[0][3],trainingData[0].numpy()[0][2],trainingData[0].numpy()[0][4],\"..\")\n",
        "print('Our first training row has the following entries in the last channel:',trainingData[0].numpy()[3][0],\n",
        "      trainingData[0].numpy()[3][1],trainingData[0].numpy()[3][2],trainingData[0].numpy()[3][3],trainingData[0].numpy()[3][2],trainingData[0].numpy()[3][4],\"..\")\n",
        "print('Our previous example row has the following entries in the first channel:',chunk_reshaped[0][0][0],chunk_reshaped[0][0][1],chunk_reshaped[0][0][2],chunk_reshaped[0][0][3],chunk_reshaped[0][0][4], \"..\")\n",
        "print('Our previous example row has the following entries in the last channel:',chunk_reshaped[0][3][0],chunk_reshaped[0][3][1],chunk_reshaped[0][3][2],chunk_reshaped[0][3][3],chunk_reshaped[0][3][4],\"..\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our first training label is: 1.0\n",
            "Our first training row has the shape: (4, 200, 1)\n",
            "Our previous example has the shape: (4, 200)\n",
            "Our first training row has the following entries in the first channel: [0.] [0.] [0.] [0.] [0.] [1.] ..\n",
            "Our first training row has the following entries in the last channel: [1.] [0.] [0.] [0.] [0.] [0.] ..\n",
            "Our previous example row has the following entries in the first channel: 0 0 0 0 1 ..\n",
            "Our previous example row has the following entries in the last channel: 1 0 0 0 0 ..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xskyaynkijc",
        "colab_type": "text"
      },
      "source": [
        "###Modeling the neural network with Keras\n",
        "####Lets import Keras API and Matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm9s8aPqN0FY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import keras API and matplotlib\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsPk92UJk7o4",
        "colab_type": "text"
      },
      "source": [
        "####Define the layers for our CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-gCAt5gOIQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create our neural network model\n",
        "tf.keras.backend.clear_session()\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(100, (4, 30), activation='relu', input_shape=(4, 200,1)))\n",
        "model.add(layers.MaxPooling2D((3, 10),strides=1,padding='same'))\n",
        "model.add(layers.Conv2D(50, (1, 10), padding='same', activation='relu'))\n",
        "model.add(layers.MaxPooling2D((1, 1),strides=1))\n",
        "model.add(layers.Conv2D(50, (1, 5), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(50, activation='relu'))\n",
        "model.add(layers.Dense(1, activation=tf.nn.sigmoid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpYqddd3lSyc",
        "colab_type": "text"
      },
      "source": [
        "####Lets examine the layers and the number of parameters associated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr1oO5Vtlw7H",
        "colab_type": "code",
        "outputId": "2f5c5d39-b920-4d16-e313-f1c0314ceab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 1, 171, 100)       12100     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 1, 171, 100)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 1, 171, 50)        50050     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 1, 171, 50)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 1, 167, 50)        12550     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8350)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 50)                417550    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 492,301\n",
            "Trainable params: 492,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWFa-eCtlho4",
        "colab_type": "text"
      },
      "source": [
        "####Compile our Keras CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ1tnQqQmHig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compile our model\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1w1BZPRlrgL",
        "colab_type": "text"
      },
      "source": [
        "####Train the neural network in batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7BhSl1sm4sf",
        "colab_type": "code",
        "outputId": "64178ab8-fc84-4c7f-d94b-fbe1fca0abe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#train our neural network\n",
        "#use batch training\n",
        "for trainData, trainLabels in iter(train_dataset):\n",
        " model.fit(trainData, trainLabels,batch_size=batchSize, epochs=5)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "5867/5867 [==============================] - 9s 2ms/sample - loss: 0.6926 - acc: 0.5216\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6926 - acc: 0.5229\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6925 - acc: 0.5238\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6925 - acc: 0.5253\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6925 - acc: 0.5258\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6929 - acc: 0.5040\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6929 - acc: 0.5050\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6929 - acc: 0.5057\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6928 - acc: 0.5067\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6928 - acc: 0.5084\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6926 - acc: 0.5202\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6926 - acc: 0.5205\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6925 - acc: 0.5221\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6925 - acc: 0.5246\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6925 - acc: 0.5250\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6928 - acc: 0.5086\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6928 - acc: 0.5088\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6928 - acc: 0.5093\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6927 - acc: 0.5096\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6927 - acc: 0.5096\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6929 - acc: 0.5067\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6929 - acc: 0.5081\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6928 - acc: 0.5084\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6928 - acc: 0.5084\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6928 - acc: 0.5101\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6926 - acc: 0.5236\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6925 - acc: 0.5250\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6925 - acc: 0.5263\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6925 - acc: 0.5282\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6924 - acc: 0.5291\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6925 - acc: 0.5303\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6924 - acc: 0.5313\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6924 - acc: 0.5325\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6924 - acc: 0.5347\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6923 - acc: 0.5357\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6919 - acc: 0.5321\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6919 - acc: 0.5321\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6918 - acc: 0.5342\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6918 - acc: 0.5352\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6918 - acc: 0.5366\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6924 - acc: 0.5187\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6924 - acc: 0.5204\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6924 - acc: 0.5199\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6923 - acc: 0.5204\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6923 - acc: 0.5207\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6922 - acc: 0.5282\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6922 - acc: 0.5294\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6921 - acc: 0.5292\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6921 - acc: 0.5301\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6921 - acc: 0.5309\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6922 - acc: 0.5284\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6922 - acc: 0.5289\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6922 - acc: 0.5296\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6921 - acc: 0.5304\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6921 - acc: 0.5301\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6920 - acc: 0.5311\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6920 - acc: 0.5313\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6920 - acc: 0.5323\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6920 - acc: 0.5332\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6919 - acc: 0.5337\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6919 - acc: 0.5372\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6919 - acc: 0.5386\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6919 - acc: 0.5386\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6918 - acc: 0.5398\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6918 - acc: 0.5395\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6915 - acc: 0.5434\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6915 - acc: 0.5432\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6914 - acc: 0.5439\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6914 - acc: 0.5454\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6914 - acc: 0.5459\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6913 - acc: 0.5524\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6913 - acc: 0.5521\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6913 - acc: 0.5521\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6912 - acc: 0.5528\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6912 - acc: 0.5541\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6912 - acc: 0.5482\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6912 - acc: 0.5490\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6911 - acc: 0.5499\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6911 - acc: 0.5504\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6910 - acc: 0.5514\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6915 - acc: 0.5389\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6915 - acc: 0.5405\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6914 - acc: 0.5413\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6914 - acc: 0.5422\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6914 - acc: 0.5434\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6916 - acc: 0.5357\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6916 - acc: 0.5360\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6916 - acc: 0.5374\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6916 - acc: 0.5383\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6915 - acc: 0.5383\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6915 - acc: 0.5422\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6914 - acc: 0.5427\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6914 - acc: 0.5441\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6914 - acc: 0.5446\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6914 - acc: 0.5451\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6910 - acc: 0.5502\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6910 - acc: 0.5497\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6909 - acc: 0.5507\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6909 - acc: 0.5509\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6908 - acc: 0.5517\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 32us/sample - loss: 0.6910 - acc: 0.5444\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6910 - acc: 0.5442\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6909 - acc: 0.5434\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6909 - acc: 0.5444\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6909 - acc: 0.5451\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6911 - acc: 0.5412\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6911 - acc: 0.5418\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6910 - acc: 0.5418\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6910 - acc: 0.5427\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6910 - acc: 0.5435\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6906 - acc: 0.5534\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6906 - acc: 0.5534\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6906 - acc: 0.5545\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6905 - acc: 0.5555\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6905 - acc: 0.5560\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6906 - acc: 0.5538\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6906 - acc: 0.5534\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6906 - acc: 0.5539\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6906 - acc: 0.5539\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6905 - acc: 0.5546\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6907 - acc: 0.5502\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6906 - acc: 0.5510\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6906 - acc: 0.5516\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6906 - acc: 0.5521\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6905 - acc: 0.5517\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6905 - acc: 0.5488\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6905 - acc: 0.5505\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6904 - acc: 0.5519\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6904 - acc: 0.5524\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6904 - acc: 0.5543\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6899 - acc: 0.5589\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6898 - acc: 0.5592\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6898 - acc: 0.5603\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6898 - acc: 0.5606\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6897 - acc: 0.5616\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6902 - acc: 0.5499\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6901 - acc: 0.5500\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6901 - acc: 0.5514\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6900 - acc: 0.5517\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6900 - acc: 0.5519\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6899 - acc: 0.5575\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6898 - acc: 0.5567\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6898 - acc: 0.5580\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6898 - acc: 0.5577\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6897 - acc: 0.5580\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6904 - acc: 0.5470\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6903 - acc: 0.5466\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6903 - acc: 0.5470\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6903 - acc: 0.5468\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6902 - acc: 0.5461\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6896 - acc: 0.5596\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6896 - acc: 0.5596\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6895 - acc: 0.5594\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6895 - acc: 0.5597\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6895 - acc: 0.5601\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6889 - acc: 0.5742\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6889 - acc: 0.5741\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6888 - acc: 0.5741\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6888 - acc: 0.5751\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6887 - acc: 0.5756\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 32us/sample - loss: 0.6894 - acc: 0.5618\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6893 - acc: 0.5613\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6893 - acc: 0.5613\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6892 - acc: 0.5614\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6892 - acc: 0.5613\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6888 - acc: 0.5671\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6887 - acc: 0.5667\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6887 - acc: 0.5671\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6886 - acc: 0.5667\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6886 - acc: 0.5684\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6890 - acc: 0.5618\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6889 - acc: 0.5614\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6889 - acc: 0.5625\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6888 - acc: 0.5625\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6888 - acc: 0.5623\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6891 - acc: 0.5570\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6891 - acc: 0.5577\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6890 - acc: 0.5584\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6890 - acc: 0.5589\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6889 - acc: 0.5582\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6875 - acc: 0.5727\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6874 - acc: 0.5722\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6873 - acc: 0.5727\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6872 - acc: 0.5729\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6872 - acc: 0.5727\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6883 - acc: 0.5592\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6883 - acc: 0.5599\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6882 - acc: 0.5599\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6881 - acc: 0.5594\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6881 - acc: 0.5599\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6880 - acc: 0.5667\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6879 - acc: 0.5672\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6879 - acc: 0.5676\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6878 - acc: 0.5672\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6878 - acc: 0.5679\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6874 - acc: 0.5718\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6873 - acc: 0.5710\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6872 - acc: 0.5712\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6872 - acc: 0.5717\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6871 - acc: 0.5717\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6879 - acc: 0.5594\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6878 - acc: 0.5599\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6878 - acc: 0.5608\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6877 - acc: 0.5613\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6877 - acc: 0.5614\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6866 - acc: 0.5759\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6865 - acc: 0.5759\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6864 - acc: 0.5768\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6863 - acc: 0.5776\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6863 - acc: 0.5780\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6869 - acc: 0.5708\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6868 - acc: 0.5710\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6868 - acc: 0.5708\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6867 - acc: 0.5706\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6866 - acc: 0.5700\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6860 - acc: 0.5725\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6859 - acc: 0.5724\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6858 - acc: 0.5725\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6858 - acc: 0.5724\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6857 - acc: 0.5715\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6859 - acc: 0.5725\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6858 - acc: 0.5720\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6857 - acc: 0.5717\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6856 - acc: 0.5720\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6856 - acc: 0.5724\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6863 - acc: 0.5674\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6862 - acc: 0.5672\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6862 - acc: 0.5674\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6861 - acc: 0.5669\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6861 - acc: 0.5674\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6869 - acc: 0.5541\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6868 - acc: 0.5545\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6868 - acc: 0.5545\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6867 - acc: 0.5543\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6867 - acc: 0.5545\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6868 - acc: 0.5638\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6867 - acc: 0.5635\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6867 - acc: 0.5637\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6866 - acc: 0.5638\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6866 - acc: 0.5635\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6850 - acc: 0.5684\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6849 - acc: 0.5686\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6849 - acc: 0.5691\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6848 - acc: 0.5691\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6847 - acc: 0.5689\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6856 - acc: 0.5674\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6855 - acc: 0.5669\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6855 - acc: 0.5672\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6854 - acc: 0.5672\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6853 - acc: 0.5672\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6865 - acc: 0.5533\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6865 - acc: 0.5536\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6864 - acc: 0.5543\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6864 - acc: 0.5546\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6863 - acc: 0.5548\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6842 - acc: 0.5741\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6841 - acc: 0.5747\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6840 - acc: 0.5751\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6839 - acc: 0.5758\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6838 - acc: 0.5768\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6849 - acc: 0.5579\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6848 - acc: 0.5591\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6848 - acc: 0.5596\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6847 - acc: 0.5597\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6846 - acc: 0.5592\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6832 - acc: 0.5771\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6831 - acc: 0.5770\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6830 - acc: 0.5771\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6830 - acc: 0.5773\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6829 - acc: 0.5766\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6838 - acc: 0.5660\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6837 - acc: 0.5662\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6836 - acc: 0.5660\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6836 - acc: 0.5662\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6835 - acc: 0.5657\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6851 - acc: 0.5604\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6850 - acc: 0.5599\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6850 - acc: 0.5599\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6849 - acc: 0.5601\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6849 - acc: 0.5606\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6826 - acc: 0.5727\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6825 - acc: 0.5730\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6824 - acc: 0.5727\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6824 - acc: 0.5729\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6823 - acc: 0.5732\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6839 - acc: 0.5630\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6838 - acc: 0.5628\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6838 - acc: 0.5626\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6837 - acc: 0.5626\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6836 - acc: 0.5626\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6842 - acc: 0.5649\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6842 - acc: 0.5657\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6841 - acc: 0.5657\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6840 - acc: 0.5662\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6840 - acc: 0.5666\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6831 - acc: 0.5674\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6830 - acc: 0.5681\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6829 - acc: 0.5684\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6829 - acc: 0.5684\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6828 - acc: 0.5684\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6836 - acc: 0.5689\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6835 - acc: 0.5684\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6835 - acc: 0.5686\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6834 - acc: 0.5686\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6834 - acc: 0.5683\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6815 - acc: 0.5770\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6815 - acc: 0.5770\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6814 - acc: 0.5771\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6813 - acc: 0.5773\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6812 - acc: 0.5771\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6802 - acc: 0.5797\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6801 - acc: 0.5773\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6800 - acc: 0.5766\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6799 - acc: 0.5756\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6798 - acc: 0.5761\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6807 - acc: 0.5713\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6806 - acc: 0.5720\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6806 - acc: 0.5730\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6805 - acc: 0.5730\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6804 - acc: 0.5737\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6823 - acc: 0.5637\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6822 - acc: 0.5633\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6821 - acc: 0.5635\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6821 - acc: 0.5638\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6820 - acc: 0.5635\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6844 - acc: 0.5533\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6844 - acc: 0.5526\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6844 - acc: 0.5528\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6843 - acc: 0.5529\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6843 - acc: 0.5529\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6801 - acc: 0.5746\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6800 - acc: 0.5756\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6800 - acc: 0.5764\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6799 - acc: 0.5766\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6798 - acc: 0.5768\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6794 - acc: 0.5795\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6793 - acc: 0.5787\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6792 - acc: 0.5790\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6791 - acc: 0.5797\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6790 - acc: 0.5799\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6832 - acc: 0.5584\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6832 - acc: 0.5592\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6831 - acc: 0.5596\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6831 - acc: 0.5599\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6830 - acc: 0.5603\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6803 - acc: 0.5712\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6803 - acc: 0.5712\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6802 - acc: 0.5712\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6802 - acc: 0.5715\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6801 - acc: 0.5717\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6811 - acc: 0.5631\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6810 - acc: 0.5621\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6809 - acc: 0.5625\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6809 - acc: 0.5623\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6808 - acc: 0.5628\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6797 - acc: 0.5712\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6796 - acc: 0.5708\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6795 - acc: 0.5713\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6795 - acc: 0.5710\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6794 - acc: 0.5713\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6770 - acc: 0.5855\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6769 - acc: 0.5858\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6768 - acc: 0.5858\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6767 - acc: 0.5862\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6766 - acc: 0.5865\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6819 - acc: 0.5669\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6819 - acc: 0.5659\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6818 - acc: 0.5657\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6818 - acc: 0.5652\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6817 - acc: 0.5654\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6817 - acc: 0.5577\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6817 - acc: 0.5599\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6816 - acc: 0.5591\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6816 - acc: 0.5599\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6816 - acc: 0.5599\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6803 - acc: 0.5689\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6802 - acc: 0.5691\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6802 - acc: 0.5691\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6801 - acc: 0.5689\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6801 - acc: 0.5693\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6802 - acc: 0.5645\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6801 - acc: 0.5650\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6801 - acc: 0.5655\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6800 - acc: 0.5660\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6800 - acc: 0.5664\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6793 - acc: 0.5722\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6792 - acc: 0.5715\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6791 - acc: 0.5715\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6791 - acc: 0.5715\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6790 - acc: 0.5720\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6775 - acc: 0.5795\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6774 - acc: 0.5778\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6773 - acc: 0.5773\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6773 - acc: 0.5773\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6772 - acc: 0.5771\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6787 - acc: 0.5672\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6787 - acc: 0.5672\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6786 - acc: 0.5678\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6786 - acc: 0.5674\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6785 - acc: 0.5681\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6753 - acc: 0.5828\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6752 - acc: 0.5824\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6751 - acc: 0.5822\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6750 - acc: 0.5826\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6749 - acc: 0.5824\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6772 - acc: 0.5729\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6771 - acc: 0.5717\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6770 - acc: 0.5725\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6770 - acc: 0.5727\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6769 - acc: 0.5730\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6784 - acc: 0.5703\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6783 - acc: 0.5696\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6783 - acc: 0.5688\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6782 - acc: 0.5683\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6782 - acc: 0.5689\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6796 - acc: 0.5735\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6796 - acc: 0.5724\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6795 - acc: 0.5729\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6795 - acc: 0.5730\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6794 - acc: 0.5732\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6799 - acc: 0.5686\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6799 - acc: 0.5701\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6798 - acc: 0.5696\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6797 - acc: 0.5703\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6797 - acc: 0.5705\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6789 - acc: 0.5696\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6789 - acc: 0.5703\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6788 - acc: 0.5700\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6788 - acc: 0.5700\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6787 - acc: 0.5701\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6760 - acc: 0.5788\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6759 - acc: 0.5788\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6759 - acc: 0.5790\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6758 - acc: 0.5790\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6757 - acc: 0.5790\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6737 - acc: 0.5826\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6736 - acc: 0.5828\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6735 - acc: 0.5828\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6734 - acc: 0.5828\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6733 - acc: 0.5831\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6760 - acc: 0.5795\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6759 - acc: 0.5795\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6759 - acc: 0.5800\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6758 - acc: 0.5802\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6757 - acc: 0.5802\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6774 - acc: 0.5679\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6773 - acc: 0.5683\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6773 - acc: 0.5683\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6772 - acc: 0.5683\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6771 - acc: 0.5684\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6741 - acc: 0.5821\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6740 - acc: 0.5826\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6739 - acc: 0.5833\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6738 - acc: 0.5834\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6737 - acc: 0.5834\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6763 - acc: 0.5753\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6762 - acc: 0.5763\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6762 - acc: 0.5764\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6761 - acc: 0.5770\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6760 - acc: 0.5770\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6740 - acc: 0.5795\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6739 - acc: 0.5793\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6738 - acc: 0.5788\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6737 - acc: 0.5792\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6737 - acc: 0.5795\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6763 - acc: 0.5761\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6762 - acc: 0.5746\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6762 - acc: 0.5746\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6761 - acc: 0.5746\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6760 - acc: 0.5753\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6743 - acc: 0.5780\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6742 - acc: 0.5781\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6741 - acc: 0.5785\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6741 - acc: 0.5781\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6740 - acc: 0.5781\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6760 - acc: 0.5720\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6759 - acc: 0.5754\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6759 - acc: 0.5761\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6758 - acc: 0.5764\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6757 - acc: 0.5759\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6751 - acc: 0.5761\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6750 - acc: 0.5771\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6749 - acc: 0.5778\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6749 - acc: 0.5780\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6748 - acc: 0.5780\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6762 - acc: 0.5693\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6762 - acc: 0.5695\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6761 - acc: 0.5696\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6760 - acc: 0.5703\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6760 - acc: 0.5705\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6745 - acc: 0.5788\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6744 - acc: 0.5788\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6744 - acc: 0.5790\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6743 - acc: 0.5788\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6742 - acc: 0.5795\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6743 - acc: 0.5809\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6743 - acc: 0.5816\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6742 - acc: 0.5819\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6741 - acc: 0.5819\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6740 - acc: 0.5822\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6740 - acc: 0.5797\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6739 - acc: 0.5805\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6739 - acc: 0.5809\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6738 - acc: 0.5807\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6737 - acc: 0.5809\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6765 - acc: 0.5691\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6764 - acc: 0.5693\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6763 - acc: 0.5701\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6762 - acc: 0.5701\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6762 - acc: 0.5712\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6732 - acc: 0.5792\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6731 - acc: 0.5797\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6730 - acc: 0.5805\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6729 - acc: 0.5805\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6728 - acc: 0.5807\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6713 - acc: 0.5955\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6712 - acc: 0.5943\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6712 - acc: 0.5943\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6711 - acc: 0.5942\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6710 - acc: 0.5940\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6674 - acc: 0.6013\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6673 - acc: 0.6022\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6672 - acc: 0.6020\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6671 - acc: 0.6022\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6670 - acc: 0.6022\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6710 - acc: 0.5848\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6709 - acc: 0.5862\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6708 - acc: 0.5860\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6707 - acc: 0.5867\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6706 - acc: 0.5865\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6701 - acc: 0.5879\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6700 - acc: 0.5879\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6699 - acc: 0.5877\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6698 - acc: 0.5879\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6698 - acc: 0.5879\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6711 - acc: 0.5787\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6710 - acc: 0.5787\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6710 - acc: 0.5788\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6709 - acc: 0.5793\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6708 - acc: 0.5793\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6715 - acc: 0.5834\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6715 - acc: 0.5834\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6714 - acc: 0.5836\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6713 - acc: 0.5839\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6712 - acc: 0.5838\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6734 - acc: 0.5787\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6733 - acc: 0.5790\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6733 - acc: 0.5793\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6732 - acc: 0.5795\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6731 - acc: 0.5797\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6723 - acc: 0.5770\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6722 - acc: 0.5770\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6721 - acc: 0.5770\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6720 - acc: 0.5768\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6720 - acc: 0.5775\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6700 - acc: 0.5838\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6699 - acc: 0.5833\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6699 - acc: 0.5831\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6698 - acc: 0.5834\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6697 - acc: 0.5843\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6703 - acc: 0.5926\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6702 - acc: 0.5904\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6701 - acc: 0.5899\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6700 - acc: 0.5908\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6699 - acc: 0.5909\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6709 - acc: 0.5768\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6708 - acc: 0.5770\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6708 - acc: 0.5764\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6707 - acc: 0.5771\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6706 - acc: 0.5773\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6684 - acc: 0.5940\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6683 - acc: 0.5949\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6682 - acc: 0.5947\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6681 - acc: 0.5943\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6680 - acc: 0.5945\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6699 - acc: 0.5862\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6698 - acc: 0.5863\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6697 - acc: 0.5865\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6696 - acc: 0.5865\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6695 - acc: 0.5870\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6688 - acc: 0.5858\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6687 - acc: 0.5865\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6686 - acc: 0.5865\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6685 - acc: 0.5870\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6684 - acc: 0.5872\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6686 - acc: 0.5872\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6685 - acc: 0.5874\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6685 - acc: 0.5880\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6684 - acc: 0.5880\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6683 - acc: 0.5884\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6699 - acc: 0.5793\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6698 - acc: 0.5776\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6697 - acc: 0.5780\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6696 - acc: 0.5781\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6695 - acc: 0.5783\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6690 - acc: 0.5988\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6689 - acc: 0.5986\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6688 - acc: 0.5991\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6687 - acc: 0.5991\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6686 - acc: 0.5989\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6708 - acc: 0.5889\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6707 - acc: 0.5904\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6706 - acc: 0.5911\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6705 - acc: 0.5913\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6704 - acc: 0.5918\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6672 - acc: 0.5855\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6671 - acc: 0.5862\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6670 - acc: 0.5868\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6669 - acc: 0.5868\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6668 - acc: 0.5868\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6663 - acc: 0.5964\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6662 - acc: 0.5964\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6661 - acc: 0.5967\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6661 - acc: 0.5969\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6660 - acc: 0.5971\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6675 - acc: 0.5978\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6674 - acc: 0.5972\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6673 - acc: 0.5972\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6672 - acc: 0.5969\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6672 - acc: 0.5971\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6663 - acc: 0.5947\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6662 - acc: 0.5937\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6661 - acc: 0.5937\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6660 - acc: 0.5940\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6659 - acc: 0.5945\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6687 - acc: 0.5868\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6686 - acc: 0.5868\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6685 - acc: 0.5872\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6684 - acc: 0.5870\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6683 - acc: 0.5868\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6668 - acc: 0.5943\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6668 - acc: 0.5950\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6667 - acc: 0.5959\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6666 - acc: 0.5957\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6665 - acc: 0.5960\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6667 - acc: 0.5891\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6666 - acc: 0.5903\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6665 - acc: 0.5904\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6664 - acc: 0.5903\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6663 - acc: 0.5909\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6666 - acc: 0.5957\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6665 - acc: 0.5964\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6663 - acc: 0.5966\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6662 - acc: 0.5967\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6661 - acc: 0.5967\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6683 - acc: 0.5889\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6682 - acc: 0.5892\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6681 - acc: 0.5896\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6680 - acc: 0.5899\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6679 - acc: 0.5897\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6650 - acc: 0.5899\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6649 - acc: 0.5909\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6648 - acc: 0.5909\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6647 - acc: 0.5909\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6646 - acc: 0.5916\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6635 - acc: 0.5991\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6634 - acc: 0.5998\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6633 - acc: 0.6005\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6632 - acc: 0.6010\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6630 - acc: 0.6015\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6623 - acc: 0.6080\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6622 - acc: 0.6061\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6620 - acc: 0.6071\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6619 - acc: 0.6075\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6618 - acc: 0.6076\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6650 - acc: 0.5986\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6649 - acc: 0.5981\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6648 - acc: 0.5986\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6646 - acc: 0.5986\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6645 - acc: 0.5991\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6631 - acc: 0.5964\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6630 - acc: 0.5966\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6629 - acc: 0.5971\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6627 - acc: 0.5972\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6626 - acc: 0.5976\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6653 - acc: 0.5908\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6652 - acc: 0.5903\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6650 - acc: 0.5911\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6649 - acc: 0.5911\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6648 - acc: 0.5914\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6639 - acc: 0.5962\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6638 - acc: 0.5960\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6637 - acc: 0.5949\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6636 - acc: 0.5957\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6635 - acc: 0.5955\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6681 - acc: 0.5877\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6679 - acc: 0.5896\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6678 - acc: 0.5899\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6677 - acc: 0.5909\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6675 - acc: 0.5908\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6634 - acc: 0.5976\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6633 - acc: 0.5979\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6632 - acc: 0.5971\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6631 - acc: 0.5978\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6629 - acc: 0.5986\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6630 - acc: 0.5942\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6628 - acc: 0.5960\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6627 - acc: 0.5954\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6626 - acc: 0.5967\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6625 - acc: 0.5969\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6626 - acc: 0.6017\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6624 - acc: 0.6018\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6623 - acc: 0.6024\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6622 - acc: 0.6027\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6621 - acc: 0.6024\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6641 - acc: 0.5988\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6640 - acc: 0.6017\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6639 - acc: 0.6010\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6638 - acc: 0.6015\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6637 - acc: 0.6017\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6618 - acc: 0.6061\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6617 - acc: 0.6073\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6616 - acc: 0.6073\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6614 - acc: 0.6078\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6613 - acc: 0.6080\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6591 - acc: 0.6095\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6590 - acc: 0.6081\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6589 - acc: 0.6093\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6587 - acc: 0.6087\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6586 - acc: 0.6085\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6587 - acc: 0.6150\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6585 - acc: 0.6153\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6584 - acc: 0.6153\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6583 - acc: 0.6155\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6581 - acc: 0.6158\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6615 - acc: 0.6047\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6614 - acc: 0.6046\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6612 - acc: 0.6054\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6611 - acc: 0.6058\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6610 - acc: 0.6066\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6585 - acc: 0.6081\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6584 - acc: 0.6073\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6583 - acc: 0.6088\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6581 - acc: 0.6081\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6580 - acc: 0.6083\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6587 - acc: 0.6020\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6586 - acc: 0.6066\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6585 - acc: 0.6042\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6583 - acc: 0.6059\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6582 - acc: 0.6052\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6596 - acc: 0.6102\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6594 - acc: 0.6090\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6593 - acc: 0.6121\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6591 - acc: 0.6102\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6590 - acc: 0.6122\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6612 - acc: 0.6080\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6611 - acc: 0.6110\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6609 - acc: 0.6097\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6608 - acc: 0.6107\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6607 - acc: 0.6100\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6531 - acc: 0.6317\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6529 - acc: 0.6317\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6527 - acc: 0.6317\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6526 - acc: 0.6318\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6524 - acc: 0.6320\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6604 - acc: 0.6037\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6603 - acc: 0.6029\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6601 - acc: 0.6041\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6600 - acc: 0.6044\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6599 - acc: 0.6051\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6599 - acc: 0.6143\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6598 - acc: 0.6151\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6596 - acc: 0.6160\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6595 - acc: 0.6158\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6593 - acc: 0.6175\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6555 - acc: 0.6155\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6554 - acc: 0.6148\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6552 - acc: 0.6158\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6551 - acc: 0.6145\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6549 - acc: 0.6162\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6557 - acc: 0.6213\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6556 - acc: 0.6201\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6554 - acc: 0.6214\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6553 - acc: 0.6213\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6551 - acc: 0.6220\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6553 - acc: 0.6153\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6552 - acc: 0.6196\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6550 - acc: 0.6165\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6548 - acc: 0.6196\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6547 - acc: 0.6174\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6560 - acc: 0.6168\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6558 - acc: 0.6145\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6557 - acc: 0.6174\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6556 - acc: 0.6151\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6555 - acc: 0.6182\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6527 - acc: 0.6226\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6525 - acc: 0.6260\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6524 - acc: 0.6226\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6522 - acc: 0.6259\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6521 - acc: 0.6235\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6544 - acc: 0.6134\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6543 - acc: 0.6165\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6541 - acc: 0.6148\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6540 - acc: 0.6191\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6539 - acc: 0.6168\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6521 - acc: 0.6259\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6521 - acc: 0.6281\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6520 - acc: 0.6257\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6520 - acc: 0.6283\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6521 - acc: 0.6235\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6577 - acc: 0.6126\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6582 - acc: 0.6022\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6589 - acc: 0.6109\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6600 - acc: 0.5923\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6616 - acc: 0.6066\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6618 - acc: 0.5879\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6652 - acc: 0.5957\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6691 - acc: 0.5689\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6735 - acc: 0.5810\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6763 - acc: 0.5509\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6812 - acc: 0.5793\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6784 - acc: 0.5359\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6762 - acc: 0.5851\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6712 - acc: 0.5528\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6679 - acc: 0.5996\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6654 - acc: 0.5778\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6632 - acc: 0.6088\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6612 - acc: 0.5903\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6599 - acc: 0.6184\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6588 - acc: 0.5983\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6531 - acc: 0.6370\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6525 - acc: 0.6160\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6521 - acc: 0.6376\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6517 - acc: 0.6220\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6514 - acc: 0.6392\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6562 - acc: 0.6075\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6559 - acc: 0.6293\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6556 - acc: 0.6092\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6554 - acc: 0.6286\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6552 - acc: 0.6097\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6527 - acc: 0.6296\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6526 - acc: 0.6206\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6524 - acc: 0.6291\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6523 - acc: 0.6197\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6522 - acc: 0.6293\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6503 - acc: 0.6211\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6502 - acc: 0.6390\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6502 - acc: 0.6189\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6502 - acc: 0.6383\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6503 - acc: 0.6175\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6522 - acc: 0.6262\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6525 - acc: 0.6189\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6529 - acc: 0.6257\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6535 - acc: 0.6141\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6543 - acc: 0.6237\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6561 - acc: 0.6022\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6575 - acc: 0.6211\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6587 - acc: 0.5945\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6605 - acc: 0.6122\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6618 - acc: 0.5817\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6641 - acc: 0.5955\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6652 - acc: 0.5730\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6663 - acc: 0.5908\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6654 - acc: 0.5708\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6649 - acc: 0.5938\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6611 - acc: 0.5799\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6597 - acc: 0.6080\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6576 - acc: 0.5865\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6562 - acc: 0.6170\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6545 - acc: 0.5947\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6527 - acc: 0.6296\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6516 - acc: 0.6042\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6509 - acc: 0.6320\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6501 - acc: 0.6099\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6497 - acc: 0.6361\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6491 - acc: 0.6240\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6488 - acc: 0.6341\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6486 - acc: 0.6259\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6484 - acc: 0.6344\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6483 - acc: 0.6260\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6515 - acc: 0.6260\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6514 - acc: 0.6163\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6514 - acc: 0.6262\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6513 - acc: 0.6168\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6514 - acc: 0.6262\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6502 - acc: 0.6160\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6503 - acc: 0.6334\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6504 - acc: 0.6124\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6507 - acc: 0.6305\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6508 - acc: 0.6087\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6556 - acc: 0.6218\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6559 - acc: 0.6017\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6564 - acc: 0.6184\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6566 - acc: 0.5996\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6570 - acc: 0.6160\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6515 - acc: 0.6052\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6520 - acc: 0.6208\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6520 - acc: 0.6035\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6525 - acc: 0.6189\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6524 - acc: 0.6012\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6554 - acc: 0.6172\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6552 - acc: 0.5995\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6555 - acc: 0.6177\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6548 - acc: 0.6000\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6547 - acc: 0.6172\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6570 - acc: 0.5967\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6562 - acc: 0.6146\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6548 - acc: 0.6037\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6540 - acc: 0.6202\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6529 - acc: 0.6080\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6517 - acc: 0.6269\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6510 - acc: 0.6148\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6505 - acc: 0.6288\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6500 - acc: 0.6177\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6497 - acc: 0.6288\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6452 - acc: 0.6238\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6450 - acc: 0.6376\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6448 - acc: 0.6250\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6448 - acc: 0.6381\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6446 - acc: 0.6240\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6515 - acc: 0.6288\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6515 - acc: 0.6066\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6518 - acc: 0.6269\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6518 - acc: 0.6071\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6522 - acc: 0.6286\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6517 - acc: 0.6073\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6523 - acc: 0.6191\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6524 - acc: 0.6044\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6530 - acc: 0.6160\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6530 - acc: 0.6018\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6473 - acc: 0.6276\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6471 - acc: 0.6122\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6477 - acc: 0.6264\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6474 - acc: 0.6107\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6479 - acc: 0.6257\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6520 - acc: 0.5974\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6521 - acc: 0.6225\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6515 - acc: 0.5981\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6515 - acc: 0.6230\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6508 - acc: 0.6017\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6483 - acc: 0.6289\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6478 - acc: 0.6145\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6479 - acc: 0.6300\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6473 - acc: 0.6155\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6474 - acc: 0.6306\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6506 - acc: 0.6078\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6506 - acc: 0.6225\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6502 - acc: 0.6088\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6503 - acc: 0.6231\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6500 - acc: 0.6093\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6512 - acc: 0.6228\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6508 - acc: 0.6097\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6509 - acc: 0.6228\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6505 - acc: 0.6112\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6505 - acc: 0.6233\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6506 - acc: 0.6151\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6506 - acc: 0.6230\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6503 - acc: 0.6160\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6503 - acc: 0.6230\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6501 - acc: 0.6162\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6476 - acc: 0.6352\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6476 - acc: 0.6208\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6479 - acc: 0.6339\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6480 - acc: 0.6189\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6485 - acc: 0.6330\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6487 - acc: 0.6131\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6495 - acc: 0.6281\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6498 - acc: 0.6085\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6507 - acc: 0.6254\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6510 - acc: 0.6042\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6559 - acc: 0.6196\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6555 - acc: 0.5906\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6557 - acc: 0.6202\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6549 - acc: 0.5925\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6547 - acc: 0.6209\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6533 - acc: 0.6139\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6529 - acc: 0.6155\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6517 - acc: 0.6153\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6513 - acc: 0.6187\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6503 - acc: 0.6192\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6457 - acc: 0.6404\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6450 - acc: 0.6182\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6447 - acc: 0.6421\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6441 - acc: 0.6191\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6440 - acc: 0.6433\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6457 - acc: 0.6197\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6458 - acc: 0.6322\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6457 - acc: 0.6185\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6460 - acc: 0.6312\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6461 - acc: 0.6167\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6410 - acc: 0.6426\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6414 - acc: 0.6255\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6421 - acc: 0.6380\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6427 - acc: 0.6228\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6437 - acc: 0.6359\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6500 - acc: 0.6081\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6506 - acc: 0.6281\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6499 - acc: 0.6085\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6503 - acc: 0.6291\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6492 - acc: 0.6100\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6507 - acc: 0.6174\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6503 - acc: 0.6061\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6505 - acc: 0.6177\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6499 - acc: 0.6066\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6501 - acc: 0.6189\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6525 - acc: 0.6003\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6520 - acc: 0.6237\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6506 - acc: 0.6070\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6500 - acc: 0.6277\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6490 - acc: 0.6110\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6431 - acc: 0.6376\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6425 - acc: 0.6249\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6425 - acc: 0.6378\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6421 - acc: 0.6262\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6423 - acc: 0.6385\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6442 - acc: 0.6271\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6443 - acc: 0.6342\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6439 - acc: 0.6284\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6440 - acc: 0.6354\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6438 - acc: 0.6276\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 32us/sample - loss: 0.6456 - acc: 0.6332\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6454 - acc: 0.6250\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6458 - acc: 0.6325\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6456 - acc: 0.6247\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6460 - acc: 0.6324\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6449 - acc: 0.6179\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6455 - acc: 0.6315\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6454 - acc: 0.6162\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6462 - acc: 0.6318\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6460 - acc: 0.6146\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6463 - acc: 0.6283\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6460 - acc: 0.6174\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6468 - acc: 0.6264\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6462 - acc: 0.6165\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6468 - acc: 0.6269\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6481 - acc: 0.6102\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6483 - acc: 0.6228\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6472 - acc: 0.6121\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6472 - acc: 0.6254\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6462 - acc: 0.6145\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6460 - acc: 0.6337\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6447 - acc: 0.6180\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6444 - acc: 0.6327\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6433 - acc: 0.6228\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6431 - acc: 0.6370\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6415 - acc: 0.6271\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6416 - acc: 0.6397\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6413 - acc: 0.6283\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6415 - acc: 0.6404\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6414 - acc: 0.6269\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6463 - acc: 0.6347\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6461 - acc: 0.6139\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6467 - acc: 0.6347\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6464 - acc: 0.6150\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6470 - acc: 0.6324\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6384 - acc: 0.6378\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6392 - acc: 0.6383\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6394 - acc: 0.6354\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6405 - acc: 0.6364\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6408 - acc: 0.6296\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6462 - acc: 0.6330\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6457 - acc: 0.6151\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6465 - acc: 0.6335\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6454 - acc: 0.6165\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6456 - acc: 0.6341\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6487 - acc: 0.6068\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6485 - acc: 0.6289\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6469 - acc: 0.6099\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6465 - acc: 0.6322\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6453 - acc: 0.6155\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6438 - acc: 0.6283\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6428 - acc: 0.6260\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6426 - acc: 0.6315\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6419 - acc: 0.6289\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6419 - acc: 0.6335\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6458 - acc: 0.6231\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6458 - acc: 0.6301\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6456 - acc: 0.6255\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6458 - acc: 0.6310\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6456 - acc: 0.6250\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6418 - acc: 0.6349\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6418 - acc: 0.6228\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6426 - acc: 0.6330\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6427 - acc: 0.6197\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6438 - acc: 0.6308\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6443 - acc: 0.6228\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6455 - acc: 0.6293\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6452 - acc: 0.6231\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6461 - acc: 0.6291\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6453 - acc: 0.6231\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6488 - acc: 0.6189\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6475 - acc: 0.6104\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6476 - acc: 0.6189\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6462 - acc: 0.6155\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6461 - acc: 0.6228\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6417 - acc: 0.6264\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6416 - acc: 0.6358\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6405 - acc: 0.6291\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6405 - acc: 0.6390\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6397 - acc: 0.6308\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6389 - acc: 0.6359\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6383 - acc: 0.6322\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6385 - acc: 0.6364\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6381 - acc: 0.6335\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6386 - acc: 0.6354\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6451 - acc: 0.6184\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6459 - acc: 0.6313\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6451 - acc: 0.6177\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6457 - acc: 0.6313\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6448 - acc: 0.6180\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6452 - acc: 0.6221\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6439 - acc: 0.6238\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6442 - acc: 0.6249\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6427 - acc: 0.6255\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6428 - acc: 0.6305\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6402 - acc: 0.6266\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6400 - acc: 0.6383\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6389 - acc: 0.6305\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6387 - acc: 0.6400\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6378 - acc: 0.6327\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6314 - acc: 0.6550\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6310 - acc: 0.6470\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6311 - acc: 0.6557\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6310 - acc: 0.6477\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6315 - acc: 0.6555\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6374 - acc: 0.6370\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6378 - acc: 0.6443\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6377 - acc: 0.6347\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6384 - acc: 0.6414\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6385 - acc: 0.6364\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6371 - acc: 0.6407\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6374 - acc: 0.6308\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6392 - acc: 0.6356\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6394 - acc: 0.6245\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6412 - acc: 0.6313\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6464 - acc: 0.6124\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6475 - acc: 0.6233\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6462 - acc: 0.6127\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6468 - acc: 0.6247\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6451 - acc: 0.6138\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6386 - acc: 0.6393\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6374 - acc: 0.6262\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6379 - acc: 0.6417\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6367 - acc: 0.6262\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6372 - acc: 0.6427\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6393 - acc: 0.6235\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6396 - acc: 0.6354\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6387 - acc: 0.6238\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6391 - acc: 0.6364\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6383 - acc: 0.6249\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6393 - acc: 0.6426\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6387 - acc: 0.6354\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6389 - acc: 0.6421\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6384 - acc: 0.6347\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6387 - acc: 0.6419\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6410 - acc: 0.6283\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6414 - acc: 0.6337\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6410 - acc: 0.6279\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6414 - acc: 0.6342\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6410 - acc: 0.6267\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6387 - acc: 0.6426\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6384 - acc: 0.6325\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6392 - acc: 0.6424\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6390 - acc: 0.6305\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6400 - acc: 0.6400\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6370 - acc: 0.6301\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6378 - acc: 0.6433\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6373 - acc: 0.6291\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6381 - acc: 0.6421\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6375 - acc: 0.6289\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6421 - acc: 0.6286\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6413 - acc: 0.6283\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6419 - acc: 0.6296\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6407 - acc: 0.6301\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6410 - acc: 0.6312\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6375 - acc: 0.6337\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6375 - acc: 0.6412\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6362 - acc: 0.6368\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6360 - acc: 0.6451\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6348 - acc: 0.6385\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6345 - acc: 0.6439\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6336 - acc: 0.6409\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6337 - acc: 0.6468\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6330 - acc: 0.6410\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6333 - acc: 0.6467\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6319 - acc: 0.6451\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6325 - acc: 0.6496\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6325 - acc: 0.6412\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6336 - acc: 0.6477\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6338 - acc: 0.6370\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6445 - acc: 0.6329\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6440 - acc: 0.6172\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6451 - acc: 0.6318\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6440 - acc: 0.6172\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6448 - acc: 0.6317\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6406 - acc: 0.6272\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6409 - acc: 0.6356\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6392 - acc: 0.6281\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6393 - acc: 0.6395\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6377 - acc: 0.6295\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6398 - acc: 0.6351\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6384 - acc: 0.6375\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6384 - acc: 0.6378\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6374 - acc: 0.6383\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6374 - acc: 0.6395\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6312 - acc: 0.6392\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6315 - acc: 0.6456\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6310 - acc: 0.6399\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6317 - acc: 0.6434\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6314 - acc: 0.6395\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6297 - acc: 0.6484\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6297 - acc: 0.6395\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6313 - acc: 0.6465\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6315 - acc: 0.6364\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6335 - acc: 0.6404\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6407 - acc: 0.6257\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6428 - acc: 0.6308\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6416 - acc: 0.6231\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6431 - acc: 0.6306\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6409 - acc: 0.6252\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6452 - acc: 0.6317\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6418 - acc: 0.6156\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6411 - acc: 0.6387\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6384 - acc: 0.6233\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6377 - acc: 0.6446\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6372 - acc: 0.6380\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6367 - acc: 0.6393\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6355 - acc: 0.6421\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6352 - acc: 0.6416\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6344 - acc: 0.6433\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6322 - acc: 0.6473\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6317 - acc: 0.6450\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6316 - acc: 0.6475\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6313 - acc: 0.6453\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6314 - acc: 0.6482\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6287 - acc: 0.6492\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6289 - acc: 0.6589\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6289 - acc: 0.6485\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6296 - acc: 0.6559\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6302 - acc: 0.6419\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6347 - acc: 0.6441\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6362 - acc: 0.6383\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6397 - acc: 0.6330\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6414 - acc: 0.6220\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6463 - acc: 0.6223\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6478 - acc: 0.6122\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6506 - acc: 0.6131\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6453 - acc: 0.6145\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6449 - acc: 0.6218\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6392 - acc: 0.6312\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6372 - acc: 0.6347\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6341 - acc: 0.6410\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6331 - acc: 0.6414\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6314 - acc: 0.6509\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6308 - acc: 0.6492\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6305 - acc: 0.6422\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6303 - acc: 0.6584\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6298 - acc: 0.6441\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6298 - acc: 0.6588\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6296 - acc: 0.6434\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6299 - acc: 0.6528\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6298 - acc: 0.6405\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6303 - acc: 0.6538\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6305 - acc: 0.6385\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6315 - acc: 0.6511\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6325 - acc: 0.6433\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6341 - acc: 0.6441\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6350 - acc: 0.6376\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6375 - acc: 0.6366\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6380 - acc: 0.6305\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6371 - acc: 0.6404\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6360 - acc: 0.6344\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6373 - acc: 0.6416\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6353 - acc: 0.6363\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6361 - acc: 0.6419\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6324 - acc: 0.6387\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6331 - acc: 0.6421\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6318 - acc: 0.6393\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6324 - acc: 0.6424\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6312 - acc: 0.6410\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6349 - acc: 0.6375\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6338 - acc: 0.6376\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6343 - acc: 0.6381\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6333 - acc: 0.6366\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6339 - acc: 0.6397\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6316 - acc: 0.6421\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6324 - acc: 0.6496\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6318 - acc: 0.6407\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6328 - acc: 0.6502\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6322 - acc: 0.6393\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6369 - acc: 0.6342\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6364 - acc: 0.6388\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6378 - acc: 0.6334\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6369 - acc: 0.6376\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6380 - acc: 0.6318\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6325 - acc: 0.6361\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6336 - acc: 0.6429\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6320 - acc: 0.6370\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6331 - acc: 0.6436\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6316 - acc: 0.6375\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6279 - acc: 0.6485\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6266 - acc: 0.6443\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6278 - acc: 0.6485\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6264 - acc: 0.6450\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6276 - acc: 0.6494\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6247 - acc: 0.6485\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6256 - acc: 0.6516\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6244 - acc: 0.6492\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6254 - acc: 0.6520\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6241 - acc: 0.6492\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6340 - acc: 0.6335\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6321 - acc: 0.6445\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6328 - acc: 0.6363\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6308 - acc: 0.6463\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6312 - acc: 0.6381\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6345 - acc: 0.6332\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6342 - acc: 0.6421\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6324 - acc: 0.6393\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6320 - acc: 0.6482\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6306 - acc: 0.6439\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6304 - acc: 0.6504\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6296 - acc: 0.6445\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6296 - acc: 0.6497\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6291 - acc: 0.6455\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6293 - acc: 0.6506\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6241 - acc: 0.6520\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6244 - acc: 0.6552\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6242 - acc: 0.6523\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6250 - acc: 0.6520\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6252 - acc: 0.6494\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6388 - acc: 0.6344\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6394 - acc: 0.6283\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6423 - acc: 0.6279\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6420 - acc: 0.6259\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6449 - acc: 0.6223\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6345 - acc: 0.6245\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6372 - acc: 0.6385\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6325 - acc: 0.6301\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6333 - acc: 0.6456\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6289 - acc: 0.6400\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6311 - acc: 0.6467\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6277 - acc: 0.6421\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6271 - acc: 0.6518\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6250 - acc: 0.6502\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6246 - acc: 0.6547\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6294 - acc: 0.6501\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6293 - acc: 0.6492\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6284 - acc: 0.6518\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6285 - acc: 0.6509\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6279 - acc: 0.6531\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6294 - acc: 0.6479\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6290 - acc: 0.6455\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6296 - acc: 0.6467\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6293 - acc: 0.6445\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6301 - acc: 0.6465\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6247 - acc: 0.6581\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6258 - acc: 0.6548\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6257 - acc: 0.6574\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6271 - acc: 0.6518\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6268 - acc: 0.6528\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6285 - acc: 0.6473\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6284 - acc: 0.6429\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6309 - acc: 0.6421\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6300 - acc: 0.6409\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6323 - acc: 0.6414\n",
            "Train on 5867 samples\n",
            "Epoch 1/5\n",
            "5867/5867 [==============================] - 0s 31us/sample - loss: 0.6312 - acc: 0.6373\n",
            "Epoch 2/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6331 - acc: 0.6426\n",
            "Epoch 3/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6301 - acc: 0.6392\n",
            "Epoch 4/5\n",
            "5867/5867 [==============================] - 0s 29us/sample - loss: 0.6311 - acc: 0.6462\n",
            "Epoch 5/5\n",
            "5867/5867 [==============================] - 0s 30us/sample - loss: 0.6280 - acc: 0.6443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnfE8GAOl1hO",
        "colab_type": "text"
      },
      "source": [
        "###Validating the model\n",
        "####To measure the performance and verify our model, lets import the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdMASdpvXrE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import validation data\n",
        "labelsValidationDf=pd.read_csv('data/labels_validation.txt', sep=',',header=None)\n",
        "dataValidationDf=pd.read_csv('data/inserts_validation.txt', sep=',',header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyfPhpTpmJH4",
        "colab_type": "text"
      },
      "source": [
        "####Lets inspect the size of our validation labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eY2zctmYMDD",
        "colab_type": "code",
        "outputId": "10504490-7c5d-4a3a-e918-74912687d0ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#verify the length of validation set labels\n",
        "len(labelsValidationDf)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "177482"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id8bfVrmmT8O",
        "colab_type": "text"
      },
      "source": [
        "####Lets inspect the size of validation data and confirm that it is of same size as the validation set labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofRASI86YOpm",
        "colab_type": "code",
        "outputId": "39f5bbd5-0fc6-4b19-9ded-f78ddb7eaddf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#verify the length of validation set data\n",
        "len(dataValidationDf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "177482"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI7hmx1smjHe",
        "colab_type": "text"
      },
      "source": [
        "####Lets define a batch set generator for our validation data, this time without splitting the dataset into smaller chunks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y-tvZ1nYBPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define a generator to reshape our dataset and zip it to be more manageable\n",
        "validationSetSize=len(labelsValidationDf)\n",
        "def geneneratorValidation():\n",
        "        npArr = np.array(dataValidationDf.values)\n",
        "        yield npArr.reshape([validationSetSize,4,200,-1]), labelsValidationDf\n",
        "#create a tensor for our training dataset\n",
        "validation_dataset = tf.data.Dataset.from_generator(geneneratorValidation,output_shapes=([validationSetSize,4,200,1],[validationSetSize,1]),output_types=(tf.float32, tf.float32)) \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oil63k7Tm1mU",
        "colab_type": "text"
      },
      "source": [
        "####Define an iterator for the set so that we can use the set for evaluating our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiWey8IuZEGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validationData, validationLabels = next(iter(validation_dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Iny-S3snFJa",
        "colab_type": "text"
      },
      "source": [
        "####Validate our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fdy8I3qxZL4-",
        "colab_type": "code",
        "outputId": "37c84c37-3f11-4be3-9e12-efe467ea79a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "#Validate our model against validation data\n",
        "validation_loss, validation_accuracy = model.evaluate(validationData, validationLabels)\n",
        "print('Validation accuracy:', validation_accuracy)\n",
        "print('Validation loss:', validation_loss)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy: 0.64423436\n",
            "Validation loss: 0.632491766409034\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm12-G3BnPX4",
        "colab_type": "text"
      },
      "source": [
        "###Receiver Operating Characteristics (ROC)\n",
        "####We will calculate the ROC and the area under the curve (AUC) for a performance benchmark of our neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeZc0QXsNR4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get predictions on validation data\n",
        "prediction=model.predict(validationData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DuzXNaON36x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        " \n",
        "fpr , tpr , thresholds = roc_curve ( validationLabels , prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua-wyIU8N-Lt",
        "colab_type": "code",
        "outputId": "9355ece2-d360-4f68-8c05-dfcac94d8a7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "# Plot ROC Curve\n",
        "def plot_roc_curve(fpr,tpr): \n",
        "  plt.plot(fpr,tpr) \n",
        "  plt.axis([0,1,0,1]) \n",
        "  plt.xlabel('False Positive Rate') \n",
        "  plt.ylabel('True Positive Rate') \n",
        "  plt.show()    \n",
        "  \n",
        "plot_roc_curve (fpr,tpr)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiLVUqEQEZFqqVCIiEi1VChERKRa/x9F4E52uIu+PgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FuUIxJSONas",
        "colab_type": "code",
        "outputId": "d63ebaf4-f7c1-4be8-e6e3-c0616a9c25de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "auc_score=roc_auc_score(validationLabels,prediction)\n",
        "print('AUC:',auc_score)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.718503797515442\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKC6clC4NWaH",
        "colab_type": "text"
      },
      "source": [
        "###Are there any patterns discovered by the network?\n",
        "####Lets examine if there are patterns by comparing the true/false integration datasets. We can do this by comparing the datasets of correctly predicted true/false predictions. We will do this by comparing the relative differences in frequencies of nucleotides in the datasets.\n",
        "####We will install biopython to help us compare the datasets and sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDEXb0VpRqwS",
        "colab_type": "code",
        "outputId": "e425e9e7-5d71-43db-a4f9-2081d23ddd0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "#Lets determine a consensus sequence for correct our correct predictions\n",
        "#For this we need to install biopython\n",
        "!pip install biopython\n",
        "import Bio\n",
        "print(Bio.__version__)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting biopython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/3d/e0c8a993dbea1136be90c31345aefc5babdd5046cd52f81c18fc3fdad865/biopython-1.76-cp36-cp36m-manylinux1_x86_64.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from biopython) (1.17.5)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.76\n",
            "1.76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpw6pQhKOc9v",
        "colab_type": "text"
      },
      "source": [
        "####Parse the DNA strings from which our one-hot encoded validation data was generated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "op50f2IsVJpD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lets parse the DNA strings for our validation data\n",
        "dnaValidation=pd.read_csv('data/DNAString_validation.txt', sep=',',header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLGiAVChOwRh",
        "colab_type": "text"
      },
      "source": [
        "####Add all correct predictions of true HIV integration events into a single dataset of DNA sequences\n",
        "#####We will ignore the sequences that contain random nucleotides 'N' as these correspond to any random nucleotide and cannot be used in biopython for sequence analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgHxHwZMSFdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add the DNA Sequences of correctly predicted true integration events into a list\n",
        "#Following http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc214\n",
        "from Bio.Seq import Seq\n",
        "dnaSequences = []\n",
        "for predIndex in range(prediction.size):\n",
        "  if (prediction[predIndex] >= 0.5 and validationLabels[predIndex].numpy()[0] == 1):\n",
        "    dnaString = dnaValidation[0][predIndex].upper()\n",
        "    #Ignore predictions performed on sequences containing random nucleotides as biopython does not handle these ->\n",
        "    if (\"N\" in dnaString): continue \n",
        "    dnaSequences.append(Seq(dnaString))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHDlUzizPsM8",
        "colab_type": "text"
      },
      "source": [
        "####Lets examine the proportion true integration events taken into consideration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD7tOHu9geZk",
        "colab_type": "code",
        "outputId": "c3c518c4-c718-4bfc-eeaf-0e28de980301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Lets calculate the percentage of correct predictions of true integrations not containing random nucleotides \n",
        "#We divide validationLabels/2 since the validation set contains equal proportions of true/false events\n",
        "len(dnaSequences)/(validationLabels.shape[0].value/2)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8361411298047126"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlC6vdI3P84L",
        "colab_type": "text"
      },
      "source": [
        "####Lets create an motif from the dataset for sequence analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vYPHPalZLlx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create a motif based on these sequences\n",
        "from Bio import motifs\n",
        "motifCorrectPredictions = motifs.create(dnaSequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLmvD8vNQM0i",
        "colab_type": "text"
      },
      "source": [
        "####Lets examine the consensus sequence of these correctly predicted true integrations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dKtTMlXcxYd",
        "colab_type": "code",
        "outputId": "a4a763aa-ae17-4f6e-b2a4-bfebf4f2cfcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "#Get the consenus sequence for the correct predictions\n",
        "print(motifCorrectPredictions.consensus)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ATTTTTATTTATAAATATATTTTTATATTAATAAATTTATTATTTTTTTAATTTATTTTTTTAAATTTTATAAATTTATTTAAAAAAATATTTTTTTTGGTTACCAAAAAAAATATTTTTTTAAATAAATTTATAAAATTTAATTAAATAAATTAATAAAATAATTAATTATTAATTTTTAATAATTTTATTATAATAAA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kq2mUKEvSYJR",
        "colab_type": "text"
      },
      "source": [
        "####When examining the above consenus sequence, wee see that there is a high rate of (A)denine and (T)hymine throughout the length of consensus sequence except in the middle. This is the position of HIV integration site. The HIV integration site contains a relative high frequency of (G)uanine and (C)ytosine compared to other positions in the DNA, the high occurrences of (G)uanine occurs right before the HIV integration position (at 100 bp) wheras (C)ytosine occurs a few bp after the integration site.\n",
        "####Below we print out the index position where the high frequency of (G)uanine and (C)ytosine occurs, we have also marked the nucleotides at these positions in red."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDW7nTqNQzQY",
        "colab_type": "code",
        "outputId": "43a7478c-9dc1-49d5-c865-6b742fd0ea7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "#Lets format the high occurrence of (G)uanine in red and its position\n",
        "print('The position of first guanine nucleotide is at position:', str(motifCorrectPredictions.consensus).index(\"G\"))\n",
        "print('The position of first cytosine nucleotide is at position:', str(motifCorrectPredictions.consensus).index(\"C\"))\n",
        "print(str(motifCorrectPredictions.consensus).replace(\"GG\",\"\\033[1;31mGG\\x1b[0m\").replace(\"CC\",\"\\033[1;31mCC\\x1b[0m\"))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The position of first guanine nucleotide is at position: 98\n",
            "The position of first cytosine nucleotide is at position: 103\n",
            "ATTTTTATTTATAAATATATTTTTATATTAATAAATTTATTATTTTTTTAATTTATTTTTTTAAATTTTATAAATTTATTTAAAAAAATATTTTTTTT\u001b[1;31mGG\u001b[0mTTA\u001b[1;31mCC\u001b[0mAAAAAAAATATTTTTTTAAATAAATTTATAAAATTTAATTAAATAAATTAATAAAATAATTAATTATTAATTTTTAATAATTTTATTATAATAAA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq_DpzK9W9se",
        "colab_type": "text"
      },
      "source": [
        "####Lets compare the above consensus sequence with correctly predicted false integration sites (sites with randomly sampled DNA from the GRCh37/hg19 genome)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5UhNPjGa5kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets now predict the consensus sequence for correctly predicted false integration events\n",
        "# Add the DNA Sequences of correctly predicted false integration events into a list\n",
        "dnaFalseSequences = []\n",
        "for predIndex in range(prediction.size):\n",
        "  if (prediction[predIndex] < 0.5 and validationLabels[predIndex].numpy()[0] == 0):\n",
        "    dnaString = dnaValidation[0][predIndex].upper()\n",
        "    if (\"N\" in dnaString): continue \n",
        "    dnaFalseSequences.append(Seq(dnaString))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKQe44geXzP8",
        "colab_type": "text"
      },
      "source": [
        "####Lets examine the proportion of false integration events we have taken into consideration for this analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2htR9APYaWe",
        "colab_type": "code",
        "outputId": "d760661f-8d9f-4a0a-9895-db8e6e88578b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Lets calculate the proportion of correctly predicted false integration events that do not contain random nucelotides\n",
        "len(dnaFalseSequences)/(validationLabels.shape[0].value/2)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3639580351810324"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tKIJPQ2YNwT",
        "colab_type": "text"
      },
      "source": [
        "####Lets generate a similar consensus sequence for false integration events"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkM5-5z0jAH5",
        "colab_type": "code",
        "outputId": "146b2aa9-7407-410b-e45d-a9c2394f94a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "#Get the consenus sequence for the correct predictions of false integrations\n",
        "motifFalseCorrectPredictions = motifs.create(dnaFalseSequences)\n",
        "print(motifFalseCorrectPredictions.consensus)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AATTTAATATATAAAAAAAAAAAAAAAAAATTTATAAAAAAAATAATAAAAAAAAAAAAAAAAAAATAAAAAAAAAAAAATTTTTTTTTAAAAAAAAAAAATTTTTTTTTTTTTTAAAAAAATAATTTTTTTTTTTTAAAATTATTTATATTTTTATAAAAATTTTTTAAAATTATTAAATATTAAAAATTTTAATATAT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dbkavYkZT21",
        "colab_type": "text"
      },
      "source": [
        "####Above we see that there are no similar inconsistencies regarding the sudden large relative occurance of (G)uanine in the correctly predicted false integration data.\n",
        "####Lets examine if there are more differences between these two sets by looking at the relative frequencies of the different nucleotides. We will compare these relative frequencies of nucleotides by substracing the total counts of nucleotides of correctly predicted false integration events from the dataset of correctly predicted true integration events ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_7XS_-vWbpx",
        "colab_type": "code",
        "outputId": "2f6c790a-dfe0-499f-ce8e-b2be9c08fcdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        }
      },
      "source": [
        "'''\n",
        "Lets compare differences in occurrences of nucleotides in correctly predicted true \n",
        "integrations events compared to correctly predicted false integration events to see\n",
        "if there is a pattern in the relative frequencies of nucleotides at different positions\n",
        "'''\n",
        "from IPython.display import HTML, display\n",
        "import tabulate\n",
        "from operator import sub\n",
        "diffA = [\"Diff. A\"]\n",
        "diffA.extend(map(sub, motifCorrectPredictions.counts[0], motifFalseCorrectPredictions.counts[0]))\n",
        "diffC = [\"Diff. C\"]\n",
        "diffC.extend(map(sub, motifCorrectPredictions.counts[1], motifFalseCorrectPredictions.counts[1]))\n",
        "diffG = [\"Diff. G\"]\n",
        "diffG.extend(map(sub, motifCorrectPredictions.counts[2], motifFalseCorrectPredictions.counts[2]))\n",
        "diffT = [\"Diff. T\"]\n",
        "diffT.extend(map(sub, motifCorrectPredictions.counts[3], motifFalseCorrectPredictions.counts[3]))\n",
        "\n",
        "table = [diffA,diffC,diffG, diffT]\n",
        "display(HTML(tabulate.tabulate(table, tablefmt='html')))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table>\n",
              "<tbody>\n",
              "<tr><td>Diff. A</td><td style=\"text-align: right;\">14196</td><td style=\"text-align: right;\">13719</td><td style=\"text-align: right;\">13520</td><td style=\"text-align: right;\">13161</td><td style=\"text-align: right;\">13260</td><td style=\"text-align: right;\">13458</td><td style=\"text-align: right;\">13714</td><td style=\"text-align: right;\">13998</td><td style=\"text-align: right;\">13793</td><td style=\"text-align: right;\">14494</td><td style=\"text-align: right;\">14225</td><td style=\"text-align: right;\">14151</td><td style=\"text-align: right;\">13896</td><td style=\"text-align: right;\">13518</td><td style=\"text-align: right;\">14091</td><td style=\"text-align: right;\">13626</td><td style=\"text-align: right;\">14656</td><td style=\"text-align: right;\">14539</td><td style=\"text-align: right;\">14602</td><td style=\"text-align: right;\">13901</td><td style=\"text-align: right;\">13538</td><td style=\"text-align: right;\">13557</td><td style=\"text-align: right;\">13696</td><td style=\"text-align: right;\">13498</td><td style=\"text-align: right;\">14242</td><td style=\"text-align: right;\">13497</td><td style=\"text-align: right;\">13877</td><td style=\"text-align: right;\">13725</td><td style=\"text-align: right;\">14328</td><td style=\"text-align: right;\">15265</td><td style=\"text-align: right;\">14596</td><td style=\"text-align: right;\">13935</td><td style=\"text-align: right;\">13767</td><td style=\"text-align: right;\">14482</td><td style=\"text-align: right;\">14018</td><td style=\"text-align: right;\">13506</td><td style=\"text-align: right;\">13636</td><td style=\"text-align: right;\">13999</td><td style=\"text-align: right;\">14645</td><td style=\"text-align: right;\">14174</td><td style=\"text-align: right;\">13846</td><td style=\"text-align: right;\">14255</td><td style=\"text-align: right;\">13394</td><td style=\"text-align: right;\">13207</td><td style=\"text-align: right;\">13781</td><td style=\"text-align: right;\">13045</td><td style=\"text-align: right;\">13796</td><td style=\"text-align: right;\">12796</td><td style=\"text-align: right;\">13458</td><td style=\"text-align: right;\">15130</td><td style=\"text-align: right;\">15253</td><td style=\"text-align: right;\">13499</td><td style=\"text-align: right;\">13269</td><td style=\"text-align: right;\">14261</td><td style=\"text-align: right;\">14057</td><td style=\"text-align: right;\">13702</td><td style=\"text-align: right;\">14077</td><td style=\"text-align: right;\">12858</td><td style=\"text-align: right;\">13771</td><td style=\"text-align: right;\">13532</td><td style=\"text-align: right;\">12448</td><td style=\"text-align: right;\">13741</td><td style=\"text-align: right;\">14449</td><td style=\"text-align: right;\">14950</td><td style=\"text-align: right;\">13608</td><td style=\"text-align: right;\">13235</td><td style=\"text-align: right;\">13144</td><td style=\"text-align: right;\">14049</td><td style=\"text-align: right;\">13321</td><td style=\"text-align: right;\">14619</td><td style=\"text-align: right;\">13213</td><td style=\"text-align: right;\">13570</td><td style=\"text-align: right;\">14688</td><td style=\"text-align: right;\">15019</td><td style=\"text-align: right;\">11871</td><td style=\"text-align: right;\">11611</td><td style=\"text-align: right;\">11915</td><td style=\"text-align: right;\">14068</td><td style=\"text-align: right;\">14281</td><td style=\"text-align: right;\">14592</td><td style=\"text-align: right;\">11459</td><td style=\"text-align: right;\">15904</td><td style=\"text-align: right;\">13743</td><td style=\"text-align: right;\">13323</td><td style=\"text-align: right;\">15207</td><td style=\"text-align: right;\">14944</td><td style=\"text-align: right;\">17044</td><td style=\"text-align: right;\">15655</td><td style=\"text-align: right;\">13080</td><td style=\"text-align: right;\">17010</td><td style=\"text-align: right;\">10711</td><td style=\"text-align: right;\"> 9735</td><td style=\"text-align: right;\">11196</td><td style=\"text-align: right;\"> 9067</td><td style=\"text-align: right;\">10622</td><td style=\"text-align: right;\"> 5950</td><td style=\"text-align: right;\"> 2393</td><td style=\"text-align: right;\"> 9982</td><td style=\"text-align: right;\"> 9476</td><td style=\"text-align: right;\"> 6439</td><td style=\"text-align: right;\"> 8966</td><td style=\"text-align: right;\">13872</td><td style=\"text-align: right;\">22867</td><td style=\"text-align: right;\">-1350</td><td style=\"text-align: right;\"> 8018</td><td style=\"text-align: right;\">17090</td><td style=\"text-align: right;\">25847</td><td style=\"text-align: right;\">16329</td><td style=\"text-align: right;\">14878</td><td style=\"text-align: right;\">13946</td><td style=\"text-align: right;\">14127</td><td style=\"text-align: right;\">14465</td><td style=\"text-align: right;\">17041</td><td style=\"text-align: right;\">14594</td><td style=\"text-align: right;\">16149</td><td style=\"text-align: right;\">13052</td><td style=\"text-align: right;\">10265</td><td style=\"text-align: right;\">10617</td><td style=\"text-align: right;\">12340</td><td style=\"text-align: right;\">12437</td><td style=\"text-align: right;\">13161</td><td style=\"text-align: right;\">11720</td><td style=\"text-align: right;\">17887</td><td style=\"text-align: right;\">15262</td><td style=\"text-align: right;\">14422</td><td style=\"text-align: right;\">14193</td><td style=\"text-align: right;\">14604</td><td style=\"text-align: right;\">15117</td><td style=\"text-align: right;\">15381</td><td style=\"text-align: right;\">15385</td><td style=\"text-align: right;\">14000</td><td style=\"text-align: right;\">13578</td><td style=\"text-align: right;\">15013</td><td style=\"text-align: right;\">13753</td><td style=\"text-align: right;\">15751</td><td style=\"text-align: right;\">14669</td><td style=\"text-align: right;\">15255</td><td style=\"text-align: right;\">15270</td><td style=\"text-align: right;\">13301</td><td style=\"text-align: right;\">12536</td><td style=\"text-align: right;\">13714</td><td style=\"text-align: right;\">14348</td><td style=\"text-align: right;\">15182</td><td style=\"text-align: right;\">13678</td><td style=\"text-align: right;\">13749</td><td style=\"text-align: right;\">14491</td><td style=\"text-align: right;\">16010</td><td style=\"text-align: right;\">15106</td><td style=\"text-align: right;\">12698</td><td style=\"text-align: right;\">14446</td><td style=\"text-align: right;\">14555</td><td style=\"text-align: right;\">15051</td><td style=\"text-align: right;\">14396</td><td style=\"text-align: right;\">14052</td><td style=\"text-align: right;\">14262</td><td style=\"text-align: right;\">15163</td><td style=\"text-align: right;\">14002</td><td style=\"text-align: right;\">14664</td><td style=\"text-align: right;\">14147</td><td style=\"text-align: right;\">14592</td><td style=\"text-align: right;\">15171</td><td style=\"text-align: right;\">13901</td><td style=\"text-align: right;\">14475</td><td style=\"text-align: right;\">14828</td><td style=\"text-align: right;\">13821</td><td style=\"text-align: right;\">14433</td><td style=\"text-align: right;\">14528</td><td style=\"text-align: right;\">14431</td><td style=\"text-align: right;\">13695</td><td style=\"text-align: right;\">13777</td><td style=\"text-align: right;\">13715</td><td style=\"text-align: right;\">13670</td><td style=\"text-align: right;\">14263</td><td style=\"text-align: right;\">15161</td><td style=\"text-align: right;\">14888</td><td style=\"text-align: right;\">13851</td><td style=\"text-align: right;\">13638</td><td style=\"text-align: right;\">13649</td><td style=\"text-align: right;\">13246</td><td style=\"text-align: right;\">13769</td><td style=\"text-align: right;\">15119</td><td style=\"text-align: right;\">14699</td><td style=\"text-align: right;\">14000</td><td style=\"text-align: right;\">14276</td><td style=\"text-align: right;\">14598</td><td style=\"text-align: right;\">14364</td><td style=\"text-align: right;\">13969</td><td style=\"text-align: right;\">13560</td><td style=\"text-align: right;\">13188</td><td style=\"text-align: right;\">13485</td><td style=\"text-align: right;\">13654</td><td style=\"text-align: right;\">13757</td><td style=\"text-align: right;\">14313</td><td style=\"text-align: right;\">13982</td><td style=\"text-align: right;\">14652</td><td style=\"text-align: right;\">14411</td><td style=\"text-align: right;\">13167</td><td style=\"text-align: right;\">13309</td><td style=\"text-align: right;\">13087</td><td style=\"text-align: right;\">13657</td></tr>\n",
              "<tr><td>Diff. C</td><td style=\"text-align: right;\"> 6930</td><td style=\"text-align: right;\"> 7065</td><td style=\"text-align: right;\"> 7550</td><td style=\"text-align: right;\"> 7755</td><td style=\"text-align: right;\"> 8341</td><td style=\"text-align: right;\"> 7961</td><td style=\"text-align: right;\"> 7297</td><td style=\"text-align: right;\"> 6819</td><td style=\"text-align: right;\"> 6762</td><td style=\"text-align: right;\"> 6877</td><td style=\"text-align: right;\"> 7341</td><td style=\"text-align: right;\"> 7171</td><td style=\"text-align: right;\"> 7462</td><td style=\"text-align: right;\"> 7723</td><td style=\"text-align: right;\"> 6681</td><td style=\"text-align: right;\"> 6754</td><td style=\"text-align: right;\"> 6140</td><td style=\"text-align: right;\"> 6269</td><td style=\"text-align: right;\"> 6563</td><td style=\"text-align: right;\"> 6830</td><td style=\"text-align: right;\"> 6541</td><td style=\"text-align: right;\"> 6478</td><td style=\"text-align: right;\"> 6085</td><td style=\"text-align: right;\"> 7139</td><td style=\"text-align: right;\"> 6929</td><td style=\"text-align: right;\"> 6893</td><td style=\"text-align: right;\"> 7104</td><td style=\"text-align: right;\"> 7801</td><td style=\"text-align: right;\"> 6268</td><td style=\"text-align: right;\"> 5525</td><td style=\"text-align: right;\"> 5656</td><td style=\"text-align: right;\"> 6287</td><td style=\"text-align: right;\"> 7220</td><td style=\"text-align: right;\"> 6406</td><td style=\"text-align: right;\"> 6417</td><td style=\"text-align: right;\"> 6704</td><td style=\"text-align: right;\"> 6796</td><td style=\"text-align: right;\"> 6594</td><td style=\"text-align: right;\"> 6274</td><td style=\"text-align: right;\"> 5957</td><td style=\"text-align: right;\"> 6317</td><td style=\"text-align: right;\"> 6018</td><td style=\"text-align: right;\"> 6934</td><td style=\"text-align: right;\"> 6458</td><td style=\"text-align: right;\"> 6435</td><td style=\"text-align: right;\"> 6896</td><td style=\"text-align: right;\"> 6672</td><td style=\"text-align: right;\"> 7216</td><td style=\"text-align: right;\"> 6872</td><td style=\"text-align: right;\"> 5891</td><td style=\"text-align: right;\"> 5220</td><td style=\"text-align: right;\"> 6418</td><td style=\"text-align: right;\"> 6872</td><td style=\"text-align: right;\"> 5067</td><td style=\"text-align: right;\"> 5613</td><td style=\"text-align: right;\"> 6369</td><td style=\"text-align: right;\"> 6018</td><td style=\"text-align: right;\"> 6238</td><td style=\"text-align: right;\"> 6577</td><td style=\"text-align: right;\"> 6589</td><td style=\"text-align: right;\"> 7547</td><td style=\"text-align: right;\"> 7046</td><td style=\"text-align: right;\"> 6993</td><td style=\"text-align: right;\"> 5997</td><td style=\"text-align: right;\"> 6763</td><td style=\"text-align: right;\"> 6759</td><td style=\"text-align: right;\"> 7463</td><td style=\"text-align: right;\"> 7004</td><td style=\"text-align: right;\"> 6123</td><td style=\"text-align: right;\"> 6927</td><td style=\"text-align: right;\"> 7260</td><td style=\"text-align: right;\"> 7065</td><td style=\"text-align: right;\"> 5822</td><td style=\"text-align: right;\"> 4709</td><td style=\"text-align: right;\"> 6891</td><td style=\"text-align: right;\"> 7946</td><td style=\"text-align: right;\"> 9225</td><td style=\"text-align: right;\"> 6973</td><td style=\"text-align: right;\"> 5272</td><td style=\"text-align: right;\"> 6266</td><td style=\"text-align: right;\"> 6152</td><td style=\"text-align: right;\"> 6536</td><td style=\"text-align: right;\"> 6677</td><td style=\"text-align: right;\"> 8772</td><td style=\"text-align: right;\"> 5683</td><td style=\"text-align: right;\"> 7439</td><td style=\"text-align: right;\"> 6746</td><td style=\"text-align: right;\"> 5187</td><td style=\"text-align: right;\"> 5740</td><td style=\"text-align: right;\"> 4882</td><td style=\"text-align: right;\"> 7139</td><td style=\"text-align: right;\"> 8952</td><td style=\"text-align: right;\"> 4833</td><td style=\"text-align: right;\"> 6177</td><td style=\"text-align: right;\"> 5610</td><td style=\"text-align: right;\"> 9616</td><td style=\"text-align: right;\"> 2843</td><td style=\"text-align: right;\">  855</td><td style=\"text-align: right;\"> 4051</td><td style=\"text-align: right;\">11227</td><td style=\"text-align: right;\"> 5374</td><td style=\"text-align: right;\"> 7236</td><td style=\"text-align: right;\"> 4996</td><td style=\"text-align: right;\">25917</td><td style=\"text-align: right;\">20677</td><td style=\"text-align: right;\">14540</td><td style=\"text-align: right;\">10740</td><td style=\"text-align: right;\">10267</td><td style=\"text-align: right;\">11024</td><td style=\"text-align: right;\">12645</td><td style=\"text-align: right;\">11514</td><td style=\"text-align: right;\"> 8871</td><td style=\"text-align: right;\"> 6994</td><td style=\"text-align: right;\"> 5451</td><td style=\"text-align: right;\"> 7005</td><td style=\"text-align: right;\"> 8073</td><td style=\"text-align: right;\"> 7588</td><td style=\"text-align: right;\"> 9142</td><td style=\"text-align: right;\"> 8792</td><td style=\"text-align: right;\"> 7560</td><td style=\"text-align: right;\"> 8291</td><td style=\"text-align: right;\"> 7740</td><td style=\"text-align: right;\"> 6347</td><td style=\"text-align: right;\"> 5909</td><td style=\"text-align: right;\"> 7707</td><td style=\"text-align: right;\"> 6421</td><td style=\"text-align: right;\"> 5712</td><td style=\"text-align: right;\"> 7169</td><td style=\"text-align: right;\"> 7774</td><td style=\"text-align: right;\"> 6403</td><td style=\"text-align: right;\"> 7253</td><td style=\"text-align: right;\"> 7519</td><td style=\"text-align: right;\"> 6044</td><td style=\"text-align: right;\"> 6554</td><td style=\"text-align: right;\"> 6753</td><td style=\"text-align: right;\"> 6283</td><td style=\"text-align: right;\"> 6390</td><td style=\"text-align: right;\"> 6955</td><td style=\"text-align: right;\"> 7862</td><td style=\"text-align: right;\"> 8187</td><td style=\"text-align: right;\"> 6351</td><td style=\"text-align: right;\"> 7044</td><td style=\"text-align: right;\"> 6681</td><td style=\"text-align: right;\"> 7715</td><td style=\"text-align: right;\"> 7531</td><td style=\"text-align: right;\"> 7988</td><td style=\"text-align: right;\"> 5775</td><td style=\"text-align: right;\"> 6503</td><td style=\"text-align: right;\"> 8686</td><td style=\"text-align: right;\"> 7536</td><td style=\"text-align: right;\"> 6927</td><td style=\"text-align: right;\"> 6367</td><td style=\"text-align: right;\"> 6528</td><td style=\"text-align: right;\"> 6682</td><td style=\"text-align: right;\"> 7024</td><td style=\"text-align: right;\"> 6729</td><td style=\"text-align: right;\"> 7302</td><td style=\"text-align: right;\"> 6798</td><td style=\"text-align: right;\"> 7530</td><td style=\"text-align: right;\"> 7176</td><td style=\"text-align: right;\"> 6025</td><td style=\"text-align: right;\"> 7380</td><td style=\"text-align: right;\"> 6984</td><td style=\"text-align: right;\"> 6681</td><td style=\"text-align: right;\"> 6968</td><td style=\"text-align: right;\"> 6292</td><td style=\"text-align: right;\"> 6520</td><td style=\"text-align: right;\"> 7018</td><td style=\"text-align: right;\"> 7548</td><td style=\"text-align: right;\"> 6906</td><td style=\"text-align: right;\"> 7150</td><td style=\"text-align: right;\"> 7539</td><td style=\"text-align: right;\"> 7292</td><td style=\"text-align: right;\"> 6005</td><td style=\"text-align: right;\"> 5812</td><td style=\"text-align: right;\"> 6212</td><td style=\"text-align: right;\"> 6963</td><td style=\"text-align: right;\"> 6977</td><td style=\"text-align: right;\"> 7119</td><td style=\"text-align: right;\"> 6872</td><td style=\"text-align: right;\"> 6425</td><td style=\"text-align: right;\"> 6517</td><td style=\"text-align: right;\"> 6875</td><td style=\"text-align: right;\"> 6537</td><td style=\"text-align: right;\"> 5748</td><td style=\"text-align: right;\"> 5996</td><td style=\"text-align: right;\"> 6776</td><td style=\"text-align: right;\"> 7424</td><td style=\"text-align: right;\"> 7130</td><td style=\"text-align: right;\"> 7296</td><td style=\"text-align: right;\"> 7296</td><td style=\"text-align: right;\"> 7115</td><td style=\"text-align: right;\"> 6535</td><td style=\"text-align: right;\"> 6766</td><td style=\"text-align: right;\"> 6746</td><td style=\"text-align: right;\"> 6882</td><td style=\"text-align: right;\"> 7148</td><td style=\"text-align: right;\"> 7400</td><td style=\"text-align: right;\"> 7436</td><td style=\"text-align: right;\"> 7158</td></tr>\n",
              "<tr><td>Diff. G</td><td style=\"text-align: right;\"> 6503</td><td style=\"text-align: right;\"> 6936</td><td style=\"text-align: right;\"> 7100</td><td style=\"text-align: right;\"> 7411</td><td style=\"text-align: right;\"> 6944</td><td style=\"text-align: right;\"> 6807</td><td style=\"text-align: right;\"> 7116</td><td style=\"text-align: right;\"> 6540</td><td style=\"text-align: right;\"> 6458</td><td style=\"text-align: right;\"> 6247</td><td style=\"text-align: right;\"> 6176</td><td style=\"text-align: right;\"> 6477</td><td style=\"text-align: right;\"> 6854</td><td style=\"text-align: right;\"> 6873</td><td style=\"text-align: right;\"> 6995</td><td style=\"text-align: right;\"> 7334</td><td style=\"text-align: right;\"> 6556</td><td style=\"text-align: right;\"> 6020</td><td style=\"text-align: right;\"> 6054</td><td style=\"text-align: right;\"> 6530</td><td style=\"text-align: right;\"> 7316</td><td style=\"text-align: right;\"> 6646</td><td style=\"text-align: right;\"> 6586</td><td style=\"text-align: right;\"> 6778</td><td style=\"text-align: right;\"> 6988</td><td style=\"text-align: right;\"> 7231</td><td style=\"text-align: right;\"> 7043</td><td style=\"text-align: right;\"> 6127</td><td style=\"text-align: right;\"> 5845</td><td style=\"text-align: right;\"> 5849</td><td style=\"text-align: right;\"> 7476</td><td style=\"text-align: right;\"> 7497</td><td style=\"text-align: right;\"> 7411</td><td style=\"text-align: right;\"> 6808</td><td style=\"text-align: right;\"> 7621</td><td style=\"text-align: right;\"> 7189</td><td style=\"text-align: right;\"> 6532</td><td style=\"text-align: right;\"> 6595</td><td style=\"text-align: right;\"> 7025</td><td style=\"text-align: right;\"> 6630</td><td style=\"text-align: right;\"> 7192</td><td style=\"text-align: right;\"> 7322</td><td style=\"text-align: right;\"> 6145</td><td style=\"text-align: right;\"> 7287</td><td style=\"text-align: right;\"> 7552</td><td style=\"text-align: right;\"> 7130</td><td style=\"text-align: right;\"> 7326</td><td style=\"text-align: right;\"> 6722</td><td style=\"text-align: right;\"> 7180</td><td style=\"text-align: right;\"> 6675</td><td style=\"text-align: right;\"> 6731</td><td style=\"text-align: right;\"> 6781</td><td style=\"text-align: right;\"> 6849</td><td style=\"text-align: right;\"> 7733</td><td style=\"text-align: right;\"> 9304</td><td style=\"text-align: right;\"> 6519</td><td style=\"text-align: right;\"> 5662</td><td style=\"text-align: right;\"> 8167</td><td style=\"text-align: right;\"> 7315</td><td style=\"text-align: right;\"> 7776</td><td style=\"text-align: right;\"> 6771</td><td style=\"text-align: right;\"> 6704</td><td style=\"text-align: right;\"> 6574</td><td style=\"text-align: right;\"> 8066</td><td style=\"text-align: right;\"> 7926</td><td style=\"text-align: right;\"> 6478</td><td style=\"text-align: right;\"> 6115</td><td style=\"text-align: right;\"> 6036</td><td style=\"text-align: right;\"> 6737</td><td style=\"text-align: right;\"> 6279</td><td style=\"text-align: right;\"> 5904</td><td style=\"text-align: right;\"> 7687</td><td style=\"text-align: right;\"> 6940</td><td style=\"text-align: right;\"> 6751</td><td style=\"text-align: right;\"> 7595</td><td style=\"text-align: right;\"> 7083</td><td style=\"text-align: right;\"> 5812</td><td style=\"text-align: right;\"> 6399</td><td style=\"text-align: right;\"> 7636</td><td style=\"text-align: right;\"> 5895</td><td style=\"text-align: right;\"> 6493</td><td style=\"text-align: right;\"> 7631</td><td style=\"text-align: right;\"> 8392</td><td style=\"text-align: right;\"> 7427</td><td style=\"text-align: right;\"> 8756</td><td style=\"text-align: right;\"> 9175</td><td style=\"text-align: right;\"> 7462</td><td style=\"text-align: right;\"> 7890</td><td style=\"text-align: right;\"> 7032</td><td style=\"text-align: right;\"> 5028</td><td style=\"text-align: right;\"> 6884</td><td style=\"text-align: right;\"> 8665</td><td style=\"text-align: right;\">11627</td><td style=\"text-align: right;\">12735</td><td style=\"text-align: right;\">11109</td><td style=\"text-align: right;\">10256</td><td style=\"text-align: right;\">10713</td><td style=\"text-align: right;\">14169</td><td style=\"text-align: right;\">20760</td><td style=\"text-align: right;\">25721</td><td style=\"text-align: right;\"> 4938</td><td style=\"text-align: right;\"> 6828</td><td style=\"text-align: right;\"> 5088</td><td style=\"text-align: right;\">10714</td><td style=\"text-align: right;\"> 3953</td><td style=\"text-align: right;\">  529</td><td style=\"text-align: right;\"> 2699</td><td style=\"text-align: right;\"> 9342</td><td style=\"text-align: right;\"> 5235</td><td style=\"text-align: right;\"> 5925</td><td style=\"text-align: right;\"> 4723</td><td style=\"text-align: right;\"> 8738</td><td style=\"text-align: right;\"> 6773</td><td style=\"text-align: right;\"> 4508</td><td style=\"text-align: right;\"> 5506</td><td style=\"text-align: right;\"> 5084</td><td style=\"text-align: right;\"> 6822</td><td style=\"text-align: right;\"> 7063</td><td style=\"text-align: right;\"> 5740</td><td style=\"text-align: right;\"> 8957</td><td style=\"text-align: right;\"> 6317</td><td style=\"text-align: right;\"> 6606</td><td style=\"text-align: right;\"> 6798</td><td style=\"text-align: right;\"> 6299</td><td style=\"text-align: right;\"> 5671</td><td style=\"text-align: right;\"> 7073</td><td style=\"text-align: right;\"> 9597</td><td style=\"text-align: right;\"> 7794</td><td style=\"text-align: right;\"> 6825</td><td style=\"text-align: right;\"> 4912</td><td style=\"text-align: right;\"> 5989</td><td style=\"text-align: right;\"> 7317</td><td style=\"text-align: right;\"> 7282</td><td style=\"text-align: right;\"> 6890</td><td style=\"text-align: right;\"> 5964</td><td style=\"text-align: right;\"> 7044</td><td style=\"text-align: right;\"> 6992</td><td style=\"text-align: right;\"> 6308</td><td style=\"text-align: right;\"> 6844</td><td style=\"text-align: right;\"> 6233</td><td style=\"text-align: right;\"> 6951</td><td style=\"text-align: right;\"> 7050</td><td style=\"text-align: right;\"> 7596</td><td style=\"text-align: right;\"> 6625</td><td style=\"text-align: right;\"> 6876</td><td style=\"text-align: right;\"> 6289</td><td style=\"text-align: right;\"> 6109</td><td style=\"text-align: right;\"> 6288</td><td style=\"text-align: right;\"> 5955</td><td style=\"text-align: right;\"> 5448</td><td style=\"text-align: right;\"> 7088</td><td style=\"text-align: right;\"> 6831</td><td style=\"text-align: right;\"> 5609</td><td style=\"text-align: right;\"> 6074</td><td style=\"text-align: right;\"> 7153</td><td style=\"text-align: right;\"> 6927</td><td style=\"text-align: right;\"> 6601</td><td style=\"text-align: right;\"> 7142</td><td style=\"text-align: right;\"> 6336</td><td style=\"text-align: right;\"> 6933</td><td style=\"text-align: right;\"> 6998</td><td style=\"text-align: right;\"> 6037</td><td style=\"text-align: right;\"> 6204</td><td style=\"text-align: right;\"> 5718</td><td style=\"text-align: right;\"> 6274</td><td style=\"text-align: right;\"> 6818</td><td style=\"text-align: right;\"> 7028</td><td style=\"text-align: right;\"> 6806</td><td style=\"text-align: right;\"> 6743</td><td style=\"text-align: right;\"> 6769</td><td style=\"text-align: right;\"> 7436</td><td style=\"text-align: right;\"> 6798</td><td style=\"text-align: right;\"> 5816</td><td style=\"text-align: right;\"> 5944</td><td style=\"text-align: right;\"> 6845</td><td style=\"text-align: right;\"> 8045</td><td style=\"text-align: right;\"> 7434</td><td style=\"text-align: right;\"> 7169</td><td style=\"text-align: right;\"> 7264</td><td style=\"text-align: right;\"> 7210</td><td style=\"text-align: right;\"> 6515</td><td style=\"text-align: right;\"> 6775</td><td style=\"text-align: right;\"> 6966</td><td style=\"text-align: right;\"> 7137</td><td style=\"text-align: right;\"> 7012</td><td style=\"text-align: right;\"> 6742</td><td style=\"text-align: right;\"> 6738</td><td style=\"text-align: right;\"> 7038</td><td style=\"text-align: right;\"> 7211</td><td style=\"text-align: right;\"> 7697</td><td style=\"text-align: right;\"> 7222</td><td style=\"text-align: right;\"> 7292</td><td style=\"text-align: right;\"> 7197</td><td style=\"text-align: right;\"> 6855</td><td style=\"text-align: right;\"> 6624</td><td style=\"text-align: right;\"> 6832</td><td style=\"text-align: right;\"> 7410</td><td style=\"text-align: right;\"> 8005</td><td style=\"text-align: right;\"> 8289</td><td style=\"text-align: right;\"> 7948</td></tr>\n",
              "<tr><td>Diff. T</td><td style=\"text-align: right;\">14273</td><td style=\"text-align: right;\">14182</td><td style=\"text-align: right;\">13732</td><td style=\"text-align: right;\">13575</td><td style=\"text-align: right;\">13357</td><td style=\"text-align: right;\">13676</td><td style=\"text-align: right;\">13775</td><td style=\"text-align: right;\">14545</td><td style=\"text-align: right;\">14889</td><td style=\"text-align: right;\">14284</td><td style=\"text-align: right;\">14160</td><td style=\"text-align: right;\">14103</td><td style=\"text-align: right;\">13690</td><td style=\"text-align: right;\">13788</td><td style=\"text-align: right;\">14135</td><td style=\"text-align: right;\">14188</td><td style=\"text-align: right;\">14550</td><td style=\"text-align: right;\">15074</td><td style=\"text-align: right;\">14683</td><td style=\"text-align: right;\">14641</td><td style=\"text-align: right;\">14507</td><td style=\"text-align: right;\">15221</td><td style=\"text-align: right;\">15535</td><td style=\"text-align: right;\">14487</td><td style=\"text-align: right;\">13743</td><td style=\"text-align: right;\">14281</td><td style=\"text-align: right;\">13878</td><td style=\"text-align: right;\">14249</td><td style=\"text-align: right;\">15461</td><td style=\"text-align: right;\">15263</td><td style=\"text-align: right;\">14174</td><td style=\"text-align: right;\">14183</td><td style=\"text-align: right;\">13504</td><td style=\"text-align: right;\">14206</td><td style=\"text-align: right;\">13846</td><td style=\"text-align: right;\">14503</td><td style=\"text-align: right;\">14938</td><td style=\"text-align: right;\">14714</td><td style=\"text-align: right;\">13958</td><td style=\"text-align: right;\">15141</td><td style=\"text-align: right;\">14547</td><td style=\"text-align: right;\">14307</td><td style=\"text-align: right;\">15429</td><td style=\"text-align: right;\">14950</td><td style=\"text-align: right;\">14134</td><td style=\"text-align: right;\">14831</td><td style=\"text-align: right;\">14108</td><td style=\"text-align: right;\">15168</td><td style=\"text-align: right;\">14392</td><td style=\"text-align: right;\">14206</td><td style=\"text-align: right;\">14698</td><td style=\"text-align: right;\">15204</td><td style=\"text-align: right;\">14912</td><td style=\"text-align: right;\">14841</td><td style=\"text-align: right;\">12928</td><td style=\"text-align: right;\">15312</td><td style=\"text-align: right;\">16145</td><td style=\"text-align: right;\">14639</td><td style=\"text-align: right;\">14239</td><td style=\"text-align: right;\">14005</td><td style=\"text-align: right;\">15136</td><td style=\"text-align: right;\">14411</td><td style=\"text-align: right;\">13886</td><td style=\"text-align: right;\">12889</td><td style=\"text-align: right;\">13605</td><td style=\"text-align: right;\">15430</td><td style=\"text-align: right;\">15180</td><td style=\"text-align: right;\">14813</td><td style=\"text-align: right;\">15721</td><td style=\"text-align: right;\">14077</td><td style=\"text-align: right;\">15525</td><td style=\"text-align: right;\">13580</td><td style=\"text-align: right;\">14452</td><td style=\"text-align: right;\">15423</td><td style=\"text-align: right;\">15545</td><td style=\"text-align: right;\">15262</td><td style=\"text-align: right;\">14950</td><td style=\"text-align: right;\">14462</td><td style=\"text-align: right;\">14713</td><td style=\"text-align: right;\">15149</td><td style=\"text-align: right;\">17798</td><td style=\"text-align: right;\">11831</td><td style=\"text-align: right;\">13090</td><td style=\"text-align: right;\">12380</td><td style=\"text-align: right;\">12256</td><td style=\"text-align: right;\">10344</td><td style=\"text-align: right;\">10650</td><td style=\"text-align: right;\">13170</td><td style=\"text-align: right;\">16050</td><td style=\"text-align: right;\">14982</td><td style=\"text-align: right;\">17168</td><td style=\"text-align: right;\">14550</td><td style=\"text-align: right;\">14246</td><td style=\"text-align: right;\">13923</td><td style=\"text-align: right;\">14561</td><td style=\"text-align: right;\">16080</td><td style=\"text-align: right;\">25953</td><td style=\"text-align: right;\">16896</td><td style=\"text-align: right;\"> 7615</td><td style=\"text-align: right;\">-1485</td><td style=\"text-align: right;\">22624</td><td style=\"text-align: right;\">13966</td><td style=\"text-align: right;\"> 8951</td><td style=\"text-align: right;\"> 6621</td><td style=\"text-align: right;\"> 9254</td><td style=\"text-align: right;\"> 9743</td><td style=\"text-align: right;\"> 2616</td><td style=\"text-align: right;\"> 5964</td><td style=\"text-align: right;\">10765</td><td style=\"text-align: right;\"> 9386</td><td style=\"text-align: right;\">11538</td><td style=\"text-align: right;\"> 9828</td><td style=\"text-align: right;\">11094</td><td style=\"text-align: right;\">17349</td><td style=\"text-align: right;\">13242</td><td style=\"text-align: right;\">15693</td><td style=\"text-align: right;\">17227</td><td style=\"text-align: right;\">15080</td><td style=\"text-align: right;\">15030</td><td style=\"text-align: right;\">12948</td><td style=\"text-align: right;\">14133</td><td style=\"text-align: right;\">15836</td><td style=\"text-align: right;\">10870</td><td style=\"text-align: right;\">14432</td><td style=\"text-align: right;\">14102</td><td style=\"text-align: right;\">14215</td><td style=\"text-align: right;\">11989</td><td style=\"text-align: right;\">11822</td><td style=\"text-align: right;\">11922</td><td style=\"text-align: right;\">15202</td><td style=\"text-align: right;\">14660</td><td style=\"text-align: right;\">13488</td><td style=\"text-align: right;\">13563</td><td style=\"text-align: right;\">14705</td><td style=\"text-align: right;\">13434</td><td style=\"text-align: right;\">13906</td><td style=\"text-align: right;\">13265</td><td style=\"text-align: right;\">13369</td><td style=\"text-align: right;\">13895</td><td style=\"text-align: right;\">14946</td><td style=\"text-align: right;\">14886</td><td style=\"text-align: right;\">13460</td><td style=\"text-align: right;\">12443</td><td style=\"text-align: right;\">13884</td><td style=\"text-align: right;\">13746</td><td style=\"text-align: right;\">13134</td><td style=\"text-align: right;\">14008</td><td style=\"text-align: right;\">14005</td><td style=\"text-align: right;\">14563</td><td style=\"text-align: right;\">14472</td><td style=\"text-align: right;\">13332</td><td style=\"text-align: right;\">13653</td><td style=\"text-align: right;\">15369</td><td style=\"text-align: right;\">15094</td><td style=\"text-align: right;\">13463</td><td style=\"text-align: right;\">13083</td><td style=\"text-align: right;\">13997</td><td style=\"text-align: right;\">13298</td><td style=\"text-align: right;\">13889</td><td style=\"text-align: right;\">13201</td><td style=\"text-align: right;\">13708</td><td style=\"text-align: right;\">14584</td><td style=\"text-align: right;\">14239</td><td style=\"text-align: right;\">14675</td><td style=\"text-align: right;\">14839</td><td style=\"text-align: right;\">14359</td><td style=\"text-align: right;\">13826</td><td style=\"text-align: right;\">13647</td><td style=\"text-align: right;\">13916</td><td style=\"text-align: right;\">14450</td><td style=\"text-align: right;\">13601</td><td style=\"text-align: right;\">13895</td><td style=\"text-align: right;\">14531</td><td style=\"text-align: right;\">14792</td><td style=\"text-align: right;\">14357</td><td style=\"text-align: right;\">13794</td><td style=\"text-align: right;\">13867</td><td style=\"text-align: right;\">14107</td><td style=\"text-align: right;\">14273</td><td style=\"text-align: right;\">14051</td><td style=\"text-align: right;\">13843</td><td style=\"text-align: right;\">13911</td><td style=\"text-align: right;\">14061</td><td style=\"text-align: right;\">13952</td><td style=\"text-align: right;\">14544</td><td style=\"text-align: right;\">14800</td><td style=\"text-align: right;\">14419</td><td style=\"text-align: right;\">13880</td><td style=\"text-align: right;\">14373</td><td style=\"text-align: right;\">13424</td><td style=\"text-align: right;\">13730</td><td style=\"text-align: right;\">13738</td><td style=\"text-align: right;\">13857</td><td style=\"text-align: right;\">14299</td><td style=\"text-align: right;\">13880</td><td style=\"text-align: right;\">13777</td><td style=\"text-align: right;\">14177</td><td style=\"text-align: right;\">13188</td><td style=\"text-align: right;\">13090</td><td style=\"text-align: right;\">13139</td></tr>\n",
              "</tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mLrq5BvdChq",
        "colab_type": "text"
      },
      "source": [
        "####Above see that an interesting pattern ensues, even though the number false integration events taken into consideration are significantly less compared to the number of true integration events, we that some nucleotides occur significantly less in the DNA of true integration events at close proximity to the HIV integration site.\n",
        "####We can make illustrate this more clearly by setting all positive differences to zero while retaining all the negative differences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N0wduBCTdYy",
        "colab_type": "code",
        "outputId": "a5b5770f-785b-4647-99fd-dcbf2e722bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        }
      },
      "source": [
        "'''\n",
        "Lets eliminate positive differences and leave the negative differences as is\n",
        "revealing a pattern at the site of HIV integration (in the middle of the sequence)\n",
        "'''\n",
        "diffANew = list(map(lambda x: 0 if type(x) == int and x > 0  else x,diffA))\n",
        "diffCNew = list(map(lambda x: 0 if type(x) == int and x > 0  else x,diffC))\n",
        "diffGNew = list(map(lambda x: 0 if type(x) == int and x > 0  else x, diffG))\n",
        "diffTNew = list(map(lambda x: 0 if type(x) == int and x > 0  else x, diffT))\n",
        "tableNew = [diffANew,diffCNew,diffGNew, diffTNew]\n",
        "display(HTML(tabulate.tabulate(tableNew, tablefmt='html')))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table>\n",
              "<tbody>\n",
              "<tr><td>Diff. A</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">-1350</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td></tr>\n",
              "<tr><td>Diff. C</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td></tr>\n",
              "<tr><td>Diff. G</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td></tr>\n",
              "<tr><td>Diff. T</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">-1485</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td></tr>\n",
              "</tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIztfemC5l2f",
        "colab_type": "text"
      },
      "source": [
        "####Lets plot the above differences using a dot-plot to more easily examine the differences and highlight the relative differences in nucleotide frequencies around the HIV integration sites (at 100bp position)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX2NFA2CSVup",
        "colab_type": "code",
        "outputId": "f9272f24-1bcc-4c19-e293-68b3caf4c0ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "# Dot plot created using scatter plot (with help from https://github.com/Pjarzabek/DotPlotPython)\n",
        "import seaborn as sns\n",
        "from __future__ import division\n",
        "seqLimitStart = 80\n",
        "seqLimitEnd = 120\n",
        "xLimit = np.arange(seqLimitStart,seqLimitEnd)\n",
        "\n",
        "Thue = []\n",
        "Ghue = []\n",
        "Chue = []\n",
        "Ahue = []\n",
        "TyValues = ['T'] * (seqLimitEnd-seqLimitStart)\n",
        "GyValues = ['G'] * (seqLimitEnd-seqLimitStart)\n",
        "CyValues = ['C'] * (seqLimitEnd-seqLimitStart)\n",
        "AyValues = ['A'] * (seqLimitEnd-seqLimitStart)\n",
        "for position in np.arange(seqLimitStart+1,seqLimitEnd+1):\n",
        "  Thue.append(diffTNew[position])\n",
        "  Ghue.append(diffGNew[position])\n",
        "  Chue.append(diffCNew[position])\n",
        "  Ahue.append(diffANew[position])\n",
        "  \n",
        "def addSubplot(plt, yValues, hueValues):\n",
        " plt.subplots( figsize=(15,1))\n",
        " ax = sns.scatterplot(xLimit, yValues, hue=hueValues, s=250, legend=False, palette=\"Reds_r\")\n",
        " scale_legend = plt.Normalize(min(hueValues), max(hueValues))  # Create the scale for the colormap.\n",
        " color_map = plt.cm.ScalarMappable(cmap=\"Reds_r\", norm=scale_legend)  # Set the colormap\n",
        " ax.figure.colorbar(color_map)  # Add colormap legend\n",
        " plt.xlim([seqLimitStart,seqLimitEnd])  \n",
        " plt.plot()\n",
        "\n",
        "addSubplot(plt, AyValues,Ahue)\n",
        "addSubplot(plt, CyValues,Chue)\n",
        "addSubplot(plt, GyValues,Ghue)\n",
        "addSubplot(plt, TyValues,Thue)\n",
        "plt.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAw4AAABZCAYAAACXIXOfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nl/8PBH/MfGqg8HkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x72 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwUAAABZCAYAAABvwYhoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO2dd3hc1bX233VmJI265N577w1XDMY2\nYNMMxBACJJCE1MtN+0jhkmJybxJISG+ECwmQXHo1xca4m+JuDC4YbGzcu6UZzajNnPX9sc40aWZ0\nzhkpstH6PY8fq8zZ2rNmn/2utfY+exEzQ1EURVEURVGUtovR2h1QFEVRFEVRFKV10aBAURRFURRF\nUdo4GhQoiqIoiqIoShtHgwJFURRFURRFaeNoUKAoiqIoiqIobRwNChRFURRFURSljaNBgaIoiqIo\niqKcRRDRHCLaRUS7iegHKX5/ARFtJqIwEc1vjr+pQYGiKIqiKIqinCUQkQfAnwHMBTAMwGeIaFiD\nl+0HcCuAx5rr73qbqyFFURRFURRFUbJmIoDdzPwRABDREwDmAdgRfQEz77N+ZzbXH22RoKBDhw7c\np0+flmhaURRFURRFUWJs2rTpJDN3bO1+NMWci2fzyVOnsGnLO9sB1CT86gFmfiDh++4ADiR8fxDA\npJbuX4sEBX369MHGjRtbomlFURRFURRFiUFEH7d2H+xw8tQpbFyzHFTUroaZJ7R2fxqizxQoiqIo\niqIoSkvDDITr7bzyEICeCd/3sH7WomhQoCiKoiiKoigtDTMQCdt55QYAA4moLxHlArgBwMIW7Rs0\nKFAURVEURVGUfwMMthEUMHMYwO0AXgOwE8BTzLydiH5KRFcBABGdR0QHAVwH4G9EtD3b3unpQ4qi\nKIqiKIrS0jADEVvbh8DMrwJ4tcHPfpzw9QbItqJmQ1cKFEVRFEVRFKXFsb19qFXQoEBRFEVRFEVR\nWhr7zxS0ChoUKIqiKIqiKEpLwwzU17Z2L9KiQYGiKIqiKIqitDTMYA0KFEVRFEVRFKUNwyZQV9P0\n61oJDQoURVEURVEUpaVhBurrWrsXadGgQFEURVEURVFaGl0pUBRFURRFUZQ2DjO4XoMCRVEURVEU\nRWm7sKnbhxRFURRFURSlTWMyUKenDymKoiiKoihK24VNoFa3DymKoiiKoihK20VPH1IURVEURVGU\nNg6f3duHvC3SaiQMrvKDikocXcbMQJUf4AgAAnLyQPkFztoI1wPVQdm3RQB8BaDcPGdt1FbL8g4z\nYBhAQTHI43HWRigA1NcDRIDHAyp0aAvTBIKB7GxRXye2YJZ+5BeCcnKdtVETkgEctUVhMchwaItg\nAIiE5RuPF1RY7Ox6MyK2ME15H7k+kC/fWRt1dUBNEGAABgG+QlBOjrM2qoNWhM+A4ZFxYTiLq2O2\nYAZyckAFDm0RiQChBFvk+UB5Tm1RC9SE4rbILwR53doCABlAUQmIyFkbVX6xBRHgzQEVFDm7PhIG\nQlXxe92NLWprgNpq6x4xgIIikNfZtJhkC8PjeN4DGtgiJxeUX+js+nAYqK5KGBf5oDyfszZi8x5k\nXBQUgTwObRGqAsL1Yk+P150GBP3yPgCXtjhbNKBKxgWRy3nPtO71qAa4sEV9vcx7pqUBvgJQrlMN\nqJYjFLPVgHB9FraIAMGquB7m5oF8raCH1SGgvhYAA+SxbOFUA/xAJCL98OY4t0VDDXClh82hAc1g\niyq/Nb7hSgPOSUwTqG1jQQEfO4jI/XfDmHEVaOBIEZcMNx/X1gDVQfC29TDfWAxUVQJeL6hzDxiX\nXg906AoUlWYccBysAmqqYK5ZBH5vnQh9rg80aBSMi+YBhSVNChT7K4DKkzCXPAM+sAcI14kYTLwI\nxvgLZULN4JhzOAwE/eADe2AufRY4fVxu/PIOMC66GtRvKFBYBPJmskU1UB0Cb30L5tuvS5Dk9YK6\n9oZxyXVA+85AcVlGB4yDfiAUhLn6ZfCOTUBNNeDLBw0eA2PGlfKeMtiCmYFABXDmJMwlT4EP7RNb\nFJbAmDwbGDtNnOoMExGH64FgALxvF8xlzwNnTsgEVt4RxqxrQL0HySSSYSLimmqgJgje/AbMdcvE\nWfDmgnr0hXHxdUB5h6ZtUeUHQgGYK18C73onbovhE2BccIVMhhkmZTZNGY+njsFc8jT4yMdAOAwU\nlcCYegkwaoqMi0y2qK8DQlXgPTtgrngBqDgFEIHadwbN/hSoR3/LFulvR64OAjUhmBtXgTesFFHI\nyQP17A/j4vlAWXtQcVna68UWlUAwAHP5C+AP3xOh9xWARk6Ccf5c+UwL00/KbEZkPJ44LLY4ekDE\nrbhUrh9+ntgzgzPK9bVAKAj+4F2Yq14CKk8DhgFq3wV08XxQt95yr2dwwLg6CFSHYK5fDt60Wpzh\nnDxQn0EwZs8HSsrs2SJQCXP58+A92yXw9RWCxkyVz9VXkFGgOBIBqirBxw6ClzwNPnFYJvviMhgX\nXA4aOk5skcEZ5bpaoLoKvPMdmGteAfxnxBYdu4IuuR7UpQdQ2IQtQlUyLt5eAt7yljiAuXmgfsNg\nzLoGKCoDFZdmtkWgAvBXwFz2LHjvLhH6/CLQuPNhTJol7yODMxqzxZH9YotTR8UWJeUwZlwJGjQa\nKCgE5diwxfaNMN9YBAQqxRZdesq817GbBJ4ZnFEOBWRcvLEY/N5acXpyfaABI2HMnCfXFzVhC38F\n4D8N8/VnwPt3iy0KikATZsA4b4bYIoMzypGwzHsHPwK//gz41DHRgLL2MC6aB+o/3IYeWhrw7lqY\nby2J62GXXqKH7Tvb0MMAUB2EufoV8PYNcT0cPAbGjKtkvmlSAyqBipNyrx/8KKYBNHEmjPHTrXkv\nkx5aGrD/Q5hLnxMNYBYNmHk1qO+QpjUgaostb8Bcu1SSQ94cUPc+Mi7KO9rUwyrRgPe3xDVg2DgY\nF1wpYzND0i6mh6ePw3ztafCRfRLgFJbAmHIJMGYqkF+QMSHB4TogWAXeuxPm8heAMydFD9t1gjH7\nWlDPAWLbTBpQE5LxvcnSgJge9hNblLUHlZSnvR6w9DAYgLnyRfCuraIBefmgERNhTL/Mvh6ePCq+\nwdEDlh6Wwph2KTBykg0NsPRw9zaYKxeKHhoGqF0n0YDu/YCiYscJiXMG5rO6TgExc7M3Or5TGa+7\n/nz5Ji8fxrxbQeMvSDnYuMoPc+VC8NJn5UZLRXlHeL7wfaB735Qiy5WnYT72B/D2jek71XcIPJ//\nPlDeodEEwuEwcOIQIg/+Ajh2MPX1hgGafAmMKz+bUmS5Ogje9Q7Mx/8kE1cqfAUwPvUl0OgpKR0O\nrqqUgGTVS/HMekPad4bni3cCXXulFBauOAXzn7+RGz4dA0bAc8sdoPIOja+vrwOOHULkwZ8DJ4+k\nvt7wgKZfBmPuDSlFlkNV4O0bYD51v2RmUlFQBOP6r4GGTQAVNHY4uKoS5quPg99YFM8kNKRjN3hu\nuxPo1CNl1p/PnEDk4fuAPdtTXw+AhoyBcfO3QWXtG19fVwsc2Y/IQ7+QAC8VXi9oxjwYsz+VUmQ5\nVAXe8ibM5x8UMUpFYQmMG/8TNGh0yqCTA5UwFz4CXrc0nkFtSOce8HzpLqBj10aTKTMDZ04g8vd7\ngX27Ul8PgIafJ/0obde4D7U1wKG90kbFydQN5OSCZs+HceEVqW0RDIA3rIS58JH0k2JxGYybvwXq\nPyylw8GBCpjPPQjeuFoe2EpFt97w3PZfQPsujRxqNk3g9HH5TA/sSX09EWjUFBif/lpKkeXaavD+\n3TAf/pUENanIyQPNvQHGtEtTOhwcDMB86zXwq49b2bYUlJTDuPUOUO9BKR0O9p+B+dT94K1vidCk\nokd/uUfadWzkUHMkApw6Jvf64X2prycDNH46jGu/BCppHGhxTQj80U6Y//ytOE6pyPXJvDlxZmoN\nCPphrnoZ/Poz6ffalnWA8fnvgXr0S+lwcOVpmI//CbxtferrAaD3INGRdp0aa0AkDJw4IrY4eiD1\n9YYBmjQLxlW3pAw6uToE/vBdmP/3B3HYUuHLh3H1F0DjpqfRAD/MZc+BV7wgzlYq2nWC5ws/ALr1\nTqOHp2D+6/fgnZtTXw8A/YbB8/nvgso7Nr4+XC8a8NDPgeOHU19veEDTLoVx2U3p9XDHJphP/kVW\n81KRXwjjuq+ARkxMr4evPQle/Wp6PezQRe71Lj1SJtu44iTMR34tSZA00KBRMD73HVBZGj08ekDG\nxaljqRvweEEXXg7jkuvT6+G7a2E+84AEqqkoLIbx6f8ADR2bMgDnQCXMV/4Ffuu19BrQqbvYolP3\nRsGFaMBJRP5xL7D3/dTXA6Ch42T+TaUBdbXA4X2IPHSPBHip8HpBs66VJGhKPQyAN62B+cI/JFBN\nRVEJjJu+BRowwtHuCCLaxMwTbF/QSkzo1YXXffcmeL/xm7Oyv54FCxY0e6MP/OqeBV8a3ku+iYTF\nWfd4QD37JzmyXOWH+ez/gle/nH6gA0BNCLxumaw6lLZPEnquPI3I7+/M6OwAACpOgjethjF2WtIE\nxGZEHL9f3yGZunQwAwd2g/d/CBp+XpIwcU0IvHkNzEd/k/kBknC9rGL4CkDd+zS2xeN/Aq99Pb2z\nA8iKyrqlMIaOA0rKk7JFXHESkd9+P72zE+X0cfCWN0BjpyVNQByJAAf3IvKb70o2IJMtPv4AOLxf\nJrHcBFtUh8DrXof5+J/TB3kAUF8HfuctmXw692hgi0qZyDetSu/sAEAoAF63DMaI8yQjmmiL0ycQ\n+c0dwJGPM9vi5FHw1rdBY89PckI5HBbH73c/kKx8OkwT+GgncOqoOPUJIs2hoDg7zz2YXuABoL4W\nvHkNqGNXoGO3pMwZByoQeehe4N23M9si6AevXQZj1CTJIiY6PaePI3Lf/wOOH8poCpw4DN6+ATRm\natLKB4frxPH7413pgzxAgrfd7wH+M6ABwxvYokqyry//M73AA0BdDXjTKlD3vkD7zknixoEKRP72\nU2DHJsi6dxoCleB1y2GMmSrZt0RbnDyCyH3fAU4ezWQJ4NgB8M4tEsAnOORcVyurHH9ZkF7gAbHF\nrq1AbQjUd2iyLYIBEfglT6cPeAGgtga8fqWsqpV3TAr22H8GkT//GPjw3czvw38GvGGFzHsJDjkz\nSyLkvv+XXuDllcDhj8G7t4FGTUqe9+pqwNs2wHzw55lP04iExUFlBvUemHyvB/0wn38IvGJhZlvU\nhMDrl4EGDAfK2ycFOFx5GpE//Bewd2dGU6DylGjAmIYaYALHDiBy3x1A5akMpmDg4EfgfbtAIxpq\nQLWs7v7jl+mDPAAIh8HbNkgA3b1vYw148i/gNxdn1sPqoOjhkDFASbsGGnAKkd/9ANj/YWZbnDkB\n3vyGzHsNNeDwPtGAdEFe1Bb7PwQO7QUNG99YAzashPl/v29aD7e+LfdogyQXV1VKYLN+eWY9DFWB\n1y6FMWwCUNxAD8+clPdxaG9mW5w6Jlo0dlqyBkTCwIE9iPz2e+kTfYD0b+8u4Pgh0OAxDWwRhPnm\nYvDT9zeth1veALXrBHTu3kADKmE+/Evwljea0ABLD0dOtDQgYSXpzAm519MlPaOcPAJ+b52lAYl6\nWC+r/r+/U1Zm02GakoSrOAkaOLKxBix/EfziP5rQgFrRgK49gQ5dbG9ruvvuu48sWLDgAVsvbkUe\n+M0vF3xpwhD89PUNZ2V//20PGvNrT4E/2hH/3oyAN64Eb1hhrwEzAvP+u4FA3HHnKj/MR3/dtLMT\nxX8Gkb8ukCXiKIFKRP54l/0HPz58T7IXiSJ44gjMJ/5s73oA/NKjsj0p+n24HuYbi2SCtEM4jMif\nfgQkvA+uqpQIPl02oyEVJxH52//I1oEogQpE/vTDzJNXArxjI8wVCyWbEuXIxzCffdBeHwDJniRM\nVFxXB3PZC5mzXInU1yHyxx8mBTEx57Eig8AncuoYIn+/V7aURAlUwPzzjzJPXgnwljdlC0eC88/7\nPwC/8i97fQBgPv7HpNUZrq2GufgJcbTtUFeDyB/uShLzmPOYSeATOXYQ5j9/J0vuUfwVMP/208yO\nSgK8fjl40xpxMKI/271NVgNtNcAwH7kvyVnl6qBkl/Z9YK+NmpA4iv4GtvjjDzMLfCKH98F88q+y\nRSdK5WlxgjM5KgnwmkXgbevF8YQ447xjE3j1K/b6wCbMh+5JWpHgUJWswjXl7EQJBhD5w13gxKRH\noELGSqYgL5GPP4D5/N9lH3GUMyflc7K52szLngN/EA9iOBIBb34DvHaZvT6YJsy//TdQmaABQb9k\n5ptydqIEKhD5y48baECFjJV0mcuG7NkO85XHZGtLlFPHxAm2Cb/6GPjj+FjmcBi8dqk4fnaIhGH+\n5SeN9DDy8K/Sr/A2pPIUIvffnawBVRWih5kCmwT4/S0wlz4rWeQoxw/CfOqv9voAgF/4e9JKFdfX\nSzIl06pPIuF60a3EeS9QicgD/91EwJvA6eOI/O/PwYFkDYj86UeZEzoJ8LvrZPtygn7ywb3gFx+2\n1wdA7JawOsN1tZJMybTyn0hdraUBCXror0DkLwsyJz0TOXEY5iP3yVajKP4KSYRkCtwT4I2rwOtW\nSGAV/dne98GLn7DXBwDmP38HnEqzQn8uYzJQd46fPkREXYjoCSLaQ0SbiOhVIhrk9I+ZCx+N33SB\nSpivPeWsgfo6cZ6jN12oyv7NEuXoAeCUZAmZWfZb2nUSLPjNxbJ3F5ZAv/xP28IYxVz4SPymCwbA\ny55zdD3qamRPdfQm9VdkXBZMycE9MWeDzQh485rM2c8U8MqFseVhDgYQcTABRjFfelT2wAKyr3jV\nS84aqA6C33kr5njhzAn7DlOUj3bEJlKOhGGufd3xCQG89NnYtoHolh9nDTDMl/8le+YB2Uv75mvO\n2gj6wTu3xL8/ccR+0Bztxvub459puB7m6lccH6FmvvYkELTsGaiAufBRR9fDNGEufkKeKwGAmmr7\nCYQo/jPJiYhD+9JvA0sDv/s2YDnCXFcLc9lztgPFKOarj8WD1kAFTAeBIgBxABMdrxp55sgRZ07I\nvnAL3rsz/danNPDGlbH5IRaw2gwUo5gvPRp3yIN+acMJYcthrI9qQBC8I8O20VQcP5x0T/D7W+RZ\nGQfw2iXxcVEdlM/UlQZY4yLoh/n6M46uR10tzLdfjyciqvzA7m3O2ji8L+Y4s2mCt661Hyha8OpX\nYtdwKADzJYf3OoDIwkfjiYhQQLZPOaGmGuam1fFEROXpplfMG/LxBzHHmSMRmBtW2g8ULXj58zF/\ngqv8MBc+7KwPzHKPRBMR1UHwmledtRGqkkREdDyePgYc3e+sGx++F38f4TDMNxfbDhSjmEueircR\nqHChhybMVx+L6+EnBWY5hMYGRDSHiHYR0W4i+kGK3+cR0ZPW79cRUZ9su9dkUECy9v48gJXM3J+Z\nxwO4E0Bnx3/t8L5YNM9HPrafvUyA17wqTnRdLcwVLzq+HgDMRU/ITReogLnkaecN1NeBt2+Um64m\nJA/zOmXfrrjjtW+X44kYsBzyQKUI9FKHgmJhvvaUPMBU5Ye5/HnnDdRWg6NCVB3MuH8/HbxrazzI\nij785BBz6bPysGN1yHmwGW1j+fOyAlTldx6YADIuD+yWr0MBYP9ux03w9o0SDJimbDWzuWqTiLnk\nKXCgQgLWRY87vh6APJRXXyfv6Y1FzhuoPA0+amVv/WccixIgqy+oCYlAb1zl2AEFIIFFoEIEetFj\njq8HM8y3Flun+wTB65Y7b+PUsXgwcvpE01uXUnVj/Qr5++GwPHzq4lkwc9Hj4Cp/7Hkd5w2YMDeu\nFMerOgTebDOrncixg4DfSkQcO+g4MAEAfmuxOI71dTBXv+y8DwDMRY/J/mZ/hbv5IhwGv7tWEhE1\n1eD3bGa1EzmwJxaM8ME96Z9DyACvelkSAbU1ErC6wFz8pDheVZXOAxNAtnu8byUiqkPg999x3sae\n7fHAYs/29M9fZUAccj+4plocUheYS5+RFaCgH7zcYWACyD0aTc6FAs4TdbCC1JpQbFXRqTMOQPya\nQIVsYV3kMPCOtrHiBUlEBP2yxdspVZWSiLG+dpyog5WUcTEWzmaYWU5DbAIi8gD4M4C5AIYB+AwR\nDWvwsi8COMPMAwD8FsC92fbPzkrBRQDqmfn+6A+YeSszr3HzB8331onD40ZcAZk4rJMV+N21rprg\nnZsk81lX60qgAVkeQ201eN8HrgQakIws19U5z4BGCVTIDeNWlADZ3xo9ltHudpuGbWxYIfuLMzzM\n1WQbu3fIvtyNK901cOaEvIe6Gln9cdOHd9dJJtQKkly1sW65bAVwEygCAJsSWFgnDbni+CEZ2/V1\ncuKSm268u1b2jlZVOl49irWxfjnYNGG6vE8RCYOP7pfVoy2uphsRovo6OTnloyb2nKeB33lLbHH6\nuCuBBgBz42r5f7PL91FfKyuc1VXgd95018be9+PznguBBgDetEbm3mMHHK+YRDG3rhVhXO9y3qup\nlrmvOmh/y2UDeNdWsUV9reOVtCjmptWiAQd2295O1qiNHZtkv7ZbWwT9smJRE5ITl1zA2zbImKit\nsb/dpmEbG1fJ/J2wMue4jQ/eA9fWuNfDytMyNmqr7W89atiH99ZbmhpylbQEJIDn+jrnuxhiDbAE\nFjUh93p46pgk1+prXWuRaEBQghuX2Xpet0ySOtvcaTJME+xyrjprYdtHkk4EsJuZP2LmOgBPAJjX\n4DXzAESXYJ4BMIucng3eADtBwQgALj2cFAQqZDKuyWJJKHptpgdeMsEsWUeb++NSNhEKShsusjux\nNgKVQKTe9Q0HwHJSyLXjFnNybO6bTAWHgkDETN6H7rSNoB+I1Ge3VBgxAbD791JdBYAcLxkntxEE\nIpHk5xOcErTOrHf7mQJyVKgZcR2wRm2R1ecRCkofXIorgHh9iuosbGFGXK0yxAhVAYzsbFFVCTMS\nzsoWHK3J0Jq2qK4CwOlPlLGD/7SsgLmdv2HNOczZzZ1ZakCsLoTD7adJ+M9YtsjifdRa48HtuIjO\nE1mMCw5VibOThS04UCGJgGzGd3Rl1W1xqOicm03FWWtcsMvEEgCxYyScvR6y6TpgRXVQjk3NJlNf\nXQWY4cwHlzRFNvfX2QjbfqagO4DEo9AOWj9L+RpmDgOoBND4KEUHNNuDxkT0ZSLaSEQbT1ZneMMF\nRYDHA+SmP8e2SaLXOixIk4RhyIB3S57PKgbjrGhIEvmFUgQrm/fhzQHAgMMiLDEMDwApsOYWyvPJ\ncX0OC0clteErkGPusvpMCQBJESo35PqQlS2jbRhSJMg1efkyPrO1hVs7API+mLP7PPLy5H04LLiU\n3Ea+VaAni35Qc9zryK4PvgIYHi+Qn8V8kZeffT+awxaQ4miuKSgCPF4gQ92Cpoid/JONjmRri1xf\nrFCca/KLAMOb3WcavdZtG0Txfy6hvOxtQZYeZjXnRE/ocnvGfXRMOizklYRlC6cFxZLw5Ys2Z3GP\nNJcGZDc2ffI+stHDbOx4NsIMrg8DQIeoz2z9+3Jrdw2wFxRsBzC+qRcx8wPMPIGZJ3TIT+9U0cAR\nIG+OHKfmBo8XKCqVAj19hrhro3tfyxn3iUC5gAaMkLPIe/R31wcARr+h8j4Gu7RFTq7cbN4cObbQ\nDb0HSkCQl+9+Qh80Sqrz9hns7noA1GugfB4DR7lrwGf13+MBeg1w14c+g8Sm+UWuRYGGjAG8OTD6\nD3d1PQA5jjOvQMaYGwpLREw8HqBrb3d96DNYxKCk3AocXbQxdBzI8IAGufxMAVDnHmKLfkPdNVDa\nDsjJkXmjQ1d3feg7RO71dp1dO040dKz8P2Scq+ujxe6Q55P+uKF9Z8DrFXukqMthqxv9h8uc1alh\nwspBG4NGgQwDNMylLQwDKC2XYlx9XM57XXrJ/ZGTB7ioQA1YGpCbJ/erS4wBw0G5ue41wOuV+Son\nF67n354DLA3wuXfeBo4UW/Qa6O56ROecXNETN+TmAT6f2KS3y370Hihzvy/ftUNOg0aLJrudswDx\nK/J87ufO/ELLITeAHv3c9SGqh4UlroMsGjoW5PHCGDDS1fUAQF17ub72rMRkcE09AJyM+szWv4bH\nkx4C0DPh+x7Wz1K+hoi8AEoBuNsHbmEnKFgOIC8xiiGiUUQ03fFfK20nIg+Aho13lZGlMdOsysKF\nMOZ82vH1AGDMuUEKrhQWg6Zf5rwBIhhTL5Ez1ItKJMhwSvvOsSI6NGaqq5uOzpsp1TELi0FzP+O8\nDwCMuZ+RIiMFRaDJs100YMCYcKGcG17aDujUzXkbnXtIzQWPB8bEma6yGzR1jlWpuRTG3Buc9wHW\nuCgokoqM581w3oDXCxo1Wc7F79BFqm06pWd/qbzq9cI4f47z6wHQhVfI2d/FZe7vkUuvl8ydrwA0\neorzBhKCXerSC2iiwnBK+g2TaqO5uTBmNNxKaQ+aeQ1QWCpF0S6Z76oNY/Z8yfr58kFDm8yPNCa/\nEFGHjXoPcrVyQkPGymeRlw9j9rXO+wBIFfDiMqk+OvMad23MmCeZ3PxCwE3gW1QK6tYHgOU8uchC\n0qgpUoU1v0Aq/LrAmPNpKUBWWAK64Ep3bZw/V85QLywC3DjDZR2AjhKo0shJ4sw6hMZfKNV0C4pg\nzHE570WLUBYUg6a5mHPIgDFplmhASZkEXE7p2E0q8hoeGOMvFGfWaTcmXwzkF4MKS2Bko4eFxVLR\ne9JMFw14QOPOl3oJ5R1F553SrQ9QXCrO9JSLXSUiaPpl4t8Ul7kfFzE9LACNO995Azm5oOFWba5O\n3cQ/cErvQUBB+grL5yTMMGttHSCyAcBAIupLRLkAbgCwsMFrFgK4xfp6PoDlnGVF4ibvPOsPXANg\ntnUk6XYAvwDg+AldIyrQgNx0LpxQ45Lr4sty7TqJ8+WE/MJYBE/eHBhT5zh2QmnI2JiwU3EZjMtu\ndNYHyPtAtPqhrxA0znmMZcy6OrbUSl16OM/+FZfFslyUkwtjxpWOJyAaNSVui5JyGJc6n4CMOTfE\nq6XmF4hAOuoEwbjg8lhVY+o5wHn2r6xDLKChPB+MWc4dLxo/A4hWYCwqhXGxcyfUmHtjvCqmr0jG\nmqMGDBiTZ8eKftGAEc6zf+fj0ZUAABViSURBVB27xQIa8hW4CixEoC3nt6gUNPNqx20Yl98YrwZc\nWAw4zZB7vDDGTQd5PBJ8D5/g3Ant3lccHUAcr8ucOxt0vgg0ABHqC69w3IZx2Y3xglvFZc4TETl5\nUnCLSFZvxp3v3AntMzj2PqiwGMblNzm7HgBdNC9+b+YXgaZe6riNWMAKWPetw1ULX74UwgQk+J48\n27ETSoNGxee9olJ3GnDxpxJsUShJHqdtzP5UfNtmx67OExGFJbHsPuXkwJh+mXM9HD4hWQ9dOOTG\npdfHEwe+fEn+OeoEwZhxFShXEo3UrY/zRERpO1AXScxSbh6MmVc718Nx5wM+a2wWl7kKWo25N8Qr\nZvsKJIHqqBMGjGlzYkW/qO8Q5zsi2neOBTSUly8JBYfQxJlxWxSVukpmGJfflLIy8rkMmwyzrunn\nHq1nBG4H8BqAnQCeYubtRPRTIrrKetlDANoT0W4A3wHQ6NhSp9i6+5n5MDNfbx1JOpyZL2fmJkom\nNmDQSClzb+1dp9w8mTwcZBXoys8B7RImveIyeL76E/v7Sg0PPF+/O+6MA1JS+3Pfsd0HlLaHceM3\nkipi0oDhoAkzbDdBwyZIpVRLiMiXD+Pqz4szZhNj/leSI++iMni+tsD+6ovXK69PLFFfXA7jhv+w\n3Qe07wxj/peTKh/S8AkSKNiERk8FDY1vI6D8QhjXf9WRuBk3fqPBZ1oqn7Pd1ZecPHi+vgAoShCR\n0nYwrr3Ndh/QqTuMqz4XE2gyDMkYOdguQhMvAvWPnzhGhUUwbvqGowyLccsdstwbpagExtcW2Hd6\n8vLh+eqPQCXl8Z+VdwJdfrPtPqBbb8nERgNWjwfG5IsdZZZp+mVJW/OoqASeW7+b/Dk3gXHbnXFn\nHAAKSmB85cf2nZ78QnhuuzMu0ADQqTtotoNgr9cAGDPnxQXamwPjwislA2YTmnUt0Dnu+FJxGTy3\n/Zf9FQciGF/5YfK4KCyBcdtd9p2eohJ4Pv+9JIGm7n1B0y+3dz0A9BsOY+qlscrMlJsryRFr5cAO\ndNmNSdlXKimH5ys/sr/v2DDkfkiyRTGMW79nuw8oKYdx87eTKkRT38GgSbNsN0GDx4DGXxCrzEx5\nPhhXfFZWTe22cc0XkhNBxVENsBn4eiwNSLyniktlzrFLeUcYN/xHUlVkGjzaUZKLRk6KBayApQHX\n3uYoy258+uux4B0AUGxpgN1toN4cSw8T2ygXnbVLh64wrvliLGlJRKBRU0DDz7PdBI2/EJSwhZYK\nimDccLsEvzYxPvvtBhpQKu/N7jbQ3DzxqxJtUd4BNO9W231Al57i0FvP/pDHA5pwkaPtUDTlEvfb\nos9mGDBrbRbEY36VmQdZvvfPrJ/9mJkXWl/XMPN1zDyAmScy80eZW2waz4IFC7JtoxEP/OqeBV8a\nHnf2adQkeD77nWRxhUSgNHqKFNKpOJm+QSIY135RBCXRGScCfIUwRk+RYwMznW/vy4fnP/8H6NEv\nllEGJFOEdh1BPfrJEVyZVl4694Dnm78AtUt2WCk3DzRguDyl38TZ9DT+AhifuV22LyX+3JcPGjMV\n/MF7mSsPkgHjhq+DJlyYPBETAflFMEZNkvPdM52ekF8IzzfvAbr1TiohTt4cKSveqbsc65nJFt36\nwPOfPwOVJ09WlJsn2wICFU0ee0iTZ8O47svxzHj0574C0Nhpct51plMLDAPGzd+SLTuJtjAMoKAY\nxvDzpEJoprP+C0vg+dY9QKcesew6ICsn6NQd1K4jeMdmABls0WsgPF+/G9RgpYZyfbKX/PQxKZqX\nAZp+OYx5tzTKilB+oYyLHZsyn8Lg8cL4wvdkH39ikGYYkp0eNk7GRaZjJIvL4Pn2L4GO3WIBKyC2\noG69JavZ1DF7/YbB85UfgxoEMpTnA404T86pb+IISJp1raweNcwQ+QpgjJ0mxwZmOpXD64Xx5R+C\nBo5MevidPB5ZtRg8WmyR6eSZsvbwfPteoH2Xxrbo2U8SEU0cwUuDRsFz238lB1iwbDFyInBwb6yQ\nYto25n4Gxsxr4ismUfILYIyZJnNWplOqcvJgfO0noL5Dkh7gJI9Htuz1Gy5HnGY6eaZ9Z3i+dW9s\nu2Osjdw8xPaxN3HcKw2fAM+t342vCEZ/npcPGjVZjnbOdBwmEeiqW2BMvzzJGQcA5BfCGDNVNKA2\ngwbk+mDc/j+gnv1jGWXA0oCy9qDeA6V4V6bTWjp1k7mzXcfGtug/XObdhErFKd/KmGkwbv5mYz30\nWXq4ZwdQmWFbMBkw5n9Ztuw01MP8QhijJ8tnmukEHl8BPN/8OdCtTwM9zJHPuWtvqZOSSQO69ILn\nGz9PrQEDRspRlgcz+yh03kUwrv9aCj0sAI2ZBv5ga+YTu8iAcdM3QGOnNdBDAygogjFykmhAJj0s\nKJLx3aVnAw3IkbmwYxepH5NJA3r0g+f2/06hAXmy2lt5Cjj8cfrrAdDUS2Fc+4XGephfIBqwc3Pm\no7IND4xb7pAAK7+xBhjDx1t6mEEDikpl3uvUPZbABax5r0tPUGm7eE2KdPQZDM9Xf5JaA4aNB04c\nbrICOc24CsYVNztaJbj77ruPLFiwoOG+/LOO+3/+swW3dmmHez46clb2l7LcfpSS8Z3KeN1nZoDG\nnQ9j9nxZlsvw4XKgAjh1XAoNbd8Yn5QLi0EXXCH76vKLkgZ60vXMQOAMeO/7UqgjcSLq1B3GJdeD\nho4RhyBN9phra4BQFczNa6QISkJRHRo4EnTZjaDOPRuJWlIbwYBUplzxInjtsvhxn94c0PgLZfms\npKyxwDe0xYkjUlBm56b4pFxUKjfKROs5gjSZMTYjUtBszzaYi59Mnoi69IIx53rJRBSVJt30SW3U\nVAPVVTA3rASveDE+KROBBo+RFZ5O3RqJWrIt/FK1evkLcu50dFLOyQNNvEiWZotKGwt8Q1scPyRF\nlxIL4hSXgWZeDWPChbIPNi/1ShFHIlJAZddWqbCbOBF17wvj0k9LZr64LMnxa2SLUBXMdUuloFl0\nUiYCDRsv+zU7dMlsiyo/EDgDc+lz4E2r4pNybh5o8sUwZlwpy/iZbOE/Az56QKrjJlYtLW0PY9Y1\nsmxdUJz25A4Oh61qx5ulsM/xw/Ff9ugvS9Z9BoujmCZ7zNVBIBSE+dZr4DWvxI+lJAM0cqJsMyrv\n1EjgG9mi8jTM159ODlLy8kFTL4FxwRVy32dY7mb/GfChfVKMLNEZLe8o2ylGT5E20qyacX292GL7\nBinyc+pY/Je9B8m+4p4DQKXlKa+P2yIAc80iqXAeDVIMAzRqimwbKO/QSOCT2ghUAhUnYS55WioU\nRx1zXwHo/Lkwzp8r93pTtjiwW4qRJTqj7TvDuHg+aMTEJmxhFajb+rYUAEx0zPsNle1s3fs0CmyS\n2ghViS1WvwJ+67X4EYYerzjAl0Q1oAlbnD4O87UnJeiLakBBkQTMUy+V50vSrI4wM+CvAH+8Swr2\nJVaz7dgNxiXzxSEpLE1y/JLaqKuVomib35BCjol1WwaMkC1cXXpmtkUwAAQDMFe9BH779XiiyusF\njbsAxuxPyT3WpB4ekyKbOzYl6GEJ6MIrZNWtoDAp+E+63jSlcNVHO0QDEpMznXvIvDd4dGYNiOrh\nxlVSXTghUUWDR1sa0KNpPayyNGD9irge5uSCzpsBY+a1QHFJ03p4/LD4Bu9viethcZmlhxfJGElz\nSEZMAz58T2yRWESxW2+xxYARsoc/TSY9pgHrl0vB0Giiigg0ZKzYomNXGxpQIQUyN6yMJ6py8kCT\nZ8GYIdvqmtIAHDsoevjBu/FflLYDXTRPnsUoKMqgh2EpzPn+FinYl5ic6d5X5r2+Q5rQw5DY4u2l\n4NUvxRNVZICGTxANaN+5aVv4z0ihuM1rEvTQB5oS1cNikMNnCYhoEzNPcHRRKzC2uIBXjh2AsjXv\nnZX9bZGgYMKY0bxh1fLYg3F24eqgZHoiYVnW9nhlInSw95UDlVKoyDRly4QnJ+PE1ej6SETOiQ+H\nZTK2TqjIdLM2aqOu1jqv3hrsHq9lC/vH53GoSjI9ibYoKkkb1KRsI1Ahk0/UFt6cjDdro+utCRWR\nsEzGHjk6L5OT0qiN2hrJZCbaIr/Q0bFzHArIub5JtkgvaCnbyNoWMqFmZwspNJdsi6KkrGWTbQQD\nIq6RiGyD8VrZb5tLwxJAy3ngYguPZQv723KiAUaSLfJ8aR22lG3UVMv56uGEz7SgKK3zmrKNKr/c\n6zFbWOPC5laplLbIycnovDZqI1wfO1M8bov8tAmMlG1Uh4C66mRbFBYnreI12UaVXwJvM2LNe14R\nd5vbg9g04/d6zBa5jjJ1XF8ngWLUFl6vnBzl4EjB1Brg1BaVli1Ml7aIyL2elQbUyRnt4fr4+/Dl\nO9PDUFCCiqz0sMG850oPKy1bWOM7J/fs0MMMjnzKNs4KDWgGPQwGZHxno4f+CqmRFLNF7r9fA1Lp\noUMNSORcCQrGFOXzspH90WHt9rOyvy0TFEyYwBs3bmz2dhVFURRFURQlkXMlKBhdmM+Lh/ZBt03v\nn5X9bbbiZYqiKIqiKIqipIaZUV+XRVX5FkaDAkVRFEVRFEVpYZiB+rAGBYqiKIqiKIrSZtGVAkVR\nFEVRFEVp4zADdfUZjsNuZTQoUBRFURRFUZQWhk1Gna4UKIqiKIqiKErbhQGEW+DUz+ZCgwJFURRF\nURRFaWEYQJ0GBYqiKIqiKIrSdjEB1JkaFCiKoiiKoihKm4UZqNeVAkVRFEVRFEVpuzAYdawPGiuK\noiiKoihKm4Wh24cURVEURVEUpU3D0O1DiqIoiqIoitKmMRmo1pUCRVEURVEURWm7mGCEIhoUKIqi\nKIqiKEqbxWQgZOqDxoqiKIqiKIrSZjEB1GS5fYiI2hHR60T0ofV/eZrXLSaiCiJ62W7bGhQoiqIo\niqIoSgvDzfNMwQ8ALGPmgQCWWd+n4lcAPuukYQ0KFEVRFEVRFKWFaaZnCuYBeMT6+hEAV6d6ETMv\nAxBw0jBxCxyNREQBALuaveG2SwcAJ1u7E58Q1JbNi9qzeVF7Ni9qz+ZDbdm8qD2bl8HMXNzanWgK\nIloM+ex9AGoSfvUAMz9gs40KZi6zviYAZ6Lfp3jtDAB3MPMVdtr22nmRC3Yx84QWarvNQUQb1Z7N\ng9qyeVF7Ni9qz+ZF7dl8qC2bF7Vn80JEG1u7D3Zg5jl2XkdESwF0SfGruxq0x0TUbNn9lgoKFEVR\nFEVRFEVxCDPPTvc7IjpGRF2Z+QgRdQVwvLn+rj5ToCiKoiiKoijnBgsB3GJ9fQuAF5ur4ZYKCmzt\ni1Jso/ZsPtSWzYvas3lRezYvas/mQ23ZvKg9m5e2ZM97AFxMRB8CmG19DyKaQEQPRl9ERGsAPA1g\nFhEdJKJLm2q4RR40VhRFURRFURTl3EG3DymKoiiKoihKG0eDAkVRFEVRFEVp42QdFBDRt4loOxFt\nI6LHichHRH2JaB0R7SaiJ4kotzk62xZIY8+HiWgvEb1j/RvT2v08VyCib1q23E5E37J+ZqtEuJJM\nGlsuIKJDCWPzstbu59kMEf2diI4T0baEn6UcjyT8wZpH3yWica3X87MPh7acQUSVCeP0x63X87OT\nNPa8zrrfTSKa0OD1d1pjc5edvcptDSf2JKI+RFSdMD7vb51en52kseWviOh9a258nojKEn6nY9Ml\nWQUFRNQdwDcATGDmEQA8AG4AcC+A3zLzAABnAHwx2462BTLYEwC+y8xjrH/vtFonzyGIaASALwGY\nCGA0gCuIaADslwhXLDLYEpB7PTo2X221Tp4bPAyg4TnV6cbjXAADrX9fBvDXf1MfzxUehn1bAsCa\nhHH6039TH88lHkZje24DcC2A1Yk/JKJhEG0abl3zFyLy/Bv6eC7xMGza02JPwvj8akt37hzjYTS2\n5esARjDzKAAfALgT0LGZLc2xfcgLIJ+IvAAKABwBMBPAM9bv05ZgVlLS0J6HW7k/5zJDAaxj5hAz\nhwGsgkzItkqEK0mks6XiAGZeDeB0gx+nG4/zADzKwloAZdaZ1Aoc21JpglT2ZOadzLwrxcvnAXiC\nmWuZeS+A3ZCEgWLh0J5KBtLYcomlRQCwFkAP62sdm1mQVVDAzIcA3AdgPyQYqASwCUBFwod1EED3\nbP5OWyGVPZl5ifXrn1nLZL8lorxW6+S5xTYA04moPREVALgMQE8AnZn5iPWaowA6t1YHzyHS2RIA\nbrfG5t91K5Yr0o3H7gAOJLxO59KmyXRvTyGirUS0iIiGt0LfPkno2Gx++hLRFiJaRUTTW7sz5xhf\nALDI+lrHZhZku32oHBKV9QXQDUAhGi/xKDZJZU8iuhmyLDYEwHkA2gH4fqt18hyCmXdCtrItAbAY\nwDsAIg1ewwD0XN4myGDLvwLoD2AMJJD9dWv18ZOAjsfmo4EtNwPozcyjAfwRwAut1jFFacwRAL2Y\neSyA7wB4jIhKWrlP5wREdBeAMID/a+2+fBLIdvvQbAB7mfkEM9cDeA7ANMgyt9d6TQ8Ah7L8O22F\nVPacysxHrC0EtQD+AV0Ksw0zP8TM45n5AsjzLR8AOBbdhkHNXCL8k0wqWzLzMWaOMLMJ4H+hY9MN\n6cbjIcRXYwCdS+2Q0pbM7GfmKuvrVwHkEFGH1uvmOY+OzWbE2upyyvp6E4A9AAa1bq/OfojoVgBX\nALiJ40W3dGxmQbZBwX4Ak4mogIgIwCwAOwCsADDfek2zlmD+hJPKnjsTRI4ge2S3ZWhDSYCIOln/\n94LsgX8MLVgi/JNMKls22ON+DXRsuiHdeFwI4HPWKUSTIdsJj6RqQImR0pZE1MWaP0FEEyHad6pV\nevjJYCGAG4goj4j6Qh6GX9/KfTpnIaKO0YdhiagfxJ4ftW6vzm6IaA6A7wG4iplDCb/SsZkFWVc0\nJqK7AXwasnyzBcBtkP1bT0C2umwBcLOV5VaaII09FwHoCIAg2za+Gs16KZkhKfPdHkA9gO8w8zIi\nag/gKQC9AHwM4HpmbvjAotKANLb8J2TrEAPYB+Ar6rimh4geBzADQAcAxwD8BLKVpdF4tJzYP0G2\nZIYAfJ6ZN7ZGv89GHNrydgBfg8yr1ZDx+1Zr9PtsJY09T0O2W3UEUAHgHWa+1Hr9XZC93GEA32Lm\nRSmabbM4sScRfQrATyFzqwngJ8z8Umv0+2wkjS3vBJCHeHC/Nnpqk45N92QdFCiKoiiKoiiKcm6j\nFY0VRVEURVEUpY2jQYGiKIqiKIqitHE0KFAURVEURVGUNo4GBYqiKIqiKIrSxtGgQFEURVEURVHa\nOBoUKIqiKIqiKEobR4MCRVEURVEURWnj/H/G/QyRK3vFfQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x72 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwYAAABZCAYAAACE9jNrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncRwH+P/6F5HWIjohJwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x72 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAw4AAABZCAYAAACXIXOfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naOAghBBCCCGEmMv/B0c8L5aI0ORAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x72 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZv12QDP7xus",
        "colab_type": "text"
      },
      "source": [
        "###**Conclusion**\n",
        "####Previously we showed a high relative frequency of guanine around the HIV integration site based on the consensus sequence calculated from DNA of correctly predicted true integration sites. Also, judging from the dot-plot above, which compares the relative distribution of DNA nucleotides from correctly predicted true integration sites with nucleotides from correctly predicted randomly sampled (false) integration sites, we clearly see that there is a significant difference in the relative distribution of nucleotides at the proviral HIV integration site. The difference is largest around the integration site itself (at 100 bp position)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVUlvm9A8k7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}